{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, TensorBoard\n",
    "from keras import backend as K\n",
    "\n",
    "from libs.util import random_mask\n",
    "from libs.pconv_model_first_resid import PConvUnet\n",
    "# from libs.pconv_model_UNet import PConvUnet\n",
    "from libs.properties import properties\n",
    "\n",
    "# Settings\n",
    "MAX_BATCH_SIZE = 32\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties_dict = properties()\n",
    "length = properties_dict[\"length\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_df = pd.read_csv('./data/trafficV_M.csv', index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix_df = np.array(matrix_df)\n",
    "\n",
    "# print(matrix_df.shape)\n",
    "# print(\"%d bytes\" % (matrix_df.size * matrix_df.itemsize))\n",
    "# print(np.isnan(matrix_df).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 单独测试week_ago, mintue_ago\n",
    "# week_delta = pd.Timedelta(1, unit='W')\n",
    "# minute_delta = pd.Timedelta(15, unit='m')\n",
    "\n",
    "\n",
    "# channel_num = 3\n",
    "# smooth_time = channel_num-1\n",
    "# set_up_time = week_delta\n",
    "\n",
    "# train_df = matrix_df.truncate(before=matrix_df.index.min() + set_up_time)\n",
    "# train_week_ago_df = matrix_df.loc[train_df.index - week_delta]\n",
    "# train_minute_ago_df = matrix_df.loc[train_df.index - minute_delta]\n",
    "\n",
    "# train_df = np.array(train_df).reshape(-1, length, length, 1)\n",
    "# train_week_ago_df = np.array(train_week_ago_df).reshape(-1, length, length, 1)\n",
    "# train_minute_ago_df = np.array(train_minute_ago_df).reshape(-1, length, length, 1)\n",
    "\n",
    "\n",
    "# train_array = np.concatenate((train_df, train_minute_ago_df, train_week_ago_df), axis=3)\n",
    "# X_train, X_val = train_test_split(train_array, test_size = 0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTrainArray(week_history_num=0, minute_history_num=0):\n",
    "    week_delta_list = [pd.Timedelta(i+1, unit='W') for i in range(week_history_num)]\n",
    "    minute_delta_list = [pd.Timedelta((i+1)*15, unit='m') for i in range(minute_history_num)]\n",
    "    delta_list = week_delta_list+minute_delta_list\n",
    "    print(delta_list)\n",
    "    \n",
    "    set_up_time = pd.Timedelta(week_history_num, unit='W')\n",
    "    train_df = matrix_df.truncate(before=matrix_df.index.min() + set_up_time)\n",
    "    \n",
    "    train_ago_array_tuple = tuple([np.array(matrix_df.loc[train_df.index - i]).reshape(-1, length, length, 1) for i in delta_list])\n",
    "    train_df = np.array(train_df).reshape(-1, length, length, 1)\n",
    "    train_array = np.concatenate((train_df,)+train_ago_array_tuple, axis=3)\n",
    "    print(train_array.shape)\n",
    "    return train_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Timedelta('7 days 00:00:00'), Timedelta('0 days 00:15:00')]\n",
      "(16704, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "week_history_num = 1\n",
    "minute_history_num = 1\n",
    "\n",
    "channel_num = week_history_num +minute_history_num +1\n",
    "smooth_time = channel_num-1\n",
    "\n",
    "train_array = createTrainArray(week_history_num, minute_history_num)\n",
    "X_train, X_val = train_test_split(train_array, test_size = 0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(469, 52)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_steps = X_train.shape[0] // MAX_BATCH_SIZE\n",
    "val_steps = X_val.shape[0] // MAX_BATCH_SIZE\n",
    "epoch_steps, val_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(ImageDataGenerator):\n",
    "    def flow(self, X, *args, **kwargs):\n",
    "        i = 1\n",
    "        while True:\n",
    "            \n",
    "            # Get augmentend image samples\n",
    "            ori = next(super().flow(X, *args, **kwargs))\n",
    "    \n",
    "            # Get masks for each image sample\n",
    "            mask = np.stack([random_mask(ori.shape[1], ori.shape[2], size=0.1, channels=channel_num, smooth_time=smooth_time) for _ in range(ori.shape[0])], axis=0)\n",
    "            # Apply masks to all image sample\n",
    "            masked = deepcopy(ori)\n",
    "#             print(masked.shape)\n",
    "            masked_mean = masked[mask==1].mean()\n",
    "            masked[mask==0] = masked_mean\n",
    "\n",
    "            # Yield ([ori, masl],  ori) training batches\n",
    "#             print(masked.shape, ori.shape)\n",
    "            gc.collect()\n",
    "            yield [masked, mask], ori[:,:,:,:1]\n",
    "            \n",
    "train_datagen = DataGenerator()\n",
    "train_generator = train_datagen.flow(\n",
    "    X_train, batch_size=MAX_BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Create validation generator\n",
    "val_datagen = DataGenerator()\n",
    "val_generator = val_datagen.flow(\n",
    "    X_val, batch_size=MAX_BATCH_SIZE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(next(train_generator)[1])[:,:,:,:1].shape\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=1, mode='auto')\n",
    "\n",
    "# model = PConvUnet(img_rows=length, img_cols=length, channels=channel_num)\n",
    "# optimizer = model.get_optimizer()\n",
    "# def scheduler(epoch):\n",
    "#     if epoch>1 and epoch % 1 == 0 and epoch != 0:\n",
    "#         lr = K.get_value(optimizer.lr)\n",
    "#         if lr>0.00005:\n",
    "#             if epoch%4==0:\n",
    "#                 K.set_value(optimizer.lr, lr * 0.6)\n",
    "#             else:\n",
    "#                 K.set_value(optimizer.lr, lr * 0.8)\n",
    "#     print(K.get_value(optimizer.lr))\n",
    "#     return K.get_value(optimizer.lr)\n",
    "\n",
    "# reduce_lr = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PConvUnet(img_rows=length, img_cols=length, channels=channel_num)\n",
    "optimizer = model.get_optimizer()\n",
    "def scheduler(epoch):\n",
    "    if epoch>2 and epoch % 1 == 0 and epoch != 0:\n",
    "        lr = K.get_value(optimizer.lr)\n",
    "        if lr>0.00005:\n",
    "            if epoch%3==0:\n",
    "                K.set_value(optimizer.lr, lr * 0.6)\n",
    "            else:\n",
    "                K.set_value(optimizer.lr, lr * 0.8)\n",
    "    print(K.get_value(optimizer.lr))\n",
    "    return K.get_value(optimizer.lr)\n",
    "\n",
    "reduce_lr = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "0.004\n",
      "469/469 [==============================] - 240s 512ms/step - loss: 235781.0351 - val_loss: 145329.8586\n",
      "Epoch 2/2\n",
      "0.004\n",
      "469/469 [==============================] - 241s 514ms/step - loss: 60085.8746 - val_loss: 112155.9730\n",
      "Epoch 3/3\n",
      "0.004\n",
      "469/469 [==============================] - 234s 499ms/step - loss: 52678.9447 - val_loss: 77648.7336\n",
      "Epoch 4/4\n",
      "0.0024\n",
      "469/469 [==============================] - 245s 523ms/step - loss: 42479.5095 - val_loss: 42949.7092\n",
      "Epoch 5/5\n",
      "0.0019200001\n",
      "469/469 [==============================] - 253s 539ms/step - loss: 38952.5737 - val_loss: 44778.5726\n",
      "Epoch 6/6\n",
      "0.001536\n",
      "469/469 [==============================] - 250s 534ms/step - loss: 37935.5602 - val_loss: 44565.7746\n",
      "Epoch 7/7\n",
      "0.00092160003\n",
      "469/469 [==============================] - 239s 509ms/step - loss: 33382.5162 - val_loss: 35605.2781\n",
      "Epoch 8/8\n",
      "0.00073728\n",
      "469/469 [==============================] - 242s 516ms/step - loss: 31088.1973 - val_loss: 34504.5064\n",
      "Epoch 9/9\n",
      "0.000589824\n",
      "469/469 [==============================] - 241s 513ms/step - loss: 28694.8172 - val_loss: 33369.6176\n",
      "Epoch 10/10\n",
      "0.0003538944\n",
      "469/469 [==============================] - 359s 766ms/step - loss: 27708.2506 - val_loss: 28368.6763\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_generator, \n",
    "    validation_data=val_generator,\n",
    "    steps_per_epoch = epoch_steps,\n",
    "    validation_steps = val_steps,\n",
    "    epochs = 10,\n",
    "    callbacks=[reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2(y_true, y_pred):\n",
    "    return np.sum(np.mean(np.square(y_true - y_pred), axis=0))\n",
    "\n",
    "def l1(y_true, y_pred):\n",
    "    return np.sum(np.mean(np.abs(y_true - y_pred), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28085.547821590575"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_shape = X_val.shape\n",
    "mask = np.stack([random_mask(mask_shape[1], mask_shape[2], size=0.1, channels=channel_num, smooth_time=smooth_time) for _ in range(mask_shape[0])], axis=0)\n",
    "\n",
    "masked = deepcopy(X_val)\n",
    "masked_mean = masked[mask==1].mean()\n",
    "masked[mask==0] = masked_mean\n",
    "\n",
    "y_pred = model.predict([masked, mask])\n",
    "y_true = X_val[:,:,:,:1]\n",
    "\n",
    "y_true = (1-mask[:,:,:,:1])*y_true\n",
    "y_pred = (1-mask[:,:,:,:1])*y_pred\n",
    "\n",
    "l2(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139.87275923252108"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(np.sum(np.sum(np.sum(np.abs(y_true - y_pred), axis=3), axis=2), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 32, 32, 32)   896         input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 32, 32, 32)   0           conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePo (None, 16, 16, 32)   0           activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 16, 16, 32)   128         average_pooling2d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 16, 16, 32)   0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 16, 16, 32)   9248        activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 16, 16, 32)   128         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 16, 16, 32)   0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 16, 16, 32)   9248        activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 16, 16, 32)   0           conv2d_98[0][0]                  \n",
      "                                                                 average_pooling2d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 16, 16, 32)   0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 16, 16, 64)   18496       activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "EncBN1 (BatchNormalization)     (None, 16, 16, 64)   256         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 16, 16, 64)   0           EncBN1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePo (None, 8, 8, 64)     0           activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 8, 8, 64)     256         average_pooling2d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 8, 8, 64)     0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 8, 8, 64)     36928       activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 8, 8, 64)     256         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 8, 8, 64)     0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 8, 8, 64)     36928       activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 8, 8, 64)     0           conv2d_101[0][0]                 \n",
      "                                                                 average_pooling2d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 8, 8, 64)     0           add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 8, 8, 96)     55392       activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "EncBN2 (BatchNormalization)     (None, 8, 8, 96)     384         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 8, 8, 96)     0           EncBN2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePo (None, 4, 4, 96)     0           activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 4, 4, 96)     384         average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 4, 4, 96)     0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 4, 4, 96)     83040       activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 4, 4, 96)     384         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 4, 4, 96)     0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 4, 4, 96)     83040       activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 4, 4, 96)     0           conv2d_104[0][0]                 \n",
      "                                                                 average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 4, 4, 96)     0           add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_16 (UpSampling2D) (None, 8, 8, 96)     0           activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "subtract_16 (Subtract)          (None, 8, 8, 96)     0           conv2d_102[0][0]                 \n",
      "                                                                 up_sampling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 8, 8, 160)    0           activation_113[0][0]             \n",
      "                                                                 subtract_16[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 8, 8, 64)     92224       concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 8, 8, 64)     256         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 8, 8, 64)     0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 8, 8, 64)     256         leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 8, 8, 64)     0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 8, 8, 64)     36928       activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 8, 64)     256         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 8, 8, 64)     0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 8, 8, 64)     36928       activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 8, 8, 64)     0           conv2d_107[0][0]                 \n",
      "                                                                 leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 8, 8, 64)     0           add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_17 (UpSampling2D) (None, 16, 16, 64)   0           activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "subtract_17 (Subtract)          (None, 16, 16, 64)   0           up_sampling2d_17[0][0]           \n",
      "                                                                 conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 16, 16, 96)   0           activation_109[0][0]             \n",
      "                                                                 subtract_17[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 16, 16, 32)   27680       concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 16, 16, 32)   128         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 16, 16, 32)   0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 16, 16, 32)   128         leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 16, 16, 32)   0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 16, 16, 32)   9248        activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 16, 16, 32)   128         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 16, 16, 32)   0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 16, 16, 32)   9248        activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 16, 16, 32)   0           conv2d_110[0][0]                 \n",
      "                                                                 leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 16, 16, 32)   0           add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_18 (UpSampling2D) (None, 32, 32, 32)   0           activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "subtract_18 (Subtract)          (None, 32, 32, 32)   0           up_sampling2d_18[0][0]           \n",
      "                                                                 conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 32, 32, 35)   0           input_11[0][0]                   \n",
      "                                                                 subtract_18[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 32, 32, 16)   5056        concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 32, 32, 16)   0           conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 32, 32, 16)   64          leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 32, 32, 16)   0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 32, 32, 16)   2320        activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 32, 32, 16)   64          conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 32, 32, 16)   0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 32, 32, 16)   2320        activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 32, 32, 16)   0           conv2d_113[0][0]                 \n",
      "                                                                 leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 32, 32, 16)   0           add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 32, 32, 1)    17          activation_126[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 558,641\n",
      "Trainable params: 556,913\n",
      "Non-trainable params: 1,728\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[27633.44140625,\n",
       " 39063.34765625,\n",
       " 29928.09765625,\n",
       " 26524.21484375,\n",
       " 30725.765625,\n",
       " 66758.765625,\n",
       " 28441.779296875,\n",
       " 35197.95703125,\n",
       " 23420.056640625,\n",
       " 25903.60546875,\n",
       " 31009.5859375,\n",
       " 26628.587890625,\n",
       " 49548.58984375,\n",
       " 19892.75390625,\n",
       " 18327.91015625,\n",
       " 28046.353515625,\n",
       " 20917.1796875,\n",
       " 21713.705078125,\n",
       " 28147.0078125,\n",
       " 33015.890625]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list = []\n",
    "for _ in range(20):\n",
    "    list.append(model.evaluate_generator(val_generator, 1))\n",
    "list\n",
    "# model.evaluate_generator(val_generator, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# test_num = random.randint(0, 200)\n",
    "# test = deepcopy(X_train[test_num,np.newaxis,:])\n",
    "\n",
    "# test_mask = random_mask(test.shape[1], test.shape[2], size=0.1, channels=channel_num, smooth_time=smooth_time)\n",
    "# test_mask = test_mask[np.newaxis,:]\n",
    "\n",
    "# test_mask[0,:,:,0].shape\n",
    "# test[test_mask==0] = test.mean()\n",
    "\n",
    "# # test_mask.shape\n",
    "# # plt.imshow(test[0,:,:,0]*255)\n",
    "# test_res = model.predict([test, test_mask])\n",
    "# # np.sum((test-test_res)**2)\n",
    "# np.sum((test[0,:,:,0][test_mask[0,:,:,0] == 0] - test_res[0,:,:,0][test_mask[0,:,:,0] == 0])**2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
