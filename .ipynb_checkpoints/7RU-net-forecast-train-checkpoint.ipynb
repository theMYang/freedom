{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, TensorBoard\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from datetime import datetime\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Conv2D, UpSampling2D, Dropout, LeakyReLU, BatchNormalization, Activation, Add, Subtract\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "# from keras.applications import VGG16\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "\n",
    "# from libs.pconv_model_UNet import PConvUnet\n",
    "from keras.models import load_model  \n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "matrix_length = 32\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "matrix_df = pd.read_csv('./data/trafficV_M.csv', index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def l2(y_true, y_pred):\n",
    "    return math.sqrt(np.sum(np.mean(np.square(y_true - y_pred), axis=0))/1024)\n",
    "\n",
    "# def createTrainArray(week_history_num=0, minute_history_num=0):\n",
    "#     week_delta_list = [pd.Timedelta(i+1, unit='W') for i in range(week_history_num)]\n",
    "#     minute_delta_list = [pd.Timedelta((i+1)*15, unit='m') for i in range(minute_history_num)]\n",
    "#     # 参考历史数据时间点list\n",
    "#     delta_list = week_delta_list+minute_delta_list\n",
    "#     print(delta_list)\n",
    "    \n",
    "#     set_up_time = pd.Timedelta(week_history_num, unit='W')\n",
    "#     # 根据历史数据选取多少，重新构建数据集\n",
    "#     # 相当于去除最开始week_history_num个周的数据，因为这些数据无法找到更前的数据\n",
    "#     train_df = matrix_df.truncate(before=matrix_df.index.min() + set_up_time)\n",
    "    \n",
    "#     train_ago_array_tuple = tuple([np.array(matrix_df.loc[train_df.index - i]).reshape(-1, matrix_length, matrix_length, 1) for i in delta_list])\n",
    "#     train_df = np.array(train_df).reshape(-1, matrix_length, matrix_length, 1)\n",
    "#     # concatenate保持 待修复数据在前，参考历史数据在后。与random_mask函数生成mask相一致\n",
    "#     train_array = np.concatenate((train_df,)+train_ago_array_tuple, axis=3)\n",
    "#     print(train_array.shape)\n",
    "#     return train_array\n",
    "\n",
    "\n",
    "def createTrainArray(week_history_num=0, minute_history_num=0):\n",
    "    week_delta_list = [pd.Timedelta(week_history_num-i, unit='W') for i in range(week_history_num)]\n",
    "    minute_delta_list = [pd.Timedelta((minute_history_num-i)*15, unit='m') for i in range(minute_history_num)]\n",
    "    # 参考历史数据时间点list\n",
    "    delta_list = minute_delta_list+week_delta_list\n",
    "    print(delta_list)\n",
    "    \n",
    "    set_up_time = pd.Timedelta(week_history_num, unit='W')\n",
    "    # 根据历史数据选取多少，重新构建数据集\n",
    "    # 相当于去除最开始week_history_num个周的数据，因为这些数据无法找到更前的数据\n",
    "    train_df = matrix_df.truncate(before=matrix_df.index.min() + set_up_time)\n",
    "    \n",
    "    train_ago_array_tuple = tuple([np.array(matrix_df.loc[train_df.index - i]).reshape(-1, matrix_length, matrix_length, 1) for i in delta_list])\n",
    "    train_df = np.array(train_df).reshape(-1, matrix_length, matrix_length, 1)\n",
    "    # concatenate保持 待修复数据在前，参考历史数据在后。与random_mask函数生成mask相一致\n",
    "    train_array = np.concatenate((train_df,)+train_ago_array_tuple, axis=3)\n",
    "    print(train_array.shape)\n",
    "    return train_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Timedelta('7 days 00:00:00')]\n",
      "(16704, 32, 32, 2)\n"
     ]
    }
   ],
   "source": [
    "week_history_num = 1\n",
    "minute_history_num = 0\n",
    "\n",
    "channel_num = week_history_num +minute_history_num +1\n",
    "smooth_time = channel_num-1\n",
    "\n",
    "# train_array为(16704, 32, 32, 3)，16704个矩阵，32*32采集点，3从上到下为当前时间，上一周，上一15min\n",
    "train_array = createTrainArray(week_history_num, minute_history_num)\n",
    "X_train, X_test = train_test_split(train_array, test_size = 0.1, random_state=42, shuffle=False)\n",
    "# X_train, X_val = train_test_split(train_array, test_size = 0.1, random_state=42, shuffle=False) # 不shuffle可用于查看数据正确性\n",
    "\n",
    "# X_train = train_array[:16704-900-900]\n",
    "# X_val = train_array[16704-900-900:16704-900]\n",
    "# X_test = train_array[16704-900:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以第一数据为例. 第一列为待预测数据\n",
    "# 第一例：1.15 0:00  二：1.8 0:00  三：1.1 0:00  四：1.14 23:45  五：1.14 23:30  六：1.14 23:15\n",
    "# X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_shape = (matrix_length, matrix_length, channel_num)\n",
    "true_volume_shape = (matrix_length, matrix_length, 1)\n",
    "history_volume_shape = (matrix_length, matrix_length, channel_num-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(469, 52)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_BATCH_SIZE = 32\n",
    "epoch_steps = X_train.shape[0] // MAX_BATCH_SIZE\n",
    "val_steps = X_test.shape[0] // MAX_BATCH_SIZE\n",
    "epoch_steps, val_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "def load_data(volume_matrix, batch_size=MAX_BATCH_SIZE):\n",
    "    n_batches=batch_size\n",
    "    len_of_matrix = len(volume_matrix)\n",
    "\n",
    "    batch_i = 0\n",
    "    while ((batch_i+1)*batch_size < len_of_matrix):\n",
    "        batch_matrix = volume_matrix[batch_i*batch_size: (batch_i+1)*batch_size]\n",
    "        true_volume, history_volume = batch_matrix[:, :, :, :1], batch_matrix[:, :, :, 1:]\n",
    "        batch_i+=1\n",
    "\n",
    "        yield true_volume, history_volume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def l2(y_true, y_pred):\n",
    "    return math.sqrt(np.sum(np.mean(np.square(y_true - y_pred), axis=0))/1024)\n",
    "\n",
    "def l1(y_true, y_pred):\n",
    "    return np.sum(np.mean(np.abs(y_true - y_pred), axis=0))/(matrix_length*matrix_length)\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    return np.sum(np.mean((np.abs(y_true - y_pred)/y_true)*100, axis=0))/(matrix_length*matrix_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_init = 'glorot_uniform'\n",
    "bias_init = 'zeros'\n",
    "\n",
    "# kernel_init = initializers.he_uniform()\n",
    "# bias_init = initializers.he_uniform()\n",
    "kernel_regul = regularizers.l2(1)\n",
    "activity_regul = regularizers.l2(1)\n",
    "\n",
    "learn_rate = 0.0002\n",
    "\n",
    "# ResNet block\n",
    "def identity_block(X, filters, f):\n",
    "\n",
    "    F1, F2 = filters\n",
    "\n",
    "    X_shortcut = X\n",
    "\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(filters=F1, kernel_size=(f, f), strides=(1, 1), padding='same',\n",
    "               kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "              kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(X)\n",
    "\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same',\n",
    "               kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "              kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(X)\n",
    "\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X\n",
    "\n",
    "# ENCODER\n",
    "def encoder_layer(img_in, filters, kernel_size, bn=True, resid=True):\n",
    "    # conv = Conv2D(filters=filters, kernel_size=kernel_size, strides=(1, 1), padding='same')(img_in)\n",
    "    conv = img_in\n",
    "    if bn:\n",
    "        conv = BatchNormalization()(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "#             conv = MaxPooling2D((2, 2))(conv)\n",
    "\n",
    "\n",
    "    if resid:\n",
    "        conv = identity_block(conv, (filters, filters), kernel_size)\n",
    "\n",
    "    return conv\n",
    "\n",
    "# DECODER\n",
    "def decoder_layer(img_in, e_conv, filters, kernel_size, bn=True, resid=True):\n",
    "    # up_img = UpSampling2D(size=(2,2))(img_in)\n",
    "    up_img = img_in\n",
    "    concat_img = Concatenate(axis=3)([e_conv,up_img])\n",
    "    conv = Conv2D(filters=filters, kernel_size=kernel_size, strides=(1, 1), padding='same',\n",
    "                  kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "              kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(concat_img)\n",
    "    if bn:\n",
    "        conv = BatchNormalization()(conv)\n",
    "    conv = LeakyReLU(alpha=0)(conv)\n",
    "\n",
    "    if resid:\n",
    "        conv = identity_block(conv, (filters, filters), kernel_size)\n",
    "    return conv\n",
    "\n",
    "\n",
    "\n",
    "def build_unet():      \n",
    "\n",
    "    # INPUTS\n",
    "    history_traffic_volume = Input(shape=history_volume_shape)\n",
    "\n",
    "    # kernel_init = initializers.he_normal()\n",
    "    # bias_init = initializers.he_normal()\n",
    "    kernel_init = 'glorot_uniform'\n",
    "    bias_init = 'zeros'\n",
    "\n",
    "#         kernel_init = initializers.he_uniform()\n",
    "#         bias_init = 'Orthogonal'\n",
    "    kernel_regul = regularizers.l2(1)\n",
    "    activity_regul = regularizers.l2(1)\n",
    "\n",
    "    filters_base = 32\n",
    "    e_conv1_head = Conv2D(filters=filters_base, kernel_size=3, strides=1, padding='same',\n",
    "                          kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(history_traffic_volume)\n",
    "#         e_conv1_head = Conv2D(filters=filters_base*1, kernel_size=3, strides=1, padding='same',\n",
    "#                               kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "#                       kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(e_conv1_head)\n",
    "    e_conv1_tail = AveragePooling2D((2, 2))(e_conv1_head)\n",
    "    e_conv1 = encoder_layer(e_conv1_tail, filters_base, 3, bn=False)\n",
    "\n",
    "    e_conv2_head = Conv2D(filters=filters_base*2, kernel_size=3, strides=1, padding='same',\n",
    "                          kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(e_conv1)\n",
    "    e_conv2_tail = AveragePooling2D((2, 2))(e_conv2_head)\n",
    "    e_conv2 = encoder_layer(e_conv2_tail, filters_base*2, 3)\n",
    "\n",
    "    e_conv3_head = Conv2D(filters=filters_base*4, kernel_size=3, strides=1, padding='same',\n",
    "                          kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(e_conv2)\n",
    "    e_conv3_tail = AveragePooling2D((2, 2))(e_conv3_head)\n",
    "    d_conv3_head = encoder_layer(e_conv3_tail, filters_base*4, 3)\n",
    "    resid1 = Subtract()([e_conv3_tail, d_conv3_head])\n",
    "    d_conv3_tail = UpSampling2D(size=(2, 2))(resid1)\n",
    "\n",
    "\n",
    "    d_conv4_head = decoder_layer(d_conv3_tail, e_conv3_head, filters_base*2, 3)\n",
    "    resid2 = Subtract()([d_conv4_head, e_conv2_tail])\n",
    "    d_conv4_tail = UpSampling2D(size=(2, 2))(resid2)\n",
    "\n",
    "\n",
    "    d_conv5_head = decoder_layer(d_conv4_tail, e_conv2_head, filters_base*1, 3)\n",
    "    resid3 = Subtract()([d_conv5_head, e_conv1_tail])\n",
    "    d_conv5_tail = UpSampling2D(size=(2, 2))(resid3)\n",
    "\n",
    "    d_conv6_head = decoder_layer(d_conv5_tail, e_conv1_head, filters_base//2, 3, bn=False)\n",
    "\n",
    "\n",
    "    outputs = Conv2D(1, 1, activation = 'relu', kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(d_conv6_head)\n",
    "\n",
    "    # Setup the model inputs / outputs\n",
    "    model = Model(inputs=history_traffic_volume, outputs=outputs)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer = Adam(lr=learn_rate),\n",
    "        loss='mse'\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = build_unet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# unet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_step = []\n",
    "l2_validation = []\n",
    "\n",
    "def train(train_matrix, epochs, batch_size=MAX_BATCH_SIZE, learn_rate=0.01):\n",
    "\n",
    "    start_time = datetime.now()\n",
    "    min_mse=999\n",
    "    print(\"train start \"+str(start_time))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "#         if epoch>2 and epoch % 1 == 0 and epoch != 0:\n",
    "#             if learn_rate>0.0001:\n",
    "#                 if epoch%3==0:\n",
    "#                     learn_rate = 0.6*learn_rate\n",
    "#                 else:\n",
    "#                     learn_rate = 0.8*learn_rate\n",
    "#                 K.set_value(unet.optimizer.lr, learn_rate)\n",
    "                \n",
    "        for batch_i, (true_volume, history_volume) in enumerate(load_data(train_matrix,batch_size)):\n",
    "            # true_volume 真实待预测路网交通量  history_volume 路网交通量历史数据\n",
    "            #  训练 unet\n",
    "            #  训练 Generator\n",
    "            g_loss = unet.train_on_batch(history_volume, true_volume)\n",
    "\n",
    "\n",
    "        elapsed_time = datetime.now() - start_time\n",
    "        # Plot the progress\n",
    "        y_pred = unet.predict(X_test[:, :, :, 1:])\n",
    "        y_true = X_test[:, :, :, :1]\n",
    "\n",
    "        l2_epoch_validation = l2(y_true, y_pred)\n",
    "        l1_epoch_validation = l1(y_true, y_pred)\n",
    "        \n",
    "        y_pred[y_true==0] += 1\n",
    "        y_true[y_true==0] += 1\n",
    "        mape_epoch_validation = mape(y_true, y_pred)\n",
    "        \n",
    "        lr_step.append(K.get_value(unet.optimizer.lr))\n",
    "        l2_validation.append(l2_epoch_validation)\n",
    "        \n",
    "#         if(l2_epoch_validation<18 and l2_epoch_validation>14 and l2_epoch_validation<min_mse):\n",
    "#             unet.save_weights('./model/RUnet/tmp/runet_forecast.h5')\n",
    "#             min_mse = l2_epoch_validation\n",
    "            \n",
    "        l2_validation.append(l2_epoch_validation)\n",
    "        if epoch%1==0:\n",
    "#             print(\"unet lr:\"+ str(K.get_value(unet.optimizer.lr)))\n",
    "            print (\"[RUnet %d/%d]  [mse: %f] [mae: %f] [mape: %f] [G loss: %f] time: %s\" % (epoch+1, epochs,\n",
    "                                                                    l2_epoch_validation,\n",
    "                                                                    l1_epoch_validation,\n",
    "                                                                    mape_epoch_validation,\n",
    "                                                                    g_loss,\n",
    "                                                                    elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train start 2020-03-02 18:36:41.934247\n",
      "[RUnet 1/130]  [mse: 31.958834] [mae: 18.269615] [mape: 14.882539] [G loss: 814.364380] time: 0:00:31.601739\n",
      "[RUnet 2/130]  [mse: 25.957943] [mae: 14.811441] [mape: 13.993809] [G loss: 568.150940] time: 0:00:54.233592\n",
      "[RUnet 3/130]  [mse: 23.273467] [mae: 13.453330] [mape: 14.235699] [G loss: 481.931000] time: 0:01:15.685566\n"
     ]
    }
   ],
   "source": [
    "train(X_train, epochs=130, batch_size=MAX_BATCH_SIZE, learn_rate=learn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unet.save_weights('./model/RUnet/unet_60epoch_18rmse.h5')\n",
    "# unet.load_weights('./model/RUnet/runet_rmse16.61_final/runet_forecast_16.61.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = unet.predict(X_test[:, :, :, 1:])\n",
    "y_true = X_test[:, :, :, :1]\n",
    "\n",
    "mape(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# every_rmse = np.sqrt(np.mean(np.square(y_true - y_pred), axis=0))\n",
    "# every_mae = np.mean(np.abs(y_true - y_pred), axis=0)\n",
    "# every_mape = np.mean((np.abs(y_true - y_pred)/y_true), axis=0)\n",
    "\n",
    "# import pickle\n",
    "# with open('./data/实验结果数据/runet/runet_everyObservationr_rmse.data','wb') as f:\n",
    "#     pickle.dump(every_rmse,f)\n",
    "    \n",
    "# with open('./data/实验结果数据/runet/runet_everyObservationr_mae.data','wb') as f:\n",
    "#     pickle.dump(every_mae,f)\n",
    "    \n",
    "# with open('./data/实验结果数据/runet/runet_everyObservationr_mape.data','wb') as f:\n",
    "#     pickle.dump(every_mape,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix = np.mean(y_true-y_pred, axis=0)\n",
    "# np.where(matrix==np.max(matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix[20][31]=0\n",
    "# np.where(matrix==np.max(matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# unet_rmse=[]\n",
    "# runet_rmse=[]\n",
    "\n",
    "# with open('./data/实验结果数据/unet/unet_everyObservationr_rmse.data','rb') as f:\n",
    "#     unet_rmse = pickle.load(f)\n",
    "\n",
    "# with open('./data/实验结果数据/runet/runet_everyObservationr_rmse.data','rb') as f:\n",
    "#     runet_rmse = pickle.load(f)\n",
    "\n",
    "# matrix = unet_rmse-runet_rmse\n",
    "\n",
    "# matrix[posX][posY]=-1\n",
    "# print(np.where(matrix==np.max(matrix))[0][0])\n",
    "# print(np.where(matrix==np.max(matrix))[1][0])\n",
    "# print(np.max(matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实验一 两日时序图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实验一\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib.patches import Ellipse\n",
    "# del mpl.font_manager.weight_dict['roman']\n",
    "# mpl.font_manager._rebuild()\n",
    "\n",
    "from matplotlib.font_manager import FontProperties\n",
    "font = FontProperties(fname=r\"c:\\windows\\fonts\\simsun.ttc\")\n",
    "fontsz = 16\n",
    "\n",
    "posX = 19\n",
    "posY = 25\n",
    "startX = 1220\n",
    "gapX = 192\n",
    "\n",
    "zero_line = np.random.randint(0, 1, (gapX,))\n",
    "\n",
    "y = y_true[:, posX, posY, :][startX: startX+gapX]\n",
    "yf = y_pred[:, posX, posY, :][startX: startX+gapX]\n",
    "x = np.linspace(0, len(y), len(y))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5.8))\n",
    "lines = plt.plot(x, y, x, yf, x,y-yf, x,zero_line)\n",
    "l1, l2, l3, l4 = lines\n",
    "\n",
    "plt.setp(lines, markersize=7, linewidth=1.34)\n",
    "plt.setp(l1, color='b', linestyle='--', marker='o')  # line1 is thick and red\n",
    "plt.setp(l2, color='r', linestyle='-', marker='x')  # line2 is thinner and green\n",
    "plt.setp(l3, color='k', linestyle='-', marker='.')  # line2 is thinner and green\n",
    "plt.setp(l4, color='k', linestyle='-')  # line2 is thinner and green\n",
    "\n",
    "plt.ylabel('交通量(辆/小时)', fontproperties=font, fontsize=fontsz)\n",
    "plt.xlabel('观测时间点(时间间隔15分钟)', fontproperties=font, fontsize=fontsz)\n",
    "# plt.ylabel('Traffic Volume/ veh/h', fontsize=fontsz)\n",
    "# plt.xlabel('Time Step(15min time interval)', fontsize=fontsz)\n",
    "ax.yaxis.grid(True)\n",
    "ax.xaxis.grid(True)\n",
    "y_major_locator=plt.MultipleLocator(200)\n",
    "ax.yaxis.set_major_locator(y_major_locator)\n",
    "\n",
    "qwe = range(0,2000,500)\n",
    "# plt.yticks(qwe, ('0', '500', '1000', '1500'))\n",
    "ax.legend(('真实值', '预测值', '误差'), prop=font, fontsize=fontsz-10, loc=1)\n",
    "\n",
    "# 椭圆\n",
    "ell1 = Ellipse(xy = (25.0, 700.0), width =10, height = 690, angle = 359.2, facecolor= 'white', edgecolor='k',linewidth=2,linestyle='--')\n",
    "ax.add_patch(ell1)\n",
    "ell2 = Ellipse(xy = (68.0, 870.0), width =35, height = 240, angle = 0, facecolor= 'white', edgecolor='y',linewidth=2,linestyle='--')\n",
    "ax.add_patch(ell2)\n",
    "ell3 = Ellipse(xy = (127.0, 900.0), width =15, height = 280, angle = 0, facecolor= 'white', edgecolor='y',linewidth=2,linestyle='--')\n",
    "ax.add_patch(ell3)\n",
    "\n",
    "# ax.legend(('Expected', 'Predicted', 'Error'), prop=font, loc=1)\n",
    "plt.rcParams.update({'font.size': fontsz})\n",
    "plt.rc('font',family='Times New Roman')\n",
    "# plt.savefig(\"./pic/毕设/两日预测Runet实验一.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "# del mpl.font_manager.weight_dict['roman']\n",
    "# mpl.font_manager._rebuild()\n",
    "\n",
    "from matplotlib.font_manager import FontProperties\n",
    "font = FontProperties(fname=r\"c:\\windows\\fonts\\simsun.ttc\")\n",
    "fontsz = 16\n",
    "\n",
    "\n",
    "posX = 21\n",
    "posY = 27\n",
    "startX = 1230\n",
    "gapX = 192\n",
    "\n",
    "zero_line = np.random.randint(0, 1, (gapX,))\n",
    "\n",
    "y = y_true[:, posX, posY, :][startX: startX+gapX]\n",
    "yf = y_pred[:, posX, posY, :][startX: startX+gapX]\n",
    "x = np.linspace(0, len(y), len(y))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5.8))\n",
    "lines = plt.plot(x, y, x, yf, x,y-yf, x,zero_line)\n",
    "l1, l2, l3, l4 = lines\n",
    "\n",
    "plt.setp(lines, markersize=7, linewidth=1.34)\n",
    "plt.setp(l1, color='b', linestyle='--', marker='o')  # line1 is thick and red\n",
    "plt.setp(l2, color='r', linestyle='-', marker='x')  # line2 is thinner and green\n",
    "plt.setp(l3, color='k', linestyle='-', marker='.')  # line2 is thinner and green\n",
    "plt.setp(l4, color='k', linestyle='-')  # line2 is thinner and green\n",
    "\n",
    "plt.ylabel('交通量(辆/小时)', fontproperties=font, fontsize=fontsz)\n",
    "plt.xlabel('观测时间点(时间间隔15分钟)', fontproperties=font, fontsize=fontsz)\n",
    "ax.yaxis.grid(True)\n",
    "ax.xaxis.grid(True)\n",
    "y_major_locator=plt.MultipleLocator(200)\n",
    "ax.yaxis.set_major_locator(y_major_locator)\n",
    "\n",
    "qwe = range(0,2000,500)\n",
    "# plt.yticks(qwe, ('0', '500', '1000', '1500'))\n",
    "ax.legend(('真实值', '预测值', '误差'), prop=font, fontsize=fontsz-10, loc=1)\n",
    "# ax.legend(('Expected', 'Predicted', 'Error'), prop=font, loc=1)\n",
    "plt.rcParams.update({'font.size': fontsz-2})\n",
    "plt.rc('font',family='Times New Roman')\n",
    "# plt.savefig(\"./pic/毕设/实验二两日预测runet.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "32*32空间预测图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as mp\n",
    "\n",
    "spacial_volume = (y_true)[startX+50].reshape(32,32)\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "# x = np.array([])\n",
    "# for i in range(32):\n",
    "#     tmp = np.ones(32)*i\n",
    "#     x = np.hstack((x,tmp))\n",
    "# y = np.arange(0,1024)%32\n",
    "x = np.arange(0, 32)\n",
    "y = np.arange(0, 32)\n",
    "\n",
    "# surf = ax.plot_surface(x, y, spacial_volume, cmap=cm.coolwarm,\n",
    "#                        linewidth=0, antialiased=False)\n",
    "# fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "axes3d = Axes3D(fig)\n",
    " \n",
    "X,Y = np.meshgrid(x,y)\n",
    "Z = np.sqrt(X**2+Y**2)\n",
    "\n",
    "surf = axes3d.plot_surface(X,Y ,spacial_volume, cmap=cm.coolwarm, cstride=1, rstride=1)\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测热力图\n",
    "from pylab import mpl\n",
    "\n",
    "font = FontProperties(fname=r\"c:\\windows\\fonts\\simsun.ttc\")\n",
    "fig, axe = plt.subplots(1, 1, figsize=(8, 8))\n",
    "\n",
    "img = axe.imshow((y_true)[startX].reshape(32,32), cmap ='coolwarm')\n",
    "cbar = fig.colorbar(img, shrink=0.82)\n",
    "cbar.set_label('交通量(辆/小时)', FontProperties=font, size=20)  \n",
    "# cbar.set_label('Traffic Volume/ veh/h', size=16)  \n",
    "# cbar.set_ticks([200, 400,600,800,1000,1200 ])\n",
    "# cbar.set_ticklabels(('200', '400','600','800','1000','1200'))\n",
    "\n",
    "# plt.rcParams['font.weight']= 'bold'\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "plt.rc('font',family='Times New Roman')\n",
    "# plt.savefig('./pic/毕设/6.27_0点交通矩阵真实.jpg', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测热力图\n",
    "from pylab import mpl\n",
    "\n",
    "font = FontProperties(fname=r\"c:\\windows\\fonts\\simsun.ttc\")\n",
    "fig, axe = plt.subplots(1, 1, figsize=(8, 8))\n",
    "\n",
    "img = axe.imshow((y_pred)[startX].reshape(32,32), cmap ='coolwarm')\n",
    "cbar = fig.colorbar(img, shrink=0.82)\n",
    "cbar.set_label('交通量(辆/小时)', FontProperties=font, size=20)  \n",
    "# cbar.set_label('Traffic Volume/ veh/h', size=16)  \n",
    "# cbar.set_ticks([200, 400,600,800,1000,1200 ])\n",
    "# cbar.set_ticklabels(('200', '400','600','800','1000','1200'))\n",
    "\n",
    "# plt.rcParams['font.weight']= 'bold'\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "plt.rc('font',family='Times New Roman')\n",
    "# plt.savefig('./pic/毕设/6.27_0点交通矩阵预测.jpg', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "路网采集点平均mape分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 路网采集点平均mape分布\n",
    "import seaborn as sns\n",
    "font = FontProperties(fname=r\"c:\\windows\\fonts\\simsun.ttc\")\n",
    "\n",
    "font_size=16\n",
    "plt.rcParams.update({'font.size': font_size})\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "x_labels=['']\n",
    "spacial_mape = ((np.mean(np.abs(y_true-y_pred)/y_true, axis=0)).reshape(1024))*100\n",
    "\n",
    "bplot = ax.boxplot(spacial_mape, sym='x', patch_artist=False, vert=True, showmeans=True, labels=x_labels, showfliers=False)\n",
    "# sns.violinplot(data=spacial_mape, palette=\"Set3\", bw=0.1, cut=1, linewidth=1)\n",
    "plt.ylabel('MAPE(%)', fontproperties=font, fontsize=font_size)\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "# plt.savefig('./pic/毕设/mape分析_runet箱图_实验一.jpg', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 箱图具体数据\n",
    "print('中位数'+ str(np.median(spacial_mape)))\n",
    "q1 = np.percentile(spacial_mape, 25)\n",
    "print('25%分位数'+ str(q1))\n",
    "q3 = np.percentile(spacial_mape, 75)\n",
    "print('75%分位数'+ str(q3))\n",
    "\n",
    "#四分位距IQR=Q3-Q1，那么上限=Q3+1.5IQR，下限=Q1-1.5IQR\n",
    "print('上限'+ str(q3+1.5*(q3-q1)))\n",
    "print('下限'+ str(q1-1.5*(q3-q1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(spacial_mape<12.01934589798499)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析mape最大值68%咋回事. 两个点1.LM466 [0][7]  2.AL3143 [27][28]\n",
    "np.where(spacial_mape.reshape(32,32)==np.max(spacial_mape.reshape(32,32)))\n",
    "(y_true[:,0,7,0]).max()\n",
    "(y_true[:,27,28,0]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(spacial_mape.reshape(32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最大最小值分10区间进行统计\n",
    "np.histogram(spacial_mape,bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacial_mape.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 路网采集点平均mape分布\n",
    "\n",
    "plt.rcParams.update({'font.size': font_size})\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "x_labels=['']\n",
    "# spacial_mape = (np.mean(np.abs(y_true-y_pred)/y_true, axis=0)).reshape(1024)\n",
    "\n",
    "sns.swarmplot(data=spacial_mape, size=5)\n",
    "\n",
    "ax.set_xticklabels(x_labels)\n",
    "plt.ylabel('MAPE(%)', fontproperties=font, fontsize=font_size)\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "# plt.savefig('./pic/毕设/mape分析_runet点图_实验一.jpg', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacial_rmse.mean(), spacial_rmse.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SRU-Net路网RMSE平均值\n",
    "# spacial_volume = (y_true)[startX+50].reshape(32*32)\n",
    "font = {'family': 'STSong',\n",
    "        'weight': 'normal',\n",
    "        'size': font_size\n",
    "        }\n",
    "plt.rcParams.update({'font.size': font_size})\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "spacial_rmse = np.sqrt(np.mean(np.square(y_true - y_pred), axis=0)).reshape(1024)\n",
    "x = np.array([])\n",
    "for i in range(32):\n",
    "    tmp = np.ones(32)*i\n",
    "    x = np.hstack((x,tmp))\n",
    "y = np.arange(0,1024)%32\n",
    "\n",
    "bottom = np.zeros_like(spacial_rmse)\n",
    "width = depth = 1\n",
    "ax.bar3d(x, y, bottom, width, depth, spacial_rmse, shade=True, color='r')\n",
    "\n",
    "ax.set_zlabel('RMSE ', fontdict=font)\n",
    "\n",
    "# plt.savefig('./pic/毕设/rmse路网bar_runet3d_实验二.jpg', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 路网采集点平均rmse分布\n",
    "\n",
    "plt.rcParams.update({'font.size': font_size})\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "x_labels=['']\n",
    "# spacial_mape = (np.mean(np.abs(y_true-y_pred)/y_true, axis=0)).reshape(1024)\n",
    "\n",
    "sns.swarmplot(data=spacial_rmse, size=5)\n",
    "\n",
    "ax.set_xticklabels(x_labels)\n",
    "plt.ylabel('RMSE', fontproperties=font, fontsize=font_size)\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "# plt.savefig('./pic/毕设/rmse分析_runet点图_实验二.jpg', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SRU-Net路网MAPE平均值\n",
    "from matplotlib import cm\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as mp\n",
    "from matplotlib.colors import LightSource\n",
    "\n",
    "# spacial_volume = (y_true)[startX+50].reshape(32*32)\n",
    "font = {'family': 'STSong',\n",
    "        'weight': 'normal',\n",
    "        'size': font_size-4\n",
    "        }\n",
    "plt.rcParams.update({'font.size': font_size-4})\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "x = np.array([])\n",
    "for i in range(32):\n",
    "    tmp = np.ones(32)*i\n",
    "    x = np.hstack((x,tmp))\n",
    "y = np.arange(0,1024)%32\n",
    "\n",
    "bottom = np.zeros_like(spacial_mape)\n",
    "width = depth = 1\n",
    "ax.bar3d(x, y, bottom, width, depth, spacial_mape, shade=True, color='r')\n",
    "\n",
    "ax.set_zlabel('MAPE(%)', fontdict=font)\n",
    "\n",
    "# plt.savefig('./pic/毕设/mape路网bar_runet3d_实验一.jpg', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SRU-Net路网MAE平均值\n",
    "# spacial_volume = (y_true)[startX+50].reshape(32*32)\n",
    "font = {'family': 'STSong',\n",
    "        'weight': 'normal',\n",
    "        'size': font_size-4\n",
    "        }\n",
    "plt.rcParams.update({'font.size': font_size-4})\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "spacial_mae = ((np.mean(np.abs(y_true-y_pred), axis=0)).reshape(1024))\n",
    "x = np.array([])\n",
    "for i in range(32):\n",
    "    tmp = np.ones(32)*i\n",
    "    x = np.hstack((x,tmp))\n",
    "y = np.arange(0,1024)%32\n",
    "\n",
    "bottom = np.zeros_like(spacial_mae)\n",
    "width = depth = 1\n",
    "ax.bar3d(x, y, bottom, width, depth, spacial_mae, shade=True, color='r')\n",
    "\n",
    "ax.set_zlabel('MAE  ', fontdict=font)\n",
    "\n",
    "# plt.savefig('./pic/毕设/mae路网bar_runet3d_实验一.jpg', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "# del mpl.font_manager.weight_dict['roman']\n",
    "# mpl.font_manager._rebuild()\n",
    "\n",
    "from matplotlib.font_manager import FontProperties\n",
    "font = FontProperties(fname=r\"c:\\windows\\fonts\\simsun.ttc\")\n",
    "fontsz = 16\n",
    "\n",
    "# posX = 21\n",
    "# posY = 27\n",
    "startX = 932\n",
    "gapX = 672\n",
    "\n",
    "zero_line = np.random.randint(0, 1, (gapX,))\n",
    "\n",
    "y = y_true[:, posX, posY, :][startX: startX+gapX]\n",
    "yf = y_pred[:, posX, posY, :][startX: startX+gapX]\n",
    "x = np.linspace(0, len(y), len(y))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "lines = plt.plot(x, y, x, yf, x,y-yf, x,zero_line)\n",
    "l1, l2, l3, l4 = lines\n",
    "\n",
    "plt.setp(lines, markersize=7, linewidth=1.34)\n",
    "plt.setp(l1, color='b', linestyle='--', marker='o')  # line1 is thick and red\n",
    "plt.setp(l2, color='r', linestyle='-', marker='x')  # line2 is thinner and green\n",
    "plt.setp(l3, color='k', linestyle='-', marker='.')  # line2 is thinner and green\n",
    "plt.setp(l4, color='k', linestyle='-')  # line2 is thinner and green\n",
    "\n",
    "plt.ylabel('交通量(辆/小时)', fontproperties=font, fontsize=fontsz)\n",
    "plt.xlabel('观测时间点(时间间隔15分钟)', fontproperties=font, fontsize=fontsz)\n",
    "ax.yaxis.grid(True)\n",
    "ax.xaxis.grid(True)\n",
    "y_major_locator=plt.MultipleLocator(200)\n",
    "ax.yaxis.set_major_locator(y_major_locator)\n",
    "\n",
    "qwe = range(0,2000,500)\n",
    "# plt.yticks(qwe, ('0', '500', '1000', '1500'))\n",
    "ax.legend(('真实值', '预测值', '误差'), prop=font, fontsize=fontsz-10, loc=1)\n",
    "# ax.legend(('Expected', 'Predicted', 'Error'), prop=font, loc=1)\n",
    "plt.rcParams.update({'font.size': fontsz-2})\n",
    "plt.rc('font',family='Times New Roman')\n",
    "# plt.savefig(\"./pic/毕设/实验一runet一周预测.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.sqrt(np.sum(np.mean(np.square(y - yf), axis=0))/1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('./wgan画图matrix偏差值.data','rb') as f:\n",
    "#     matrix_wgan = pickle.load(f)\n",
    "    \n",
    "# matrix_runet = np.mean(y_true[startX: startX+gapX]-y_pred[startX: startX+gapX], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_diff = np.abs(matrix_runet)-np.abs(matrix_wgan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_diff[posX][posY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_diff[posX][posY]=0\n",
    "max_may = np.where(matrix_diff==np.max(matrix_diff))\n",
    "\n",
    "posX = max_may[0][0]\n",
    "posY = max_may[1][0]\n",
    "\n",
    "posX, posY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "start_time = 1600\n",
    "y = y_true.reshape(-1,)[start_time: start_time+100]\n",
    "x = np.linspace(0, len(y), len(y))\n",
    "\n",
    "yi = y_pred.reshape(-1,)[start_time: start_time+100]\n",
    "xi = np.linspace(0, len(yi), len(yi))\n",
    "fig, ax = plt.subplots(figsize=(25, 10))\n",
    "# ax.plot(x, y, '.', linewidth=1, markersize=10)\n",
    "lines = plt.plot(xi, yi, 'k^--', x, y, 'ro-',linewidth=1, markersize=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yi = l2_validation\n",
    "xi = np.linspace(0, len(yi), len(yi))\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "lines = plt.plot(xi, yi, 'k^--', linewidth=1, markersize=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = lr_step\n",
    "x = np.linspace(0, len(y), len(y))\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "lines = plt.plot(x, y, 'ko-', linewidth=1, markersize=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
