{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import scipy\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import transform\n",
    "\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, concatenate, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D, Add, Subtract, ConvLSTM2D\n",
    "from keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D ,AveragePooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU, ELU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam, Nadam, RMSprop\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.merge import _Merge\n",
    "from keras.engine.topology import Layer\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "import gc\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, TensorBoard\n",
    "from keras import backend as K\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from keras.models import load_model  \n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载  预处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交通矩阵为 matrix_length*matrix_length\n",
    "matrix_length = 32\n",
    "\n",
    "matrix_df = pd.read_csv('./data/trafficV_M.csv', index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def createTrainArray(week_history_num=0, minute_history_num=0):\n",
    "#     week_delta_list = [pd.Timedelta(i+1, unit='W') for i in range(week_history_num)]\n",
    "#     minute_delta_list = [pd.Timedelta((i+1)*15, unit='m') for i in range(minute_history_num)]\n",
    "#     # 参考历史数据时间点list\n",
    "#     delta_list = week_delta_list+minute_delta_list\n",
    "#     print(delta_list)\n",
    "    \n",
    "#     set_up_time = pd.Timedelta(week_history_num, unit='W')\n",
    "#     # 根据历史数据选取多少，重新构建数据集\n",
    "#     # 相当于去除最开始week_history_num个周的数据，因为这些数据无法找到更前的数据\n",
    "#     train_df = matrix_df.truncate(before=matrix_df.index.min() + set_up_time)\n",
    "    \n",
    "#     train_ago_array_tuple = tuple([np.array(matrix_df.loc[train_df.index - i]).reshape(-1, matrix_length, matrix_length, 1) for i in delta_list])\n",
    "#     train_df = np.array(train_df).reshape(-1, matrix_length, matrix_length, 1)\n",
    "#     # concatenate保持 待修复数据在前，参考历史数据在后。与random_mask函数生成mask相一致\n",
    "#     train_array = np.concatenate((train_df,)+train_ago_array_tuple, axis=3)\n",
    "#     print(train_array.shape)\n",
    "#     return train_array\n",
    "\n",
    "\n",
    "\n",
    "def createTrainArray(week_history_num=0, minute_history_num=0):\n",
    "    week_delta_list = [pd.Timedelta(week_history_num-i, unit='W') for i in range(week_history_num)]\n",
    "    minute_delta_list = [pd.Timedelta((minute_history_num-i)*15, unit='m') for i in range(minute_history_num)]\n",
    "    # 参考历史数据时间点list\n",
    "    delta_list = minute_delta_list+week_delta_list\n",
    "    print(delta_list)\n",
    "    \n",
    "    set_up_time = pd.Timedelta(week_history_num, unit='W')\n",
    "    # 根据历史数据选取多少，重新构建数据集\n",
    "    # 相当于去除最开始week_history_num个周的数据，因为这些数据无法找到更前的数据\n",
    "    train_df = matrix_df.truncate(before=matrix_df.index.min() + set_up_time)\n",
    "    \n",
    "    train_ago_array_tuple = tuple([np.array(matrix_df.loc[train_df.index - i]).reshape(-1, matrix_length, matrix_length, 1) for i in delta_list])\n",
    "    train_df = np.array(train_df).reshape(-1, matrix_length, matrix_length, 1)\n",
    "    # concatenate保持 待修复数据在前，参考历史数据在后。与random_mask函数生成mask相一致\n",
    "    train_array = np.concatenate((train_df,)+train_ago_array_tuple, axis=3)\n",
    "    print(train_array.shape)\n",
    "    return train_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Timedelta('0 days 00:45:00'), Timedelta('0 days 00:30:00'), Timedelta('0 days 00:15:00'), Timedelta('14 days 00:00:00'), Timedelta('7 days 00:00:00')]\n",
      "(16032, 32, 32, 6)\n"
     ]
    }
   ],
   "source": [
    "week_history_num = 2\n",
    "minute_history_num = 3\n",
    "\n",
    "channel_num = week_history_num +minute_history_num +1\n",
    "smooth_time = channel_num-1\n",
    "\n",
    "# train_array为(16704, 32, 32, 3)，16704个矩阵，32*32采集点，3从上到下为当前时间，上一周，上一15min\n",
    "train_array = createTrainArray(week_history_num, minute_history_num)\n",
    "X_train, X_test = train_test_split(train_array, test_size = 0.1, random_state=42, shuffle=False)\n",
    "# X_train, X_val = train_test_split(train_array, test_size = 0.1, random_state=42, shuffle=False) # 不shuffle可用于查看数据正确性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14428, 32, 32, 6), (1604, 32, 32, 6))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225, 25)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_BATCH_SIZE = 64\n",
    "epoch_steps = X_train.shape[0] // MAX_BATCH_SIZE\n",
    "test_steps = X_test.shape[0] // MAX_BATCH_SIZE\n",
    "epoch_steps, test_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "def load_data(volume_matrix, batch_size=MAX_BATCH_SIZE):\n",
    "    n_batches=batch_size\n",
    "    len_of_matrix = len(volume_matrix)\n",
    "\n",
    "    batch_i = 0\n",
    "    while ((batch_i+1)*batch_size < len_of_matrix):\n",
    "        batch_matrix = volume_matrix[batch_i*batch_size: (batch_i+1)*batch_size]\n",
    "        true_volume, history_volume = batch_matrix[:, :, :, :1], batch_matrix[:, :, :, 1:]\n",
    "#         history_volume = normalization(history_volume)\n",
    "        batch_i+=1\n",
    "\n",
    "        yield true_volume, history_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def l2(y_true, y_pred):\n",
    "    return math.sqrt(np.sum(np.mean(np.square(y_true - y_pred), axis=0))/1024)\n",
    "\n",
    "def l1(y_true, y_pred):\n",
    "    return np.sum(np.mean(np.abs(y_true - y_pred), axis=0))/(matrix_length*matrix_length)\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    return np.sum(np.mean((np.abs(y_true - y_pred)/y_true)*100, axis=0))/(matrix_length*matrix_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算D输出valid大小（PatchGAN）\n",
    "patch = 4\n",
    "disc_patch = (patch, patch, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (3, 3)\n",
    "g_filters_base = 32\n",
    "DropoutRatio = 0\n",
    "learn_rate_g = 0.0002\n",
    "learn_rate_d = 0.001\n",
    "learn_rate_c = 0.0002\n",
    "\n",
    "# channels = 3\n",
    "matrix_shape = (matrix_length, matrix_length, channel_num)\n",
    "true_volume_shape = (matrix_length, matrix_length, 1)\n",
    "history_volume_shape = (matrix_length, matrix_length, channel_num-1)\n",
    "\n",
    "kernel_init = 'glorot_uniform'\n",
    "bias_init = 'zeros'\n",
    "kernel_regul = regularizers.l2(1)\n",
    "activity_regul = regularizers.l2(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet block\n",
    "def identity_block(X, filters, f):\n",
    "\n",
    "    F1, F2 = filters\n",
    "\n",
    "    X_shortcut = X\n",
    "\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(filters=F1, kernel_size=(f, f), strides=(1, 1), padding='same',\n",
    "               kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "              kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(X)\n",
    "\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same',\n",
    "               kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "              kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(X)\n",
    "\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X\n",
    "\n",
    "# ENCODER\n",
    "def encoder_layer(img_in, filters, kernel_size, bn=True, resid=True):\n",
    "    # conv = Conv2D(filters=filters, kernel_size=kernel_size, strides=(1, 1), padding='same')(img_in)\n",
    "    conv = img_in\n",
    "    if bn:\n",
    "        conv = BatchNormalization()(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "#             conv = MaxPooling2D((2, 2))(conv)\n",
    "\n",
    "\n",
    "    if resid:\n",
    "        conv = identity_block(conv, (filters, filters), kernel_size)\n",
    "\n",
    "    return conv\n",
    "\n",
    "# DECODER\n",
    "def decoder_layer(img_in, e_conv, filters, kernel_size, bn=True, resid=True):\n",
    "    # up_img = UpSampling2D(size=(2,2))(img_in)\n",
    "    up_img = img_in\n",
    "    concat_img = Concatenate(axis=3)([e_conv,up_img])\n",
    "    conv = Conv2D(filters=filters, kernel_size=kernel_size, strides=(1, 1), padding='same',\n",
    "                  kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "              kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(concat_img)\n",
    "    if bn:\n",
    "        conv = BatchNormalization()(conv)\n",
    "    conv = LeakyReLU(alpha=0)(conv)\n",
    "\n",
    "    if resid:\n",
    "        conv = identity_block(conv, (filters, filters), kernel_size)\n",
    "    return conv\n",
    "\n",
    "\n",
    "\n",
    "def build_generator():      \n",
    "\n",
    "    # INPUTS\n",
    "    history_traffic_volume = Input(shape=history_volume_shape)\n",
    "\n",
    "    # kernel_init = initializers.he_normal()\n",
    "    # bias_init = initializers.he_normal()\n",
    "    kernel_init = 'glorot_uniform'\n",
    "    bias_init = 'zeros'\n",
    "\n",
    "#         kernel_init = initializers.he_uniform()\n",
    "#         bias_init = 'Orthogonal'\n",
    "    kernel_regul = regularizers.l2(1)\n",
    "    activity_regul = regularizers.l2(1)\n",
    "\n",
    "    filters_base = 32\n",
    "    e_conv1_head = Conv2D(filters=filters_base, kernel_size=3, strides=1, padding='same',\n",
    "                          kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(history_traffic_volume)\n",
    "#         e_conv1_head = Conv2D(filters=filters_base*1, kernel_size=3, strides=1, padding='same',\n",
    "#                               kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "#                       kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(e_conv1_head)\n",
    "    e_conv1_tail = AveragePooling2D((2, 2))(e_conv1_head)\n",
    "#     e_conv1_tail = Dropout(DropoutRatio/2)(e_conv1_tail)\n",
    "    e_conv1 = encoder_layer(e_conv1_tail, filters_base, 3, bn=False)\n",
    "\n",
    "    e_conv2_head = Conv2D(filters=filters_base*2, kernel_size=3, strides=1, padding='same',\n",
    "                          kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(e_conv1)\n",
    "    e_conv2_tail = AveragePooling2D((2, 2))(e_conv2_head)\n",
    "#     e_conv2_tail = Dropout(DropoutRatio)(e_conv2_tail)\n",
    "    e_conv2 = encoder_layer(e_conv2_tail, filters_base*2, 3)\n",
    "\n",
    "    e_conv3_head = Conv2D(filters=filters_base*4, kernel_size=3, strides=1, padding='same',\n",
    "                          kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(e_conv2)\n",
    "    e_conv3_tail = AveragePooling2D((2, 2))(e_conv3_head)\n",
    "    \n",
    "    # 加drop引入噪声\n",
    "#     e_conv3_tail = Dropout(DropoutRatio)(e_conv3_tail)\n",
    "    \n",
    "    d_conv3_head = encoder_layer(e_conv3_tail, filters_base*4, 3)\n",
    "    resid1 = Subtract()([e_conv3_tail, d_conv3_head])\n",
    "    d_conv3_tail = UpSampling2D(size=(2, 2))(resid1)\n",
    "#     d_conv3_tail = Dropout(DropoutRatio)(d_conv3_tail)\n",
    "\n",
    "\n",
    "    d_conv4_head = decoder_layer(d_conv3_tail, e_conv3_head, filters_base*2, 3)\n",
    "    resid2 = Subtract()([d_conv4_head, e_conv2_tail])\n",
    "    d_conv4_tail = UpSampling2D(size=(2, 2))(resid2)\n",
    "#     d_conv4_tail = Dropout(DropoutRatio)(d_conv4_tail)\n",
    "\n",
    "\n",
    "    d_conv5_head = decoder_layer(d_conv4_tail, e_conv2_head, filters_base*1, 3)\n",
    "    resid3 = Subtract()([d_conv5_head, e_conv1_tail])\n",
    "    d_conv5_tail = UpSampling2D(size=(2, 2))(resid3)\n",
    "#     d_conv5_tail = Dropout(DropoutRatio)(d_conv5_tail)\n",
    "\n",
    "    d_conv6_head = decoder_layer(d_conv5_tail, e_conv1_head, filters_base//2, 3, bn=False)\n",
    "\n",
    "\n",
    "    outputs = Conv2D(1, 1, activation = 'relu', kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(d_conv6_head)\n",
    "\n",
    "    # Setup the model inputs / outputs\n",
    "    model = Model(inputs=history_traffic_volume, outputs=outputs)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer = Adam(lr=learn_rate_g),\n",
    "        loss='mse'\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty_loss(y_true, y_pred, averaged_samples):\n",
    "    \"\"\"\n",
    "    Computes gradient penalty based on prediction and weighted real / fake samples\n",
    "    \"\"\"\n",
    "    gradients = K.gradients(y_pred, averaged_samples)[0]\n",
    "    # compute the euclidean norm by squaring ...\n",
    "    gradients_sqr = K.square(gradients)\n",
    "    #   ... summing over the rows ...\n",
    "    gradients_sqr_sum = K.sum(gradients_sqr,\n",
    "                              axis=np.arange(1, len(gradients_sqr.shape)))\n",
    "    #   ... and sqrt\n",
    "    gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
    "    # compute lambda * (1 - ||grad||)^2 still for each single sample\n",
    "    gradient_penalty = K.square(1 - gradient_l2_norm)\n",
    "    # return the mean as loss over all the batch samples\n",
    "    return K.mean(gradient_penalty)\n",
    "\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)\n",
    "\n",
    "def neg_wasserstein_loss(y_true, y_pred):\n",
    "    return -K.mean(y_true * y_pred)\n",
    "\n",
    "def neg_mean_squared_error(y_true, y_pred):\n",
    "    return -K.mean(K.square(y_pred - y_true), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomWeightedAverage(_Merge):\n",
    "    \"\"\"Provides a (random) weighted average between real and generated image samples\"\"\"\n",
    "    def _merge_function(self, inputs):\n",
    "        alpha = K.random_uniform((64, 1, 1, 1))\n",
    "        return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])\n",
    "    \n",
    "    \n",
    "class GradNorm(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(GradNorm, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(GradNorm, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        vaild_interpolated, interpolation_volume = inputs\n",
    "        grads = K.gradients(vaild_interpolated, interpolation_volume)\n",
    "        assert len(grads) == 1\n",
    "        grad = grads[0]\n",
    "#         a = K.sqrt(K.sum(K.batch_flatten(K.square(grad)), axis=1, keepdims=True))\n",
    "        return grad\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (MAX_BATCH_SIZE,) + true_volume_shape\n",
    "    \n",
    "    def compute_output_shape(self, input_shapes):\n",
    "        return (MAX_BATCH_SIZE,) + true_volume_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_filters_base = 32\n",
    "# Input shape\n",
    "\n",
    "# Discriminator\n",
    "def build_spatial_discriminator():\n",
    "    def d_layer(layer_input, filters, f_size=3, bn=True, stride=1):\n",
    "        \"\"\"Discriminator layer\"\"\"\n",
    "        d = Conv2D(filters, kernel_size=f_size, strides=stride, padding='same', kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(layer_input)\n",
    "        if bn:\n",
    "            d = BatchNormalization()(d)\n",
    "        d = LeakyReLU(alpha=0.1)(d)\n",
    "        return d\n",
    "    \n",
    "    matrix_A = Input(shape=true_volume_shape)\n",
    "    matrix_B = Input(shape=history_volume_shape)\n",
    "\n",
    "    # Concatenate image and conditioning image生成输入对象\n",
    "    combined_matrix = Concatenate(axis=-1)([matrix_A, matrix_B])\n",
    "\n",
    "    d1 = d_layer(combined_matrix, d_filters_base, bn=False)\n",
    "    d2 = d_layer(d1, d_filters_base*2, stride=2)\n",
    "#     d2 = AveragePooling2D((2, 2))(d2)\n",
    "    d3 = d_layer(d2, d_filters_base*4, stride=2)\n",
    "#     d3 = AveragePooling2D((2, 2))(d3)\n",
    "    d4 = d_layer(d3, d_filters_base*8, stride=2)\n",
    "#     d4 = AveragePooling2D((2, 2))(d4)\n",
    "    d4 = d_layer(d4, d_filters_base*4)\n",
    "    d5 = d_layer(d4, d_filters_base*2)\n",
    "    d6 = d_layer(d5, d_filters_base*1)\n",
    "    \n",
    "    validity = Conv2D(1, kernel_size=3, strides=1, padding='same')(d6)\n",
    "    model = Model([matrix_A, matrix_B], validity)\n",
    "#     model.compile(optimizer=RMSprop(lr=learn_rate_d), loss='mse', metrics=['mse']) \n",
    "    model.compile(optimizer=Adam(lr=learn_rate_d), loss=wasserstein_loss, metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def build_temporal_discriminator():\n",
    "    def d_layer(layer_input, filters, f_size=3, bn=True, stride=1):\n",
    "        \"\"\"Discriminator layer\"\"\"\n",
    "        d = Conv2D(filters, kernel_size=f_size, strides=stride, padding='same', kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(layer_input)\n",
    "        if bn:\n",
    "            d = BatchNormalization()(d)\n",
    "        d = LeakyReLU(alpha=0.1)(d)\n",
    "        return d\n",
    "\n",
    "    matrix_A = Input(shape=true_volume_shape)\n",
    "    matrix_B = Input(shape=history_volume_shape)\n",
    "\n",
    "    # Concatenate image and conditioning image生成输入对象\n",
    "    combined_matrix = Concatenate(axis=-1)([matrix_B, matrix_A])\n",
    "    combined_matrix = Reshape((6, 32, 32, 1))(combined_matrix)\n",
    "    \n",
    "    cl1 = ConvLSTM2D(filters=d_filters_base, kernel_size=(3, 3), strides=2, \n",
    "                     padding='same', return_sequences=True)(combined_matrix)\n",
    "    cl1 = BatchNormalization()(cl1)\n",
    "\n",
    "#     cl2 = ConvLSTM2D(filters=d_filters_base*2, kernel_size=(3, 3), strides=2,\n",
    "#                        padding='same', return_sequences=True)(cl1)\n",
    "#     cl2 = BatchNormalization()(cl2)\n",
    "\n",
    "    cl3 = ConvLSTM2D(filters=d_filters_base, kernel_size=(3, 3), strides=2,\n",
    "                       padding='same', return_sequences=False)(cl1)\n",
    "    cl3 = BatchNormalization()(cl3)\n",
    "    \n",
    "    cl3 = d_layer(cl3, d_filters_base//2, stride=2)\n",
    "    cl3 = d_layer(cl3, d_filters_base//4)\n",
    "    \n",
    "    validity = Conv2D(1, kernel_size=3, strides=1, padding='same')(cl3)\n",
    "    \n",
    "    model = Model([matrix_A, matrix_B], validity)\n",
    "    model.compile(optimizer=RMSprop(lr=learn_rate_d), loss='mse', metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "temporal_discriminator = build_temporal_discriminator()\n",
    "spatial_discriminator = build_spatial_discriminator()\n",
    "generator = build_generator()\n",
    "\n",
    "\n",
    "true_volume = Input(shape=true_volume_shape)\n",
    "history_volume = Input(shape=history_volume_shape)\n",
    "interpolation_volume = Input(shape=true_volume_shape)\n",
    "\n",
    "forecast_volume = generator(history_volume)\n",
    "\n",
    "temporal_discriminator.trainable = False\n",
    "spatial_discriminator.trainable = False\n",
    "temporal_true_vaild = temporal_discriminator([true_volume, history_volume])\n",
    "temporal_fake_vaild = temporal_discriminator([forecast_volume, history_volume])\n",
    "spatial_true_vaild = spatial_discriminator([true_volume, history_volume])\n",
    "spatial_fake_vaild = spatial_discriminator([forecast_volume, history_volume])\n",
    "\n",
    "\n",
    "# gp = gradient_penalty_loss(true_volume, forecast_volume, interpolation_volume)\n",
    "temporal_norm = GradNorm()([temporal_discriminator([interpolation_volume, history_volume]), interpolation_volume])\n",
    "spatial_norm = GradNorm()([spatial_discriminator([interpolation_volume, history_volume]), interpolation_volume])\n",
    "\n",
    "combined = Model(inputs=[true_volume, history_volume, interpolation_volume],\n",
    "                    outputs=[temporal_true_vaild, temporal_fake_vaild, temporal_norm, spatial_true_vaild, spatial_fake_vaild, spatial_norm, forecast_volume])\n",
    "# combined.compile(loss=[wasserstein_loss,\n",
    "#                         neg_wasserstein_loss,\n",
    "#                        neg_mean_squared_error,\n",
    "#                        wasserstein_loss,\n",
    "#                         neg_wasserstein_loss,\n",
    "#                        neg_mean_squared_error,\n",
    "#                         'mse'],\n",
    "#                         optimizer=RMSprop(lr=learn_rate_c),\n",
    "#                         loss_weights=[1, 1, 5, 1, 1, 5, 10])\n",
    "#按照目标函数，loss最小化\n",
    "combined.compile(loss=[neg_wasserstein_loss,\n",
    "                        wasserstein_loss,\n",
    "                       'mse',\n",
    "                       neg_wasserstein_loss,\n",
    "                        wasserstein_loss,\n",
    "                       'mse',\n",
    "                        'mse'],\n",
    "                        optimizer=RMSprop(lr=learn_rate_c),\n",
    "                        loss_weights=[1, 1, 3, 1, 1, 3, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_step = []\n",
    "l2_validation = []\n",
    "\n",
    "def train(train_matrix, epochs, batch_size=MAX_BATCH_SIZE, learn_rate=0.01):\n",
    "\n",
    "    min_mse = 999\n",
    "    start_time = datetime.datetime.now()\n",
    "    print(\"train start \"+str(start_time))\n",
    "\n",
    "    # Adversarial loss ground truths\n",
    "#     valid = np.ones((MAX_BATCH_SIZE,) + disc_patch)+np.random.rand(MAX_BATCH_SIZE, patch, patch, 1)/5\n",
    "#     fake = np.zeros((MAX_BATCH_SIZE,) + disc_patch)+np.random.rand(MAX_BATCH_SIZE, patch, patch, 1)/5\n",
    "    valid = np.ones((MAX_BATCH_SIZE,) + disc_patch)\n",
    "    fake = -np.ones((MAX_BATCH_SIZE,) + disc_patch)\n",
    "    dummy = np.ones((MAX_BATCH_SIZE,) + true_volume_shape)\n",
    "\n",
    "    #　周期修改学习率　https://zhuanlan.zhihu.com/p/52084949\n",
    "    for epoch in range(epochs):\n",
    "        if epoch>=80 and epoch % 5 == 0 and epoch != 0:\n",
    "            generator_lr = K.get_value(generator.optimizer.lr)\n",
    "            temporal_discriminator_lr = K.get_value(temporal_discriminator.optimizer.lr)\n",
    "            spatial_discriminator_lr = K.get_value(spatial_discriminator.optimizer.lr)\n",
    "            combined_lr = K.get_value(combined.optimizer.lr)\n",
    "            if generator_lr>0.0001:\n",
    "                K.set_value(generator.optimizer.lr, generator_lr*0.9)\n",
    "            if temporal_discriminator_lr>0.0005:\n",
    "                K.set_value(temporal_discriminator.optimizer.lr, temporal_discriminator_lr*0.9)\n",
    "                K.set_value(spatial_discriminator.optimizer.lr, spatial_discriminator_lr*0.9)\n",
    "            if combined_lr>0.0001:\n",
    "                K.set_value(combined.optimizer.lr, combined_lr*0.9)\n",
    "\n",
    "        for batch_i, (true_volume, history_volume) in enumerate(load_data(train_matrix,batch_size)):\n",
    "            # true_volume 真实待预测路网交通量  history_volume 路网交通量历史数据\n",
    "            #  训练 Discriminator\n",
    "\n",
    "            # 根据历史数据生成预测数据\n",
    "            forecast_volume = generator.predict(history_volume)\n",
    "\n",
    "            epsilon = np.random.uniform(0, 1, size=(MAX_BATCH_SIZE,1,1,1))\n",
    "            interpolation_volume = epsilon*true_volume + (1-epsilon)*forecast_volume\n",
    "            # 训练 the discriminators (original images = real / generated = Fake)\n",
    "            temporal_discriminator.trainable = True\n",
    "            dt_loss_real = temporal_discriminator.train_on_batch([true_volume, history_volume], valid)\n",
    "            dt_loss_fake = temporal_discriminator.train_on_batch([forecast_volume, history_volume], fake)\n",
    "            temporal_discriminator.trainable = False\n",
    "            spatial_discriminator.trainable = True\n",
    "            ds_loss_real = spatial_discriminator.train_on_batch([true_volume, history_volume], valid)\n",
    "            ds_loss_fake = spatial_discriminator.train_on_batch([forecast_volume, history_volume], fake)\n",
    "            spatial_discriminator.trainable = False\n",
    "            dt_loss = 0.5 * np.add(dt_loss_real, dt_loss_fake)\n",
    "            ds_loss = 0.5 * np.add(ds_loss_real, ds_loss_fake)\n",
    "            \n",
    "            #  训练 Generator\n",
    "            g_loss = combined.train_on_batch([true_volume, history_volume, interpolation_volume], [valid, fake, dummy, valid, fake, dummy, true_volume])\n",
    "\n",
    "            elapsed_time = datetime.datetime.now() - start_time\n",
    "\n",
    "        # Plot the progress\n",
    "        y_pred = generator.predict(X_test[:, :, :, 1:])\n",
    "        y_true = X_test[:, :, :, :1]\n",
    "\n",
    "        l2_epoch_validation = l2(y_true, y_pred)\n",
    "        l1_epoch_validation = l1(y_true, y_pred)\n",
    "        \n",
    "        y_pred[y_true==0] += 1\n",
    "        y_true[y_true==0] += 1\n",
    "        mape_epoch_validation = mape(y_true, y_pred)\n",
    "        \n",
    "#         lr_step.append(K.get_value(discriminator.optimizer.lr))\n",
    "        if(l2_epoch_validation<12 and l2_epoch_validation < min_mse):\n",
    "            generator.save_weights('./model/wganpg/tmp/min_generator_wganpg.h5')\n",
    "            spatial_discriminator.save_weights('./model/wganpg/tmp/min_spatial_discriminator_wganpg.h5')\n",
    "            temporal_discriminator.save_weights('./model/wganpg/tmp/min_temporal_discriminator_wganpg.h5')\n",
    "            combined.save_weights('./model/wganpg/tmp/min_combined_wganpg.h5')\n",
    "            min_mse = l2_epoch_validation\n",
    "            \n",
    "        l2_validation.append(l2_epoch_validation)\n",
    "        if epoch%1==0:\n",
    "#             print(\"unet lr:\"+ str(K.get_value(unet.optimizer.lr)))\n",
    "            print (\"[Epoch %d/%d][Dt: %f, Ds: %f, mse: %f, mae: %f, mape: %f, G loss: %f] time: %s\" % (epoch+1, epochs,\n",
    "                                                                    dt_loss[0], ds_loss[0], l2_epoch_validation,\n",
    "                                                                    l1_epoch_validation,\n",
    "                                                                    mape_epoch_validation,\n",
    "                                                                    g_loss[0],\n",
    "                                                                    elapsed_time))\n",
    "        # If at show interval => show generated image samples\n",
    "#             if epoch % show_interval == 0:\n",
    "#                     show_images(dataset_name,epoch, batch_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train start 2019-12-13 11:52:15.653790\n",
      "[Epoch 1/200][Dt: 0.087768, Ds: 0.804275, mse: 75.807156, mae: 53.580315, mape: 21.762852, G loss: 41907.261719] time: 0:03:23.426426\n",
      "[Epoch 2/200][Dt: 0.131814, Ds: 0.069421, mse: 60.193502, mae: 43.329440, mape: 18.248831, G loss: 27267.824219] time: 0:06:13.666680\n",
      "[Epoch 3/200][Dt: 0.094847, Ds: 0.079040, mse: 51.453246, mae: 36.881868, mape: 15.692650, G loss: 21023.427734] time: 0:09:03.795792\n",
      "[Epoch 4/200][Dt: 0.106003, Ds: 0.809397, mse: 46.345786, mae: 33.024109, mape: 14.156581, G loss: 16910.138672] time: 0:11:53.634949\n",
      "[Epoch 5/200][Dt: 0.051857, Ds: 0.198236, mse: 44.857876, mae: 32.221896, mape: 13.726537, G loss: 14721.021484] time: 0:14:44.680954\n",
      "[Epoch 6/200][Dt: 0.055700, Ds: 0.485315, mse: 43.804293, mae: 31.805420, mape: 13.585369, G loss: 13034.823242] time: 0:17:38.016812\n",
      "[Epoch 7/200][Dt: 0.745559, Ds: 0.444717, mse: 45.604877, mae: 33.220363, mape: 13.844289, G loss: 12179.185547] time: 0:20:30.225165\n",
      "[Epoch 8/200][Dt: 0.045178, Ds: 0.347540, mse: 41.989884, mae: 30.388197, mape: 12.691100, G loss: 9322.868164] time: 0:23:22.260239\n",
      "[Epoch 9/200][Dt: 0.044182, Ds: 0.387951, mse: 26.697147, mae: 17.543194, mape: 8.551201, G loss: 6772.464844] time: 0:26:13.818010\n",
      "[Epoch 10/200][Dt: 0.035371, Ds: 0.289856, mse: 39.716648, mae: 28.339478, mape: 11.474460, G loss: 7004.315430] time: 0:29:06.113117\n",
      "[Epoch 11/200][Dt: 0.456443, Ds: 0.117236, mse: 31.491716, mae: 21.801636, mape: 9.152239, G loss: 5271.977051] time: 0:31:57.483936\n",
      "[Epoch 12/200][Dt: 0.158217, Ds: 0.459345, mse: 28.650706, mae: 19.536020, mape: 8.338794, G loss: 4791.560547] time: 0:34:49.507769\n",
      "[Epoch 13/200][Dt: 1.592738, Ds: 0.242082, mse: 34.761392, mae: 24.585609, mape: 10.051311, G loss: 5687.318848] time: 0:37:40.654320\n",
      "[Epoch 14/200][Dt: 0.243673, Ds: 0.262275, mse: 18.033829, mae: 10.803410, mape: 5.667559, G loss: 4292.091309] time: 0:40:33.289786\n",
      "[Epoch 15/200][Dt: 0.303006, Ds: 0.021450, mse: 17.220369, mae: 10.213622, mape: 5.412182, G loss: 3992.615479] time: 0:43:24.777032\n",
      "[Epoch 16/200][Dt: 0.040129, Ds: 0.103076, mse: 27.284013, mae: 18.730549, mape: 8.083017, G loss: 4361.650879] time: 0:46:16.088572\n",
      "[Epoch 17/200][Dt: 0.175430, Ds: 0.068994, mse: 17.019085, mae: 10.085616, mape: 5.313651, G loss: 3810.777344] time: 0:49:06.632352\n",
      "[Epoch 18/200][Dt: 0.263952, Ds: 0.075092, mse: 19.850132, mae: 12.686619, mape: 6.358529, G loss: 4734.004395] time: 0:51:58.031073\n",
      "[Epoch 19/200][Dt: 0.040991, Ds: 0.212795, mse: 16.247103, mae: 9.723094, mape: 5.235333, G loss: 3536.518066] time: 0:54:48.525866\n",
      "[Epoch 20/200][Dt: 0.041628, Ds: 0.108799, mse: 17.495281, mae: 10.846084, mape: 5.657872, G loss: 3815.229492] time: 0:57:39.391749\n",
      "[Epoch 21/200][Dt: 1.355046, Ds: 1.046546, mse: 16.180769, mae: 9.809948, mape: 5.323830, G loss: 3485.758545] time: 1:00:29.162456\n",
      "[Epoch 22/200][Dt: 0.046334, Ds: 0.027374, mse: 34.575753, mae: 24.905794, mape: 10.171998, G loss: 5695.356445] time: 1:03:18.476061\n",
      "[Epoch 23/200][Dt: 0.051858, Ds: 0.064665, mse: 18.813540, mae: 12.058389, mape: 6.082661, G loss: 4191.780273] time: 1:06:08.200840\n",
      "[Epoch 24/200][Dt: 0.193166, Ds: 0.029269, mse: 16.484152, mae: 10.168875, mape: 5.471910, G loss: 3508.453369] time: 1:08:58.125775\n",
      "[Epoch 25/200][Dt: 0.042482, Ds: 0.298903, mse: 16.311158, mae: 9.984677, mape: 5.264222, G loss: 3395.789551] time: 1:11:48.316064\n",
      "[Epoch 26/200][Dt: 0.035745, Ds: 0.620524, mse: 18.268198, mae: 11.651797, mape: 5.901425, G loss: 3978.988281] time: 1:14:38.362918\n",
      "[Epoch 27/200][Dt: 0.055366, Ds: 0.045266, mse: 15.101022, mae: 9.068897, mape: 4.914194, G loss: 3103.255859] time: 1:17:28.673952\n",
      "[Epoch 28/200][Dt: 0.080883, Ds: 0.010194, mse: 15.413961, mae: 9.245483, mape: 4.954969, G loss: 3153.614502] time: 1:20:18.589727\n",
      "[Epoch 29/200][Dt: 0.052269, Ds: 0.039266, mse: 14.834949, mae: 8.948776, mape: 4.984972, G loss: 2956.473877] time: 1:23:08.125141\n",
      "[Epoch 30/200][Dt: 0.082919, Ds: 0.088941, mse: 17.279420, mae: 10.889938, mape: 5.437227, G loss: 3531.091309] time: 1:25:58.332049\n",
      "[Epoch 31/200][Dt: 0.030993, Ds: 0.141146, mse: 25.643337, mae: 17.870758, mape: 7.506574, G loss: 4481.976074] time: 1:28:47.333092\n",
      "[Epoch 32/200][Dt: 0.028992, Ds: 0.061140, mse: 16.724659, mae: 10.503630, mape: 5.161976, G loss: 2921.564941] time: 1:31:37.252816\n",
      "[Epoch 33/200][Dt: 0.030589, Ds: 0.101851, mse: 14.466740, mae: 8.567085, mape: 4.689983, G loss: 2824.642090] time: 1:34:26.105149\n",
      "[Epoch 34/200][Dt: 0.021226, Ds: 0.061225, mse: 16.387414, mae: 10.281742, mape: 5.316884, G loss: 2838.591553] time: 1:37:14.486078\n",
      "[Epoch 35/200][Dt: 0.038212, Ds: 0.027147, mse: 14.793089, mae: 8.877362, mape: 4.727967, G loss: 2858.929932] time: 1:40:02.954339\n",
      "[Epoch 36/200][Dt: 0.035492, Ds: 0.160882, mse: 16.173645, mae: 10.141025, mape: 5.442515, G loss: 2854.653809] time: 1:42:55.588014\n",
      "[Epoch 37/200][Dt: 0.029989, Ds: 0.292813, mse: 20.127453, mae: 13.467325, mape: 6.760308, G loss: 3929.482422] time: 1:45:47.465172\n",
      "[Epoch 38/200][Dt: 0.023505, Ds: 0.048439, mse: 18.023224, mae: 11.630848, mape: 5.974496, G loss: 3291.676270] time: 1:48:41.262872\n",
      "[Epoch 39/200][Dt: 0.026444, Ds: 0.048837, mse: 25.264168, mae: 17.839848, mape: 7.837960, G loss: 4368.507812] time: 1:51:33.052488\n",
      "[Epoch 40/200][Dt: 0.036898, Ds: 0.014019, mse: 15.835393, mae: 9.969443, mape: 5.169453, G loss: 2621.187256] time: 1:54:28.148622\n",
      "[Epoch 41/200][Dt: 0.025978, Ds: 0.022775, mse: 14.439392, mae: 8.680688, mape: 4.741733, G loss: 2646.215820] time: 1:57:25.636330\n",
      "[Epoch 42/200][Dt: 0.029009, Ds: 0.007959, mse: 14.009200, mae: 8.545201, mape: 4.845449, G loss: 2534.234375] time: 2:00:21.635829\n",
      "[Epoch 43/200][Dt: 0.043837, Ds: 0.000409, mse: 14.235139, mae: 8.498898, mape: 4.567252, G loss: 2497.998291] time: 2:03:24.568763\n",
      "[Epoch 44/200][Dt: 0.030407, Ds: 0.000165, mse: 14.154056, mae: 8.549370, mape: 4.877735, G loss: 2516.826904] time: 2:06:27.913870\n",
      "[Epoch 45/200][Dt: 0.021266, Ds: 0.000165, mse: 15.001510, mae: 9.351756, mape: 5.026101, G loss: 2461.180908] time: 2:09:30.288576\n",
      "[Epoch 46/200][Dt: 0.034285, Ds: 0.000148, mse: 14.212234, mae: 8.428592, mape: 4.612850, G loss: 2375.482422] time: 2:12:33.916736\n",
      "[Epoch 47/200][Dt: 0.020695, Ds: 0.000289, mse: 16.694467, mae: 10.603187, mape: 5.199577, G loss: 2463.615234] time: 2:15:36.304554\n",
      "[Epoch 48/200][Dt: 0.084173, Ds: 0.000211, mse: 13.726818, mae: 8.179549, mape: 4.465615, G loss: 2290.273193] time: 2:18:37.649645\n",
      "[Epoch 49/200][Dt: 0.022115, Ds: 0.000395, mse: 13.890330, mae: 8.330884, mape: 4.489261, G loss: 2271.528076] time: 2:21:31.669489\n",
      "[Epoch 50/200][Dt: 0.021507, Ds: 0.000370, mse: 13.686919, mae: 8.197326, mape: 4.506211, G loss: 2245.088379] time: 2:24:24.429717\n",
      "[Epoch 51/200][Dt: 0.024807, Ds: 0.000796, mse: 14.922440, mae: 9.051939, mape: 4.925131, G loss: 2468.141602] time: 2:27:17.819691\n",
      "[Epoch 52/200][Dt: 0.037387, Ds: 0.000484, mse: 13.892840, mae: 8.265361, mape: 4.485716, G loss: 2171.239258] time: 2:30:10.639910\n",
      "[Epoch 53/200][Dt: 0.021148, Ds: 0.000675, mse: 14.073745, mae: 8.701271, mape: 4.615294, G loss: 2180.425537] time: 2:33:02.976284\n",
      "[Epoch 54/200][Dt: 0.026201, Ds: 0.000520, mse: 13.829935, mae: 8.224623, mape: 4.359119, G loss: 2114.964355] time: 2:36:03.935582\n",
      "[Epoch 55/200][Dt: 0.023042, Ds: 0.000534, mse: 17.645695, mae: 11.470933, mape: 5.295470, G loss: 2236.417969] time: 2:39:01.088107\n",
      "[Epoch 56/200][Dt: 0.022518, Ds: 0.033747, mse: 19.204543, mae: 12.773802, mape: 5.697775, G loss: 3103.554443] time: 2:41:55.608220\n",
      "[Epoch 57/200][Dt: 0.043056, Ds: 0.000061, mse: 13.552711, mae: 8.153105, mape: 4.431273, G loss: 2068.505859] time: 2:44:50.000817\n",
      "[Epoch 58/200][Dt: 0.027738, Ds: 0.000066, mse: 13.774652, mae: 8.565883, mape: 4.681283, G loss: 2074.334961] time: 2:47:45.945906\n",
      "[Epoch 59/200][Dt: 0.018633, Ds: 0.000072, mse: 13.488295, mae: 8.079402, mape: 4.266837, G loss: 2022.141479] time: 2:50:37.792785\n",
      "[Epoch 60/200][Dt: 0.020869, Ds: 0.000081, mse: 14.797332, mae: 9.120260, mape: 4.524560, G loss: 1991.054077] time: 2:53:30.049764\n",
      "[Epoch 61/200][Dt: 0.020824, Ds: 0.000098, mse: 13.683090, mae: 8.379446, mape: 4.362680, G loss: 1986.308838] time: 2:56:22.823992\n",
      "[Epoch 62/200][Dt: 0.131603, Ds: 0.000127, mse: 14.166615, mae: 8.609787, mape: 4.418225, G loss: 2022.612305] time: 2:59:15.419170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 63/200][Dt: 0.028411, Ds: 0.000170, mse: 13.337440, mae: 8.137537, mape: 4.331444, G loss: 1993.041382] time: 3:02:08.337946\n",
      "[Epoch 64/200][Dt: 0.021833, Ds: 0.000237, mse: 13.358738, mae: 8.091229, mape: 4.284472, G loss: 1968.334473] time: 3:04:59.856744\n",
      "[Epoch 65/200][Dt: 0.025582, Ds: 0.000502, mse: 15.763692, mae: 10.335901, mape: 5.433106, G loss: 2179.209717] time: 3:07:52.407267\n",
      "[Epoch 66/200][Dt: 0.026034, Ds: 0.000435, mse: 13.840339, mae: 8.623150, mape: 4.583036, G loss: 2072.361084] time: 3:10:45.785311\n",
      "[Epoch 67/200][Dt: 0.058730, Ds: 0.000496, mse: 14.209139, mae: 8.762309, mape: 4.408814, G loss: 1951.260986] time: 3:13:39.548127\n",
      "[Epoch 68/200][Dt: 0.024986, Ds: 0.000542, mse: 26.229128, mae: 18.408600, mape: 7.380630, G loss: 4606.513184] time: 3:16:31.259810\n",
      "[Epoch 69/200][Dt: 0.037961, Ds: 0.000540, mse: 19.453797, mae: 13.047485, mape: 6.369597, G loss: 2366.261230] time: 3:19:27.200602\n",
      "[Epoch 70/200][Dt: 0.695882, Ds: 0.000580, mse: 15.358894, mae: 9.698372, mape: 4.682792, G loss: 2013.200073] time: 3:22:20.993094\n",
      "[Epoch 71/200][Dt: 0.038890, Ds: 0.000491, mse: 14.443724, mae: 9.022135, mape: 4.501725, G loss: 1871.735229] time: 3:25:14.725841\n",
      "[Epoch 72/200][Dt: 0.028710, Ds: 0.000633, mse: 13.750915, mae: 8.550202, mape: 4.626640, G loss: 1907.538330] time: 3:28:06.435817\n",
      "[Epoch 73/200][Dt: 0.022173, Ds: 0.000506, mse: 15.019354, mae: 9.386086, mape: 4.559000, G loss: 1910.884155] time: 3:30:58.128393\n",
      "[Epoch 74/200][Dt: 0.046770, Ds: 0.000612, mse: 13.483268, mae: 8.302743, mape: 4.484023, G loss: 1803.619629] time: 3:33:49.052886\n",
      "[Epoch 75/200][Dt: 0.025988, Ds: 0.000632, mse: 16.141891, mae: 10.355591, mape: 4.822623, G loss: 2012.561157] time: 3:36:40.503145\n",
      "[Epoch 76/200][Dt: 2.391545, Ds: 0.000521, mse: 13.798219, mae: 8.624072, mape: 4.605778, G loss: 1903.575195] time: 3:39:32.762883\n",
      "[Epoch 77/200][Dt: 0.197671, Ds: 0.000762, mse: 14.427618, mae: 8.966857, mape: 4.733756, G loss: 1882.680054] time: 3:42:26.291058\n",
      "[Epoch 78/200][Dt: 0.026344, Ds: 0.000054, mse: 14.749846, mae: 9.236453, mape: 4.895423, G loss: 1945.372192] time: 3:45:18.745101\n",
      "[Epoch 79/200][Dt: 0.081252, Ds: 0.000063, mse: 17.188749, mae: 11.328947, mape: 5.988615, G loss: 1992.497314] time: 3:48:12.524983\n",
      "[Epoch 80/200][Dt: 0.020833, Ds: 0.000068, mse: 15.062839, mae: 9.675734, mape: 5.238597, G loss: 2031.468872] time: 3:51:06.171501\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'Model' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-f2845cdbc646>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMAX_BATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearn_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearn_rate_c\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-20-e7772cdd712d>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(train_matrix, epochs, batch_size, learn_rate)\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerator_lr\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtemporal_discriminator_lr\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0.0005\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemporal_discriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemporal_discriminator\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m                 \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspatial_discriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspatial_discriminator\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcombined_lr\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'Model' and 'float'"
     ]
    }
   ],
   "source": [
    "train(X_train, epochs=200, batch_size=MAX_BATCH_SIZE, learn_rate=learn_rate_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator.save_weights('./model/wganpg/generator_167epoch_11rmse.h5')\n",
    "# discriminator.save_weights('./model/wganpg/discriminator_167epoch_11rmse.h5')\n",
    "# combined.save_weights('./model/wganpg/combined_167epoch_11rmse.h5')\n",
    "\n",
    "# generator.load_weights('./model/wganpg/DS_rmse11/generator_167epoch_11rmse.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.062838987902238"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = generator.predict(X_test[:, :, :, 1:])\n",
    "y_true = X_test[:, :, :, :1]\n",
    "\n",
    "l2(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': [<matplotlib.lines.Line2D at 0x114475dcc18>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x114475e8668>,\n",
       "  <matplotlib.lines.Line2D at 0x114475e8a90>],\n",
       " 'fliers': [],\n",
       " 'means': [],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x114475e8eb8>],\n",
       " 'whiskers': [<matplotlib.lines.Line2D at 0x114475dcd68>,\n",
       "  <matplotlib.lines.Line2D at 0x114475e8240>]}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11447559320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://matplotlib.org/gallery/pyplots/boxplot_demo_pyplot.html#sphx-glr-gallery-pyplots-boxplot-demo-pyplot-py\n",
    "plt.boxplot(np.sqrt(np.mean(np.square(y_true - y_pred), axis=0)).reshape(1024), showfliers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': [<matplotlib.lines.Line2D at 0x11447517c50>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x114475216a0>,\n",
       "  <matplotlib.lines.Line2D at 0x11447521ac8>],\n",
       " 'fliers': [],\n",
       " 'means': [],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x11447521ef0>],\n",
       " 'whiskers': [<matplotlib.lines.Line2D at 0x11447517da0>,\n",
       "  <matplotlib.lines.Line2D at 0x11447521278>]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11447498470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(np.mean(np.abs(y_true - y_pred), axis=0).reshape(1024), showfliers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.sqrt(np.sum(np.mean(np.square(y_true - y_pred), axis=0))/1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2(y_true, y_pred+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y = y_true.reshape(-1,)[1600:1700]\n",
    "x = np.linspace(0, len(y), len(y))\n",
    "\n",
    "yi = y_pred.reshape(-1,)[1600:1700]\n",
    "xi = np.linspace(0, len(yi), len(yi))\n",
    "fig, ax = plt.subplots(figsize=(25, 6))\n",
    "# ax.plot(x, y, '.', linewidth=1, markersize=10)\n",
    "lines = plt.plot(xi, yi, 'k^--', x, y, 'ro-',linewidth=1, markersize=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yi = l2_validation\n",
    "xi = np.linspace(0, len(yi), len(yi))\n",
    "\n",
    "y = [i*10000 for i in lr_step]\n",
    "x = np.linspace(0, len(y), len(y))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "lines = plt.plot(x, y, 'ko-', xi, yi, 'k^--', linewidth=1, markersize=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = lr_step\n",
    "x = np.linspace(0, len(y), len(y))\n",
    "# fig, ax = plt.subplots(figsize=(6, 6))\n",
    "# lines = plt.plot(x, y, 'ko-', linewidth=1, markersize=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_true.reshape(-1,)[3600:3700]\n",
    "x = np.linspace(0, len(y), len(y))\n",
    "\n",
    "yi = y_pred.reshape(-1,)[3600:3700]\n",
    "xi = np.linspace(0, len(yi), len(yi))\n",
    "fig, ax = plt.subplots(figsize=(25, 6))\n",
    "ax.plot(x, y, '.', linewidth=1, markersize=10)\n",
    "lines = plt.plot(xi, yi, 'k^--', x, y, 'ro-',linewidth=1, markersize=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = 0\n",
    "y = y_true.reshape(-1,)[start_time: start_time+100]\n",
    "x = np.linspace(0, len(y), len(y))\n",
    "\n",
    "yi = y_pred.reshape(-1,)[start_time: start_time+100]\n",
    "xi = np.linspace(0, len(yi), len(yi))\n",
    "fig, ax = plt.subplots(figsize=(25, 6))\n",
    "# ax.plot(x, y, '.', linewidth=1, markersize=10)\n",
    "lines = plt.plot(xi, yi, 'k^--', x, y, 'ro-',linewidth=1, markersize=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
