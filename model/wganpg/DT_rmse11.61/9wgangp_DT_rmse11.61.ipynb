{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import scipy\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import transform\n",
    "\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, concatenate, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D, Add, Subtract, ConvLSTM2D\n",
    "from keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D ,AveragePooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU, ELU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam, Nadam, RMSprop\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.merge import _Merge\n",
    "from keras.engine.topology import Layer\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "import gc\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, TensorBoard\n",
    "from keras import backend as K\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from keras.models import load_model  \n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载  预处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交通矩阵为 matrix_length*matrix_length\n",
    "matrix_length = 32\n",
    "\n",
    "matrix_df = pd.read_csv('./data/trafficV_M.csv', index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def createTrainArray(week_history_num=0, minute_history_num=0):\n",
    "#     week_delta_list = [pd.Timedelta(i+1, unit='W') for i in range(week_history_num)]\n",
    "#     minute_delta_list = [pd.Timedelta((i+1)*15, unit='m') for i in range(minute_history_num)]\n",
    "#     # 参考历史数据时间点list\n",
    "#     delta_list = week_delta_list+minute_delta_list\n",
    "#     print(delta_list)\n",
    "    \n",
    "#     set_up_time = pd.Timedelta(week_history_num, unit='W')\n",
    "#     # 根据历史数据选取多少，重新构建数据集\n",
    "#     # 相当于去除最开始week_history_num个周的数据，因为这些数据无法找到更前的数据\n",
    "#     train_df = matrix_df.truncate(before=matrix_df.index.min() + set_up_time)\n",
    "    \n",
    "#     train_ago_array_tuple = tuple([np.array(matrix_df.loc[train_df.index - i]).reshape(-1, matrix_length, matrix_length, 1) for i in delta_list])\n",
    "#     train_df = np.array(train_df).reshape(-1, matrix_length, matrix_length, 1)\n",
    "#     # concatenate保持 待修复数据在前，参考历史数据在后。与random_mask函数生成mask相一致\n",
    "#     train_array = np.concatenate((train_df,)+train_ago_array_tuple, axis=3)\n",
    "#     print(train_array.shape)\n",
    "#     return train_array\n",
    "\n",
    "\n",
    "\n",
    "def createTrainArray(week_history_num=0, minute_history_num=0):\n",
    "    week_delta_list = [pd.Timedelta(week_history_num-i, unit='W') for i in range(week_history_num)]\n",
    "    minute_delta_list = [pd.Timedelta((minute_history_num-i)*15, unit='m') for i in range(minute_history_num)]\n",
    "    # 参考历史数据时间点list\n",
    "    delta_list = minute_delta_list+week_delta_list\n",
    "    print(delta_list)\n",
    "    \n",
    "    set_up_time = pd.Timedelta(week_history_num, unit='W')\n",
    "    # 根据历史数据选取多少，重新构建数据集\n",
    "    # 相当于去除最开始week_history_num个周的数据，因为这些数据无法找到更前的数据\n",
    "    train_df = matrix_df.truncate(before=matrix_df.index.min() + set_up_time)\n",
    "    \n",
    "    train_ago_array_tuple = tuple([np.array(matrix_df.loc[train_df.index - i]).reshape(-1, matrix_length, matrix_length, 1) for i in delta_list])\n",
    "    train_df = np.array(train_df).reshape(-1, matrix_length, matrix_length, 1)\n",
    "    # concatenate保持 待修复数据在前，参考历史数据在后。与random_mask函数生成mask相一致\n",
    "    train_array = np.concatenate((train_df,)+train_ago_array_tuple, axis=3)\n",
    "    print(train_array.shape)\n",
    "    return train_array\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def normalization(matrix):\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(matrix.shape[-1]):\n",
    "            cur_time = matrix[i][:, :, j]\n",
    "#             mean_val = cur_time.mean()\n",
    "            mx = cur_time.max()\n",
    "            mn = cur_time.min()\n",
    "            matrix[i][:, :, j] = np.divide((cur_time-mn), (mx-mn))\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Timedelta('0 days 00:45:00'), Timedelta('0 days 00:30:00'), Timedelta('0 days 00:15:00'), Timedelta('14 days 00:00:00'), Timedelta('7 days 00:00:00')]\n",
      "(16032, 32, 32, 6)\n"
     ]
    }
   ],
   "source": [
    "week_history_num = 2\n",
    "minute_history_num = 3\n",
    "\n",
    "channel_num = week_history_num +minute_history_num +1\n",
    "smooth_time = channel_num-1\n",
    "\n",
    "# train_array为(16704, 32, 32, 3)，16704个矩阵，32*32采集点，3从上到下为当前时间，上一周，上一15min\n",
    "train_array = createTrainArray(week_history_num, minute_history_num)\n",
    "X_train, X_test = train_test_split(train_array, test_size = 0.1, random_state=42, shuffle=False)\n",
    "# X_train, X_val = train_test_split(train_array, test_size = 0.1, random_state=42, shuffle=False) # 不shuffle可用于查看数据正确性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14428, 32, 32, 6), (1604, 32, 32, 6))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225, 25)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_BATCH_SIZE = 64\n",
    "epoch_steps = X_train.shape[0] // MAX_BATCH_SIZE\n",
    "test_steps = X_test.shape[0] // MAX_BATCH_SIZE\n",
    "epoch_steps, test_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "def load_data(volume_matrix, batch_size=MAX_BATCH_SIZE):\n",
    "    n_batches=batch_size\n",
    "    len_of_matrix = len(volume_matrix)\n",
    "\n",
    "    batch_i = 0\n",
    "    while ((batch_i+1)*batch_size < len_of_matrix):\n",
    "        batch_matrix = volume_matrix[batch_i*batch_size: (batch_i+1)*batch_size]\n",
    "        true_volume, history_volume = batch_matrix[:, :, :, :1], batch_matrix[:, :, :, 1:]\n",
    "#         history_volume = normalization(history_volume)\n",
    "        batch_i+=1\n",
    "\n",
    "        yield true_volume, history_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def l2(y_true, y_pred):\n",
    "    return math.sqrt(np.sum(np.mean(np.square(y_true - y_pred), axis=0))/1024)\n",
    "\n",
    "def l1(y_true, y_pred):\n",
    "    return np.sum(np.mean(np.abs(y_true - y_pred), axis=0))/(matrix_length*matrix_length)\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    return np.sum(np.mean((np.abs(y_true - y_pred)/y_true)*100, axis=0))/(matrix_length*matrix_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算D输出valid大小（PatchGAN）\n",
    "patch = 4\n",
    "disc_patch = (patch, patch, 1)\n",
    "\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "def wgan_gp_distance(y_true, y_pred):\n",
    "    # WGAN-GP代码注释\n",
    "#     eps = K.random_uniform([MAX_BATCH_SIZE, 1], minval=0., maxval=1.) #eps是U[0,1]的随机数\n",
    "#     X_inter = eps*y_true + (1. - eps)*y_pred  #在真实样本和生成样本之间随机插值，希望这个约束可以“布满”真实样本和生成样本之间的空间\n",
    "#     grad = K.gradients(D(X_inter), [X_inter])[0] #求梯度\n",
    "#     grad_norm = K.sqrt(K.reduce_sum((grad)**2, axis=1)) #求梯度的二范数\n",
    "#     grad_pen = 0 #10 * K.reduce_mean(K.nn.relu(grad_norm - 1.)) #Lipschitz限制是要求判别器的梯度不超过K，这个loss项是希望判别器的梯度离K（此处K设为1）越近越好\n",
    "\n",
    "#     #判别器损失函数\n",
    "#     D_loss = K.reduce_mean(y_true) - K.reduce_mean(y_pred) + grad_pen\n",
    "    return K.mean(y_true * y_pred)\n",
    "#     return wasserstein_distance(K.eval(K.reshape(K.mean(y_true, axis=0), [1,-1])).tolist(), K.eval(K.reshape(K.mean(y_pred, axis=0), [1,-1])).tolist())\n",
    "#     return wasserstein_distance(K.mean(y_true, axis=0).reshape(patch*patch).tolist(), K.mean(y_pred, axis=0).reshape(patch*patch).tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (3, 3)\n",
    "g_filters_base = 32\n",
    "DropoutRatio = 0\n",
    "learn_rate_g = 0.0002\n",
    "learn_rate_d = 0.001\n",
    "learn_rate_c = 0.0002\n",
    "\n",
    "# channels = 3\n",
    "matrix_shape = (matrix_length, matrix_length, channel_num)\n",
    "true_volume_shape = (matrix_length, matrix_length, 1)\n",
    "history_volume_shape = (matrix_length, matrix_length, channel_num-1)\n",
    "\n",
    "kernel_init = 'glorot_uniform'\n",
    "bias_init = 'zeros'\n",
    "kernel_regul = regularizers.l2(1)\n",
    "activity_regul = regularizers.l2(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet block\n",
    "def identity_block(X, filters, f):\n",
    "\n",
    "    F1, F2 = filters\n",
    "\n",
    "    X_shortcut = X\n",
    "\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(filters=F1, kernel_size=(f, f), strides=(1, 1), padding='same',\n",
    "               kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "              kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(X)\n",
    "\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same',\n",
    "               kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "              kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(X)\n",
    "\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X\n",
    "\n",
    "# ENCODER\n",
    "def encoder_layer(img_in, filters, kernel_size, bn=True, resid=True):\n",
    "    # conv = Conv2D(filters=filters, kernel_size=kernel_size, strides=(1, 1), padding='same')(img_in)\n",
    "    conv = img_in\n",
    "    if bn:\n",
    "        conv = BatchNormalization()(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "#             conv = MaxPooling2D((2, 2))(conv)\n",
    "\n",
    "\n",
    "    if resid:\n",
    "        conv = identity_block(conv, (filters, filters), kernel_size)\n",
    "\n",
    "    return conv\n",
    "\n",
    "# DECODER\n",
    "def decoder_layer(img_in, e_conv, filters, kernel_size, bn=True, resid=True):\n",
    "    # up_img = UpSampling2D(size=(2,2))(img_in)\n",
    "    up_img = img_in\n",
    "    concat_img = Concatenate(axis=3)([e_conv,up_img])\n",
    "    conv = Conv2D(filters=filters, kernel_size=kernel_size, strides=(1, 1), padding='same',\n",
    "                  kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "              kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(concat_img)\n",
    "    if bn:\n",
    "        conv = BatchNormalization()(conv)\n",
    "    conv = LeakyReLU(alpha=0)(conv)\n",
    "\n",
    "    if resid:\n",
    "        conv = identity_block(conv, (filters, filters), kernel_size)\n",
    "    return conv\n",
    "\n",
    "\n",
    "\n",
    "def build_generator():      \n",
    "\n",
    "    # INPUTS\n",
    "    history_traffic_volume = Input(shape=history_volume_shape)\n",
    "\n",
    "    # kernel_init = initializers.he_normal()\n",
    "    # bias_init = initializers.he_normal()\n",
    "    kernel_init = 'glorot_uniform'\n",
    "    bias_init = 'zeros'\n",
    "\n",
    "#         kernel_init = initializers.he_uniform()\n",
    "#         bias_init = 'Orthogonal'\n",
    "    kernel_regul = regularizers.l2(1)\n",
    "    activity_regul = regularizers.l2(1)\n",
    "\n",
    "    filters_base = 32\n",
    "    e_conv1_head = Conv2D(filters=filters_base, kernel_size=3, strides=1, padding='same',\n",
    "                          kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(history_traffic_volume)\n",
    "#         e_conv1_head = Conv2D(filters=filters_base*1, kernel_size=3, strides=1, padding='same',\n",
    "#                               kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "#                       kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(e_conv1_head)\n",
    "    e_conv1_tail = AveragePooling2D((2, 2))(e_conv1_head)\n",
    "#     e_conv1_tail = Dropout(DropoutRatio/2)(e_conv1_tail)\n",
    "    e_conv1 = encoder_layer(e_conv1_tail, filters_base, 3, bn=False)\n",
    "\n",
    "    e_conv2_head = Conv2D(filters=filters_base*2, kernel_size=3, strides=1, padding='same',\n",
    "                          kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(e_conv1)\n",
    "    e_conv2_tail = AveragePooling2D((2, 2))(e_conv2_head)\n",
    "#     e_conv2_tail = Dropout(DropoutRatio)(e_conv2_tail)\n",
    "    e_conv2 = encoder_layer(e_conv2_tail, filters_base*2, 3)\n",
    "\n",
    "    e_conv3_head = Conv2D(filters=filters_base*4, kernel_size=3, strides=1, padding='same',\n",
    "                          kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(e_conv2)\n",
    "    e_conv3_tail = AveragePooling2D((2, 2))(e_conv3_head)\n",
    "    \n",
    "    # 加drop引入噪声\n",
    "#     e_conv3_tail = Dropout(DropoutRatio)(e_conv3_tail)\n",
    "    \n",
    "    d_conv3_head = encoder_layer(e_conv3_tail, filters_base*4, 3)\n",
    "    resid1 = Subtract()([e_conv3_tail, d_conv3_head])\n",
    "    d_conv3_tail = UpSampling2D(size=(2, 2))(resid1)\n",
    "#     d_conv3_tail = Dropout(DropoutRatio)(d_conv3_tail)\n",
    "\n",
    "\n",
    "    d_conv4_head = decoder_layer(d_conv3_tail, e_conv3_head, filters_base*2, 3)\n",
    "    resid2 = Subtract()([d_conv4_head, e_conv2_tail])\n",
    "    d_conv4_tail = UpSampling2D(size=(2, 2))(resid2)\n",
    "#     d_conv4_tail = Dropout(DropoutRatio)(d_conv4_tail)\n",
    "\n",
    "\n",
    "    d_conv5_head = decoder_layer(d_conv4_tail, e_conv2_head, filters_base*1, 3)\n",
    "    resid3 = Subtract()([d_conv5_head, e_conv1_tail])\n",
    "    d_conv5_tail = UpSampling2D(size=(2, 2))(resid3)\n",
    "#     d_conv5_tail = Dropout(DropoutRatio)(d_conv5_tail)\n",
    "\n",
    "    d_conv6_head = decoder_layer(d_conv5_tail, e_conv1_head, filters_base//2, 3, bn=False)\n",
    "\n",
    "\n",
    "    outputs = Conv2D(1, 1, activation = 'relu', kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(d_conv6_head)\n",
    "\n",
    "    # Setup the model inputs / outputs\n",
    "    model = Model(inputs=history_traffic_volume, outputs=outputs)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer = Adam(lr=learn_rate_g),\n",
    "        loss='mse'\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty_loss(y_true, y_pred, averaged_samples):\n",
    "    \"\"\"\n",
    "    Computes gradient penalty based on prediction and weighted real / fake samples\n",
    "    \"\"\"\n",
    "    gradients = K.gradients(y_pred, averaged_samples)[0]\n",
    "    # compute the euclidean norm by squaring ...\n",
    "    gradients_sqr = K.square(gradients)\n",
    "    #   ... summing over the rows ...\n",
    "    gradients_sqr_sum = K.sum(gradients_sqr,\n",
    "                              axis=np.arange(1, len(gradients_sqr.shape)))\n",
    "    #   ... and sqrt\n",
    "    gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
    "    # compute lambda * (1 - ||grad||)^2 still for each single sample\n",
    "    gradient_penalty = K.square(1 - gradient_l2_norm)\n",
    "    # return the mean as loss over all the batch samples\n",
    "    return K.mean(gradient_penalty)\n",
    "\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)\n",
    "\n",
    "def neg_wasserstein_loss(y_true, y_pred):\n",
    "    return -K.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_filters_base = 32\n",
    "# Input shape\n",
    "\n",
    "# Discriminator\n",
    "def build_discriminator():\n",
    "    def d_layer(layer_input, filters, f_size=3, bn=True, stride=1):\n",
    "        \"\"\"Discriminator layer\"\"\"\n",
    "        d = Conv2D(filters, kernel_size=f_size, strides=stride, padding='same', kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(layer_input)\n",
    "        if bn:\n",
    "            d = BatchNormalization()(d)\n",
    "        d = LeakyReLU(alpha=0.1)(d)\n",
    "        return d\n",
    "\n",
    "    matrix_A = Input(shape=true_volume_shape)\n",
    "    matrix_B = Input(shape=history_volume_shape)\n",
    "\n",
    "    # Concatenate image and conditioning image生成输入对象\n",
    "    combined_matrix = Concatenate(axis=-1)([matrix_B, matrix_A])\n",
    "    combined_matrix = Reshape((6, 32, 32, 1))(combined_matrix)\n",
    "    \n",
    "    cl1 = ConvLSTM2D(filters=d_filters_base, kernel_size=(3, 3), strides=2, \n",
    "                     padding='same', return_sequences=True)(combined_matrix)\n",
    "    cl1 = BatchNormalization()(cl1)\n",
    "\n",
    "#     cl2 = ConvLSTM2D(filters=d_filters_base*2, kernel_size=(3, 3), strides=2,\n",
    "#                        padding='same', return_sequences=True)(cl1)\n",
    "#     cl2 = BatchNormalization()(cl2)\n",
    "\n",
    "    cl3 = ConvLSTM2D(filters=d_filters_base, kernel_size=(3, 3), strides=2,\n",
    "                       padding='same', return_sequences=False)(cl1)\n",
    "    cl3 = BatchNormalization()(cl3)\n",
    "    \n",
    "    cl3 = d_layer(cl3, d_filters_base//2, stride=2)\n",
    "    cl3 = d_layer(cl3, d_filters_base//4)\n",
    "    \n",
    "    validity = Conv2D(1, kernel_size=3, strides=1, padding='same')(cl3)\n",
    "    \n",
    "    model = Model([matrix_A, matrix_B], validity)\n",
    "    model.compile(loss='mse', optimizer=RMSprop(lr=learn_rate_d), metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomWeightedAverage(_Merge):\n",
    "    \"\"\"Provides a (random) weighted average between real and generated image samples\"\"\"\n",
    "    def _merge_function(self, inputs):\n",
    "        alpha = K.random_uniform((64, 1, 1, 1))\n",
    "        return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])\n",
    "    \n",
    "    \n",
    "class GradNorm(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(GradNorm, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(GradNorm, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        vaild_interpolated, interpolation_volume = inputs\n",
    "        grads = K.gradients(vaild_interpolated, interpolation_volume)\n",
    "        assert len(grads) == 1\n",
    "        grad = grads[0]\n",
    "#         a = K.sqrt(K.sum(K.batch_flatten(K.square(grad)), axis=1, keepdims=True))\n",
    "        return grad\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (MAX_BATCH_SIZE,) + true_volume_shape\n",
    "    \n",
    "    def compute_output_shape(self, input_shapes):\n",
    "        return (MAX_BATCH_SIZE,) + true_volume_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "discriminator = build_discriminator()\n",
    "generator = build_generator()\n",
    "\n",
    "\n",
    "true_volume = Input(shape=true_volume_shape)\n",
    "history_volume = Input(shape=history_volume_shape)\n",
    "interpolation_volume = Input(shape=true_volume_shape)\n",
    "\n",
    "forecast_volume = generator(history_volume)\n",
    "\n",
    "discriminator.trainable = False\n",
    "true_vaild = discriminator([true_volume, history_volume])\n",
    "fake_vaild = discriminator([forecast_volume, history_volume])\n",
    "\n",
    "# gp = gradient_penalty_loss(true_volume, forecast_volume, interpolation_volume)\n",
    "norm = GradNorm()([discriminator([interpolation_volume, history_volume]), interpolation_volume])\n",
    "\n",
    "combined = Model(inputs=[true_volume, history_volume, interpolation_volume],\n",
    "                    outputs=[true_vaild, fake_vaild, norm, forecast_volume])\n",
    "combined.compile(loss=[wasserstein_loss,\n",
    "                        neg_wasserstein_loss,\n",
    "                       'mse',\n",
    "                        'mse'],\n",
    "                        optimizer=RMSprop(lr=learn_rate_c),\n",
    "                        loss_weights=[1, 1, 10, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_step = []\n",
    "l2_validation = []\n",
    "\n",
    "def train(train_matrix, epochs, batch_size=MAX_BATCH_SIZE, learn_rate=0.01):\n",
    "\n",
    "    min_mse = 999\n",
    "    start_time = datetime.datetime.now()\n",
    "    print(\"train start \"+str(start_time))\n",
    "\n",
    "    # Adversarial loss ground truths\n",
    "#     valid = np.ones((MAX_BATCH_SIZE,) + disc_patch)+np.random.rand(MAX_BATCH_SIZE, patch, patch, 1)/5\n",
    "#     fake = np.zeros((MAX_BATCH_SIZE,) + disc_patch)+np.random.rand(MAX_BATCH_SIZE, patch, patch, 1)/5\n",
    "    valid = np.ones((MAX_BATCH_SIZE,) + disc_patch)\n",
    "    fake = -np.ones((MAX_BATCH_SIZE,) + disc_patch)\n",
    "    dummy = np.ones((MAX_BATCH_SIZE,) + true_volume_shape)\n",
    "\n",
    "    #　周期修改学习率　https://zhuanlan.zhihu.com/p/52084949\n",
    "    for epoch in range(epochs):\n",
    "        if epoch>=80 and epoch % 5 == 0 and epoch != 0:\n",
    "            generator_lr = K.get_value(generator.optimizer.lr)\n",
    "            discriminator_lr = K.get_value(discriminator.optimizer.lr)\n",
    "            combined_lr = K.get_value(combined.optimizer.lr)\n",
    "            if generator_lr>0.0001:\n",
    "                K.set_value(generator.optimizer.lr, generator_lr*0.9)\n",
    "            if discriminator_lr>0.0005:\n",
    "                K.set_value(discriminator.optimizer.lr, discriminator_lr*0.9)\n",
    "            if combined_lr>0.0001:\n",
    "                K.set_value(combined.optimizer.lr, combined_lr*0.9)\n",
    "\n",
    "        for batch_i, (true_volume, history_volume) in enumerate(load_data(train_matrix,batch_size)):\n",
    "            # true_volume 真实待预测路网交通量  history_volume 路网交通量历史数据\n",
    "            #  训练 Discriminator\n",
    "\n",
    "            # 根据历史数据生成预测数据\n",
    "            forecast_volume = generator.predict(history_volume)\n",
    "\n",
    "            # 训练 the discriminators (original images = real / generated = Fake)\n",
    "            discriminator.trainable = True\n",
    "            d_loss_real = discriminator.train_on_batch([true_volume, history_volume], valid)\n",
    "            d_loss_fake = discriminator.train_on_batch([forecast_volume, history_volume], fake)\n",
    "            discriminator.trainable = False\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            \n",
    "\n",
    "            epsilon = np.random.uniform(0, 1, size=(MAX_BATCH_SIZE,1,1,1))\n",
    "            interpolation_volume = epsilon*true_volume + (1-epsilon)*forecast_volume\n",
    "            #  训练 Generator\n",
    "            g_loss = combined.train_on_batch([true_volume, history_volume, interpolation_volume], [valid, fake, dummy, true_volume])\n",
    "\n",
    "            elapsed_time = datetime.datetime.now() - start_time\n",
    "\n",
    "        # Plot the progress\n",
    "        y_pred = generator.predict(X_test[:, :, :, 1:])\n",
    "        y_true = X_test[:, :, :, :1]\n",
    "\n",
    "        l2_epoch_validation = l2(y_true, y_pred)\n",
    "        l1_epoch_validation = l1(y_true, y_pred)\n",
    "        \n",
    "        y_pred[y_true==0] += 1\n",
    "        y_true[y_true==0] += 1\n",
    "        mape_epoch_validation = mape(y_true, y_pred)\n",
    "        \n",
    "#         lr_step.append(K.get_value(discriminator.optimizer.lr))\n",
    "        if(l2_epoch_validation<12 and l2_epoch_validation < min_mse):\n",
    "            generator.save_weights('./model/wganpg/tmp/min_generator_wganpg.h5')\n",
    "            discriminator.save_weights('./model/wganpg/tmp/min_discriminator_wganpg.h5')\n",
    "            combined.save_weights('./model/wganpg/tmp/min_combined_wganpg.h5')\n",
    "            min_mse = l2_epoch_validation\n",
    "            \n",
    "        l2_validation.append(l2_epoch_validation)\n",
    "        if epoch%1==0:\n",
    "#             print(\"unet lr:\"+ str(K.get_value(unet.optimizer.lr)))\n",
    "            print (\"[Epoch %d/%d]  [D loss: %f, mse: %f] [mae: %f] [mape: %f] [G loss: %f] time: %s\" % (epoch+1, epochs,\n",
    "                                                                    d_loss[0], l2_epoch_validation,\n",
    "                                                                    l1_epoch_validation,\n",
    "                                                                    mape_epoch_validation,\n",
    "                                                                    g_loss[0],\n",
    "                                                                    elapsed_time))\n",
    "        # If at show interval => show generated image samples\n",
    "#             if epoch % show_interval == 0:\n",
    "#                     show_images(dataset_name,epoch, batch_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train start 2019-11-26 13:19:05.754198\n",
      "[Epoch 1/200]  [D loss: 0.124524, mse: 100.091171] [mae: 73.441703] [mape: 28.808083] [G loss: 59113.250000] time: 0:02:56.185754\n",
      "[Epoch 2/200]  [D loss: 0.095113, mse: 94.248531] [mae: 70.052178] [mape: 26.934189] [G loss: 39553.941406] time: 0:05:18.390829\n",
      "[Epoch 3/200]  [D loss: 0.044082, mse: 68.415183] [mae: 50.340614] [mape: 20.220849] [G loss: 15758.801758] time: 0:07:40.168194\n",
      "[Epoch 4/200]  [D loss: 0.114171, mse: 32.819658] [mae: 22.454051] [mape: 11.569154] [G loss: 8069.354980] time: 0:10:03.261457\n",
      "[Epoch 5/200]  [D loss: 0.047028, mse: 44.462842] [mae: 32.718800] [mape: 15.386702] [G loss: 11228.185547] time: 0:12:25.866950\n",
      "[Epoch 6/200]  [D loss: 0.055241, mse: 26.213553] [mae: 17.621291] [mape: 9.175404] [G loss: 6092.447266] time: 0:14:48.569724\n",
      "[Epoch 7/200]  [D loss: 0.074949, mse: 24.900542] [mae: 16.717537] [mape: 8.738384] [G loss: 6224.511719] time: 0:17:11.417089\n",
      "[Epoch 8/200]  [D loss: 0.032736, mse: 22.277029] [mae: 14.559002] [mape: 7.711957] [G loss: 5200.472656] time: 0:19:34.012648\n",
      "[Epoch 9/200]  [D loss: 0.038992, mse: 21.474460] [mae: 14.042502] [mape: 7.486804] [G loss: 4888.546387] time: 0:21:56.474282\n",
      "[Epoch 10/200]  [D loss: 0.043442, mse: 20.045641] [mae: 12.885717] [mape: 6.992855] [G loss: 4384.887695] time: 0:24:19.106904\n",
      "[Epoch 11/200]  [D loss: 0.037293, mse: 19.288208] [mae: 12.257850] [mape: 6.556068] [G loss: 4040.020752] time: 0:26:41.832249\n",
      "[Epoch 12/200]  [D loss: 0.049813, mse: 17.552609] [mae: 10.849180] [mape: 6.032196] [G loss: 3733.076904] time: 0:29:04.460049\n",
      "[Epoch 13/200]  [D loss: 0.036264, mse: 17.137364] [mae: 10.552008] [mape: 5.866144] [G loss: 3561.475830] time: 0:31:27.054859\n",
      "[Epoch 14/200]  [D loss: 0.044930, mse: 16.370360] [mae: 9.940585] [mape: 5.655943] [G loss: 3324.984619] time: 0:33:49.718257\n",
      "[Epoch 15/200]  [D loss: 0.055001, mse: 16.834455] [mae: 10.444737] [mape: 5.995266] [G loss: 3295.073975] time: 0:36:12.515372\n",
      "[Epoch 16/200]  [D loss: 0.028911, mse: 16.224718] [mae: 9.911263] [mape: 5.528196] [G loss: 3244.709229] time: 0:38:36.547843\n",
      "[Epoch 17/200]  [D loss: 0.034386, mse: 15.755636] [mae: 9.446599] [mape: 5.282894] [G loss: 3096.841064] time: 0:41:01.991967\n",
      "[Epoch 18/200]  [D loss: 0.026163, mse: 15.465499] [mae: 9.305720] [mape: 5.279473] [G loss: 3066.271973] time: 0:43:30.976999\n",
      "[Epoch 19/200]  [D loss: 0.033664, mse: 15.831517] [mae: 9.653494] [mape: 5.366251] [G loss: 3090.701660] time: 0:45:56.720112\n",
      "[Epoch 20/200]  [D loss: 0.034438, mse: 15.814361] [mae: 9.583866] [mape: 5.189280] [G loss: 2983.400146] time: 0:48:20.305218\n",
      "[Epoch 21/200]  [D loss: 0.024857, mse: 15.393459] [mae: 9.316221] [mape: 5.239096] [G loss: 2985.958984] time: 0:50:43.649044\n",
      "[Epoch 22/200]  [D loss: 0.025897, mse: 15.120474] [mae: 9.086810] [mape: 5.054213] [G loss: 2899.315674] time: 0:53:07.445795\n",
      "[Epoch 23/200]  [D loss: 0.036730, mse: 16.269920] [mae: 10.106734] [mape: 5.402472] [G loss: 3072.158447] time: 0:55:30.859468\n",
      "[Epoch 24/200]  [D loss: 0.035971, mse: 16.594447] [mae: 10.295052] [mape: 5.392090] [G loss: 3155.516357] time: 0:57:53.887246\n",
      "[Epoch 25/200]  [D loss: 0.028058, mse: 14.910760] [mae: 8.966524] [mape: 5.041425] [G loss: 2856.289551] time: 1:00:19.590428\n",
      "[Epoch 26/200]  [D loss: 0.024157, mse: 14.635370] [mae: 8.859991] [mape: 5.011706] [G loss: 2776.886719] time: 1:02:45.985246\n",
      "[Epoch 27/200]  [D loss: 0.018241, mse: 14.580813] [mae: 8.836491] [mape: 5.073208] [G loss: 2763.645020] time: 1:05:09.120019\n",
      "[Epoch 28/200]  [D loss: 0.019591, mse: 15.331516] [mae: 9.500484] [mape: 5.229054] [G loss: 2847.521484] time: 1:07:31.347665\n",
      "[Epoch 29/200]  [D loss: 0.019072, mse: 15.906057] [mae: 9.805516] [mape: 5.055224] [G loss: 2722.392090] time: 1:09:54.046629\n",
      "[Epoch 30/200]  [D loss: 0.021464, mse: 14.568990] [mae: 8.954002] [mape: 5.115178] [G loss: 2744.400391] time: 1:12:16.811917\n",
      "[Epoch 31/200]  [D loss: 0.018930, mse: 14.539497] [mae: 8.880479] [mape: 4.971851] [G loss: 2723.627686] time: 1:14:40.159492\n",
      "[Epoch 32/200]  [D loss: 0.024263, mse: 14.411318] [mae: 8.824494] [mape: 5.043654] [G loss: 2716.907959] time: 1:17:03.900252\n",
      "[Epoch 33/200]  [D loss: 0.019704, mse: 14.600403] [mae: 8.995834] [mape: 4.776268] [G loss: 2602.380859] time: 1:19:28.364998\n",
      "[Epoch 34/200]  [D loss: 0.024071, mse: 14.400250] [mae: 8.782334] [mape: 5.001002] [G loss: 2695.174561] time: 1:21:51.968294\n",
      "[Epoch 35/200]  [D loss: 0.024476, mse: 14.186232] [mae: 8.601344] [mape: 4.868088] [G loss: 2590.379639] time: 1:24:15.726011\n",
      "[Epoch 36/200]  [D loss: 0.024347, mse: 13.849374] [mae: 8.374575] [mape: 4.852495] [G loss: 2525.608154] time: 1:26:42.883192\n",
      "[Epoch 37/200]  [D loss: 0.030367, mse: 14.522608] [mae: 9.012213] [mape: 5.075512] [G loss: 2620.921875] time: 1:29:05.887596\n",
      "[Epoch 38/200]  [D loss: 0.017687, mse: 14.013422] [mae: 8.554089] [mape: 4.685212] [G loss: 2475.817383] time: 1:31:28.485807\n",
      "[Epoch 39/200]  [D loss: 0.026224, mse: 14.282027] [mae: 8.753167] [mape: 4.978865] [G loss: 2557.853271] time: 1:33:54.489780\n",
      "[Epoch 40/200]  [D loss: 0.018522, mse: 13.753181] [mae: 8.330823] [mape: 4.819932] [G loss: 2435.672119] time: 1:36:21.390991\n",
      "[Epoch 41/200]  [D loss: 0.022654, mse: 14.282670] [mae: 8.969334] [mape: 5.134444] [G loss: 2503.197266] time: 1:38:45.999057\n",
      "[Epoch 42/200]  [D loss: 0.037333, mse: 13.775949] [mae: 8.461241] [mape: 4.868223] [G loss: 2369.396729] time: 1:41:11.045526\n",
      "[Epoch 43/200]  [D loss: 0.015805, mse: 14.285670] [mae: 8.945196] [mape: 5.022698] [G loss: 2362.813232] time: 1:43:33.589765\n",
      "[Epoch 44/200]  [D loss: 0.019568, mse: 13.290295] [mae: 8.056407] [mape: 4.597153] [G loss: 2199.443848] time: 1:45:56.265295\n",
      "[Epoch 45/200]  [D loss: 0.021619, mse: 13.947942] [mae: 8.703036] [mape: 4.916494] [G loss: 2257.988770] time: 1:48:18.601068\n",
      "[Epoch 46/200]  [D loss: 0.028565, mse: 14.236202] [mae: 9.043179] [mape: 5.035444] [G loss: 2266.607910] time: 1:50:40.609457\n",
      "[Epoch 47/200]  [D loss: 0.030435, mse: 12.989936] [mae: 7.980224] [mape: 4.593674] [G loss: 2083.955811] time: 1:53:03.490962\n",
      "[Epoch 48/200]  [D loss: 0.019994, mse: 17.157154] [mae: 11.608528] [mape: 5.414953] [G loss: 2503.975098] time: 1:55:26.020409\n",
      "[Epoch 49/200]  [D loss: 0.016380, mse: 12.819435] [mae: 7.726444] [mape: 4.381912] [G loss: 2012.616333] time: 1:57:49.756747\n",
      "[Epoch 50/200]  [D loss: 0.024103, mse: 13.363103] [mae: 8.440526] [mape: 4.900962] [G loss: 2164.378174] time: 2:00:12.135296\n",
      "[Epoch 51/200]  [D loss: 0.022367, mse: 13.552574] [mae: 8.597514] [mape: 4.968427] [G loss: 2176.705566] time: 2:02:36.451412\n",
      "[Epoch 52/200]  [D loss: 0.025253, mse: 13.464188] [mae: 8.439165] [mape: 4.692416] [G loss: 2186.093262] time: 2:05:05.340769\n",
      "[Epoch 53/200]  [D loss: 0.028156, mse: 19.575887] [mae: 13.326081] [mape: 6.598605] [G loss: 3505.484375] time: 2:07:31.570341\n",
      "[Epoch 54/200]  [D loss: 0.017077, mse: 12.381185] [mae: 7.559251] [mape: 4.192910] [G loss: 1914.557495] time: 2:09:57.778618\n",
      "[Epoch 55/200]  [D loss: 0.026510, mse: 12.226012] [mae: 7.507722] [mape: 4.353692] [G loss: 1945.525269] time: 2:12:20.157502\n",
      "[Epoch 56/200]  [D loss: 0.030815, mse: 12.630201] [mae: 7.914637] [mape: 4.667866] [G loss: 1991.195068] time: 2:14:44.174564\n",
      "[Epoch 57/200]  [D loss: 0.027597, mse: 12.307719] [mae: 7.512045] [mape: 4.318619] [G loss: 1915.667480] time: 2:17:07.243629\n",
      "[Epoch 58/200]  [D loss: 0.025670, mse: 12.244988] [mae: 7.403346] [mape: 4.235653] [G loss: 1823.169312] time: 2:19:30.784344\n",
      "[Epoch 59/200]  [D loss: 0.019795, mse: 12.676001] [mae: 7.952673] [mape: 4.535944] [G loss: 1976.687012] time: 2:21:53.407393\n",
      "[Epoch 60/200]  [D loss: 0.038350, mse: 13.424244] [mae: 8.579410] [mape: 4.974464] [G loss: 2055.624756] time: 2:24:18.691315\n",
      "[Epoch 61/200]  [D loss: 0.028044, mse: 12.161075] [mae: 7.268762] [mape: 4.128379] [G loss: 1726.340332] time: 2:26:44.629411\n",
      "[Epoch 62/200]  [D loss: 0.022319, mse: 12.264722] [mae: 7.314867] [mape: 4.086536] [G loss: 1756.083008] time: 2:29:08.350720\n",
      "[Epoch 63/200]  [D loss: 0.021564, mse: 15.583647] [mae: 10.294491] [mape: 5.252522] [G loss: 1913.846680] time: 2:31:31.050173\n",
      "[Epoch 64/200]  [D loss: 0.020643, mse: 12.554018] [mae: 7.907306] [mape: 4.553015] [G loss: 1866.498413] time: 2:33:53.419912\n",
      "[Epoch 65/200]  [D loss: 0.025969, mse: 12.719324] [mae: 7.967345] [mape: 4.439745] [G loss: 1777.486328] time: 2:36:17.592258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 66/200]  [D loss: 0.024498, mse: 12.261892] [mae: 7.408151] [mape: 4.252197] [G loss: 1763.153687] time: 2:38:47.180863\n",
      "[Epoch 67/200]  [D loss: 0.060060, mse: 12.953941] [mae: 8.195078] [mape: 4.584451] [G loss: 1865.888672] time: 2:41:17.831434\n",
      "[Epoch 68/200]  [D loss: 0.024762, mse: 12.026468] [mae: 7.197354] [mape: 4.115988] [G loss: 1699.576294] time: 2:43:44.593617\n",
      "[Epoch 69/200]  [D loss: 0.017162, mse: 20.932801] [mae: 14.660558] [mape: 6.915587] [G loss: 2771.262451] time: 2:46:08.812667\n",
      "[Epoch 70/200]  [D loss: 0.018928, mse: 12.981422] [mae: 8.070052] [mape: 4.380931] [G loss: 1679.169800] time: 2:48:33.510133\n",
      "[Epoch 71/200]  [D loss: 0.020236, mse: 13.297059] [mae: 8.604990] [mape: 4.746994] [G loss: 1849.260010] time: 2:50:55.395568\n",
      "[Epoch 72/200]  [D loss: 0.017962, mse: 16.920335] [mae: 11.633753] [mape: 5.923354] [G loss: 2581.816406] time: 2:53:27.443010\n",
      "[Epoch 73/200]  [D loss: 0.016880, mse: 11.695329] [mae: 6.962305] [mape: 3.884360] [G loss: 1564.677734] time: 2:55:57.099928\n",
      "[Epoch 74/200]  [D loss: 0.022379, mse: 12.843329] [mae: 8.122140] [mape: 4.496276] [G loss: 1833.532104] time: 2:58:48.775506\n",
      "[Epoch 75/200]  [D loss: 0.209721, mse: 11.615930] [mae: 7.024487] [mape: 4.033480] [G loss: 1550.114380] time: 3:01:12.480103\n",
      "[Epoch 76/200]  [D loss: 0.025959, mse: 11.977786] [mae: 7.124639] [mape: 3.763567] [G loss: 1555.998535] time: 3:03:37.263235\n",
      "[Epoch 77/200]  [D loss: 0.017372, mse: 12.957710] [mae: 8.200087] [mape: 4.451970] [G loss: 1690.347290] time: 3:06:00.541436\n",
      "[Epoch 78/200]  [D loss: 0.026478, mse: 13.206679] [mae: 8.090716] [mape: 3.928073] [G loss: 1635.209106] time: 3:08:26.719070\n",
      "[Epoch 79/200]  [D loss: 0.022101, mse: 12.258194] [mae: 7.564871] [mape: 3.994633] [G loss: 1609.837402] time: 3:10:50.003758\n",
      "[Epoch 80/200]  [D loss: 0.020399, mse: 13.539888] [mae: 8.636212] [mape: 4.458591] [G loss: 1662.008545] time: 3:13:13.099966\n",
      "[Epoch 81/200]  [D loss: 0.036461, mse: 14.455100] [mae: 9.305798] [mape: 4.599724] [G loss: 1646.060059] time: 3:15:39.680672\n",
      "[Epoch 82/200]  [D loss: 0.033692, mse: 16.251799] [mae: 10.790271] [mape: 5.108207] [G loss: 2186.235352] time: 3:18:08.176816\n",
      "[Epoch 83/200]  [D loss: 0.023697, mse: 11.782322] [mae: 6.950529] [mape: 3.801700] [G loss: 1478.205444] time: 3:20:33.247476\n",
      "[Epoch 84/200]  [D loss: 0.019746, mse: 11.809666] [mae: 7.092115] [mape: 3.756925] [G loss: 1467.262329] time: 3:22:59.079459\n",
      "[Epoch 85/200]  [D loss: 0.037272, mse: 12.063088] [mae: 7.192257] [mape: 3.660949] [G loss: 1534.944946] time: 3:25:21.979085\n",
      "[Epoch 86/200]  [D loss: 0.039231, mse: 12.047037] [mae: 7.254598] [mape: 3.802538] [G loss: 1495.153931] time: 3:27:43.870581\n",
      "[Epoch 87/200]  [D loss: 0.024659, mse: 11.953589] [mae: 7.253294] [mape: 3.857777] [G loss: 1474.946289] time: 3:30:06.777273\n",
      "[Epoch 88/200]  [D loss: 0.017572, mse: 20.152522] [mae: 13.748896] [mape: 5.417496] [G loss: 3538.936035] time: 3:32:29.165510\n",
      "[Epoch 89/200]  [D loss: 0.018015, mse: 12.025244] [mae: 7.231234] [mape: 3.638702] [G loss: 1581.967773] time: 3:34:51.854636\n",
      "[Epoch 90/200]  [D loss: 0.027586, mse: 13.062299] [mae: 8.193751] [mape: 3.834670] [G loss: 1724.812988] time: 3:37:14.357966\n",
      "[Epoch 91/200]  [D loss: 0.034069, mse: 11.652707] [mae: 6.916864] [mape: 3.702163] [G loss: 1408.051636] time: 3:39:38.013959\n",
      "[Epoch 92/200]  [D loss: 0.014941, mse: 12.105328] [mae: 7.334644] [mape: 3.901525] [G loss: 1436.594116] time: 3:42:01.168702\n",
      "[Epoch 93/200]  [D loss: 0.025461, mse: 19.547097] [mae: 13.304700] [mape: 5.259054] [G loss: 2617.034668] time: 3:44:23.871848\n",
      "[Epoch 94/200]  [D loss: 0.020900, mse: 13.730976] [mae: 8.801347] [mape: 4.463002] [G loss: 1517.862427] time: 3:46:46.274785\n",
      "[Epoch 95/200]  [D loss: 0.018571, mse: 13.723832] [mae: 8.713772] [mape: 4.352340] [G loss: 1460.326660] time: 3:49:08.520058\n",
      "[Epoch 96/200]  [D loss: 0.014791, mse: 11.895802] [mae: 6.934657] [mape: 3.525864] [G loss: 1366.998657] time: 3:51:30.892154\n",
      "[Epoch 97/200]  [D loss: 0.014778, mse: 12.549820] [mae: 8.070192] [mape: 4.393748] [G loss: 1486.041992] time: 3:53:53.247358\n",
      "[Epoch 98/200]  [D loss: 0.022510, mse: 12.211305] [mae: 7.329872] [mape: 3.832594] [G loss: 1401.781372] time: 3:56:15.516467\n",
      "[Epoch 99/200]  [D loss: 0.017989, mse: 12.782597] [mae: 7.659726] [mape: 3.882451] [G loss: 1403.107178] time: 3:58:38.021306\n",
      "[Epoch 100/200]  [D loss: 0.031018, mse: 12.613879] [mae: 7.758053] [mape: 3.984935] [G loss: 1427.823730] time: 4:01:03.228334\n",
      "[Epoch 101/200]  [D loss: 0.018114, mse: 12.725077] [mae: 7.860394] [mape: 4.034328] [G loss: 1421.432983] time: 4:03:26.522326\n",
      "[Epoch 102/200]  [D loss: 0.016149, mse: 15.114966] [mae: 10.194422] [mape: 4.984509] [G loss: 1825.239502] time: 4:05:50.658925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-f2845cdbc646>\", line 1, in <module>\n",
      "    train(X_train, epochs=200, batch_size=MAX_BATCH_SIZE, learn_rate=learn_rate_c)\n",
      "  File \"<ipython-input-16-73273cdd1419>\", line 35, in train\n",
      "    forecast_volume = generator.predict(history_volume)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1167, in predict\n",
      "    steps=steps)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\", line 294, in predict_loop\n",
      "    batch_outs = f(ins_batch)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 2666, in __call__\n",
      "    return self._call(inputs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 2636, in _call\n",
      "    fetched = self._callable_fn(*array_vals)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1451, in __call__\n",
      "    self._session._session, self._handle, args, status, None)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 1828, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1090, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tornado.general:Uncaught exception, closing connection.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2737, in run_cell\n",
      "    self.events.trigger('post_execute')\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\events.py\", line 73, in trigger\n",
      "    func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 512, in post_execute_hook\n",
      "    for modname in newly_loaded_modules:\n",
      "KeyboardInterrupt\n",
      "ERROR:tornado.general:Uncaught exception, closing connection.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2737, in run_cell\n",
      "    self.events.trigger('post_execute')\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\events.py\", line 73, in trigger\n",
      "    func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 512, in post_execute_hook\n",
      "    for modname in newly_loaded_modules:\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "train(X_train, epochs=200, batch_size=MAX_BATCH_SIZE, learn_rate=learn_rate_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator.save_weights('./model/wganpg/generator_167epoch_11rmse.h5')\n",
    "# discriminator.save_weights('./model/wganpg/discriminator_167epoch_11rmse.h5')\n",
    "# combined.save_weights('./model/wganpg/combined_167epoch_11rmse.h5')\n",
    "\n",
    "# generator.load_weights('./model/wganpg/DS_rmse11/generator_167epoch_11rmse.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = generator.predict(X_test[:, :, :, 1:])\n",
    "y_true = X_test[:, :, :, :1]\n",
    "\n",
    "l2(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.sqrt(np.sum(np.mean(np.square(y_true - y_pred), axis=0))/1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2(y_true, y_pred+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y = y_true.reshape(-1,)[1600:1700]\n",
    "x = np.linspace(0, len(y), len(y))\n",
    "\n",
    "yi = y_pred.reshape(-1,)[1600:1700]\n",
    "xi = np.linspace(0, len(yi), len(yi))\n",
    "fig, ax = plt.subplots(figsize=(25, 6))\n",
    "# ax.plot(x, y, '.', linewidth=1, markersize=10)\n",
    "lines = plt.plot(xi, yi, 'k^--', x, y, 'ro-',linewidth=1, markersize=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yi = l2_validation\n",
    "xi = np.linspace(0, len(yi), len(yi))\n",
    "\n",
    "y = [i*10000 for i in lr_step]\n",
    "x = np.linspace(0, len(y), len(y))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "lines = plt.plot(x, y, 'ko-', xi, yi, 'k^--', linewidth=1, markersize=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = lr_step\n",
    "x = np.linspace(0, len(y), len(y))\n",
    "# fig, ax = plt.subplots(figsize=(6, 6))\n",
    "# lines = plt.plot(x, y, 'ko-', linewidth=1, markersize=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_true.reshape(-1,)[3600:3700]\n",
    "x = np.linspace(0, len(y), len(y))\n",
    "\n",
    "yi = y_pred.reshape(-1,)[3600:3700]\n",
    "xi = np.linspace(0, len(yi), len(yi))\n",
    "fig, ax = plt.subplots(figsize=(25, 6))\n",
    "ax.plot(x, y, '.', linewidth=1, markersize=10)\n",
    "lines = plt.plot(xi, yi, 'k^--', x, y, 'ro-',linewidth=1, markersize=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = 0\n",
    "y = y_true.reshape(-1,)[start_time: start_time+100]\n",
    "x = np.linspace(0, len(y), len(y))\n",
    "\n",
    "yi = y_pred.reshape(-1,)[start_time: start_time+100]\n",
    "xi = np.linspace(0, len(yi), len(yi))\n",
    "fig, ax = plt.subplots(figsize=(25, 6))\n",
    "# ax.plot(x, y, '.', linewidth=1, markersize=10)\n",
    "lines = plt.plot(xi, yi, 'k^--', x, y, 'ro-',linewidth=1, markersize=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
