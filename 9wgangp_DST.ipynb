{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import scipy\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import transform\n",
    "\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, concatenate, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D, Add, Subtract, ConvLSTM2D\n",
    "from keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D ,AveragePooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU, ELU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam, Nadam, RMSprop\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.merge import _Merge\n",
    "from keras.engine.topology import Layer\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "import gc\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, TensorBoard\n",
    "from keras import backend as K\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from keras.models import load_model  \n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载  预处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交通矩阵为 matrix_length*matrix_length\n",
    "matrix_length = 32\n",
    "\n",
    "matrix_df = pd.read_csv('./data/trafficV_M.csv', index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def createTrainArray(week_history_num=0, minute_history_num=0):\n",
    "#     week_delta_list = [pd.Timedelta(i+1, unit='W') for i in range(week_history_num)]\n",
    "#     minute_delta_list = [pd.Timedelta((i+1)*15, unit='m') for i in range(minute_history_num)]\n",
    "#     # 参考历史数据时间点list\n",
    "#     delta_list = week_delta_list+minute_delta_list\n",
    "#     print(delta_list)\n",
    "    \n",
    "#     set_up_time = pd.Timedelta(week_history_num, unit='W')\n",
    "#     # 根据历史数据选取多少，重新构建数据集\n",
    "#     # 相当于去除最开始week_history_num个周的数据，因为这些数据无法找到更前的数据\n",
    "#     train_df = matrix_df.truncate(before=matrix_df.index.min() + set_up_time)\n",
    "    \n",
    "#     train_ago_array_tuple = tuple([np.array(matrix_df.loc[train_df.index - i]).reshape(-1, matrix_length, matrix_length, 1) for i in delta_list])\n",
    "#     train_df = np.array(train_df).reshape(-1, matrix_length, matrix_length, 1)\n",
    "#     # concatenate保持 待修复数据在前，参考历史数据在后。与random_mask函数生成mask相一致\n",
    "#     train_array = np.concatenate((train_df,)+train_ago_array_tuple, axis=3)\n",
    "#     print(train_array.shape)\n",
    "#     return train_array\n",
    "\n",
    "\n",
    "\n",
    "def createTrainArray(week_history_num=0, minute_history_num=0):\n",
    "    week_delta_list = [pd.Timedelta(week_history_num-i, unit='W') for i in range(week_history_num)]\n",
    "    minute_delta_list = [pd.Timedelta((minute_history_num-i)*15, unit='m') for i in range(minute_history_num)]\n",
    "    # 参考历史数据时间点list\n",
    "    delta_list = minute_delta_list+week_delta_list\n",
    "    print(delta_list)\n",
    "    \n",
    "    set_up_time = pd.Timedelta(week_history_num, unit='W')\n",
    "    # 根据历史数据选取多少，重新构建数据集\n",
    "    # 相当于去除最开始week_history_num个周的数据，因为这些数据无法找到更前的数据\n",
    "    train_df = matrix_df.truncate(before=matrix_df.index.min() + set_up_time)\n",
    "    \n",
    "    train_ago_array_tuple = tuple([np.array(matrix_df.loc[train_df.index - i]).reshape(-1, matrix_length, matrix_length, 1) for i in delta_list])\n",
    "    train_df = np.array(train_df).reshape(-1, matrix_length, matrix_length, 1)\n",
    "    # concatenate保持 待修复数据在前，参考历史数据在后。与random_mask函数生成mask相一致\n",
    "    train_array = np.concatenate((train_df,)+train_ago_array_tuple, axis=3)\n",
    "    print(train_array.shape)\n",
    "    return train_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Timedelta('0 days 00:45:00'), Timedelta('0 days 00:30:00'), Timedelta('0 days 00:15:00'), Timedelta('14 days 00:00:00'), Timedelta('7 days 00:00:00')]\n",
      "(16032, 32, 32, 6)\n"
     ]
    }
   ],
   "source": [
    "week_history_num = 2\n",
    "minute_history_num = 3\n",
    "\n",
    "channel_num = week_history_num +minute_history_num +1\n",
    "smooth_time = channel_num-1\n",
    "\n",
    "# train_array为(16704, 32, 32, 3)，16704个矩阵，32*32采集点，3从上到下为当前时间，上一周，上一15min\n",
    "train_array = createTrainArray(week_history_num, minute_history_num)\n",
    "X_train, X_test = train_test_split(train_array, test_size = 0.1, random_state=42, shuffle=False)\n",
    "# X_train, X_val = train_test_split(train_array, test_size = 0.1, random_state=42, shuffle=False) # 不shuffle可用于查看数据正确性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14428, 32, 32, 6), (1604, 32, 32, 6))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225, 25)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_BATCH_SIZE = 64\n",
    "epoch_steps = X_train.shape[0] // MAX_BATCH_SIZE\n",
    "test_steps = X_test.shape[0] // MAX_BATCH_SIZE\n",
    "epoch_steps, test_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "def load_data(volume_matrix, batch_size=MAX_BATCH_SIZE):\n",
    "    n_batches=batch_size\n",
    "    len_of_matrix = len(volume_matrix)\n",
    "\n",
    "    batch_i = 0\n",
    "    while ((batch_i+1)*batch_size < len_of_matrix):\n",
    "        batch_matrix = volume_matrix[batch_i*batch_size: (batch_i+1)*batch_size]\n",
    "        true_volume, history_volume = batch_matrix[:, :, :, :1], batch_matrix[:, :, :, 1:]\n",
    "#         history_volume = normalization(history_volume)\n",
    "        batch_i+=1\n",
    "\n",
    "        yield true_volume, history_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def l2(y_true, y_pred):\n",
    "    return math.sqrt(np.sum(np.mean(np.square(y_true - y_pred), axis=0))/1024)\n",
    "\n",
    "def l1(y_true, y_pred):\n",
    "    return np.sum(np.mean(np.abs(y_true - y_pred), axis=0))/(matrix_length*matrix_length)\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    return np.sum(np.mean((np.abs(y_true - y_pred)/y_true)*100, axis=0))/(matrix_length*matrix_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算D输出valid大小（PatchGAN）\n",
    "patch = 4\n",
    "disc_patch = (patch, patch, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (3, 3)\n",
    "g_filters_base = 32\n",
    "DropoutRatio = 0\n",
    "learn_rate_g = 0.0002\n",
    "learn_rate_d = 0.0008\n",
    "learn_rate_c = 0.0002\n",
    "\n",
    "# channels = 3\n",
    "matrix_shape = (matrix_length, matrix_length, channel_num)\n",
    "true_volume_shape = (matrix_length, matrix_length, 1)\n",
    "history_volume_shape = (matrix_length, matrix_length, channel_num-1)\n",
    "\n",
    "kernel_init = 'glorot_uniform'\n",
    "bias_init = 'zeros'\n",
    "kernel_regul = regularizers.l2(1)\n",
    "activity_regul = regularizers.l2(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet block\n",
    "def identity_block(X, filters, f):\n",
    "\n",
    "    F1, F2 = filters\n",
    "\n",
    "    X_shortcut = X\n",
    "\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(filters=F1, kernel_size=(f, f), strides=(1, 1), padding='same',\n",
    "               kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "              kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(X)\n",
    "\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same',\n",
    "               kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "              kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(X)\n",
    "\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X\n",
    "\n",
    "# ENCODER\n",
    "def encoder_layer(img_in, filters, kernel_size, bn=True, resid=True):\n",
    "    # conv = Conv2D(filters=filters, kernel_size=kernel_size, strides=(1, 1), padding='same')(img_in)\n",
    "    conv = img_in\n",
    "    if bn:\n",
    "        conv = BatchNormalization()(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "#             conv = MaxPooling2D((2, 2))(conv)\n",
    "\n",
    "\n",
    "    if resid:\n",
    "        conv = identity_block(conv, (filters, filters), kernel_size)\n",
    "\n",
    "    return conv\n",
    "\n",
    "# DECODER\n",
    "def decoder_layer(img_in, e_conv, filters, kernel_size, bn=True, resid=True):\n",
    "    # up_img = UpSampling2D(size=(2,2))(img_in)\n",
    "    up_img = img_in\n",
    "    concat_img = Concatenate(axis=3)([e_conv,up_img])\n",
    "    conv = Conv2D(filters=filters, kernel_size=kernel_size, strides=(1, 1), padding='same',\n",
    "                  kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "              kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(concat_img)\n",
    "    if bn:\n",
    "        conv = BatchNormalization()(conv)\n",
    "    conv = LeakyReLU(alpha=0)(conv)\n",
    "\n",
    "    if resid:\n",
    "        conv = identity_block(conv, (filters, filters), kernel_size)\n",
    "    return conv\n",
    "\n",
    "\n",
    "\n",
    "def build_generator():      \n",
    "\n",
    "    # INPUTS\n",
    "    history_traffic_volume = Input(shape=history_volume_shape)\n",
    "\n",
    "    # kernel_init = initializers.he_normal()\n",
    "    # bias_init = initializers.he_normal()\n",
    "    kernel_init = 'glorot_uniform'\n",
    "    bias_init = 'zeros'\n",
    "\n",
    "#         kernel_init = initializers.he_uniform()\n",
    "#         bias_init = 'Orthogonal'\n",
    "    kernel_regul = regularizers.l2(1)\n",
    "    activity_regul = regularizers.l2(1)\n",
    "\n",
    "    filters_base = 32\n",
    "    e_conv1_head = Conv2D(filters=filters_base, kernel_size=3, strides=1, padding='same',\n",
    "                          kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(history_traffic_volume)\n",
    "#         e_conv1_head = Conv2D(filters=filters_base*1, kernel_size=3, strides=1, padding='same',\n",
    "#                               kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "#                       kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(e_conv1_head)\n",
    "    e_conv1_tail = AveragePooling2D((2, 2))(e_conv1_head)\n",
    "#     e_conv1_tail = Dropout(DropoutRatio/2)(e_conv1_tail)\n",
    "    e_conv1 = encoder_layer(e_conv1_tail, filters_base, 3, bn=False)\n",
    "\n",
    "    e_conv2_head = Conv2D(filters=filters_base*2, kernel_size=3, strides=1, padding='same',\n",
    "                          kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(e_conv1)\n",
    "    e_conv2_tail = AveragePooling2D((2, 2))(e_conv2_head)\n",
    "#     e_conv2_tail = Dropout(DropoutRatio)(e_conv2_tail)\n",
    "    e_conv2 = encoder_layer(e_conv2_tail, filters_base*2, 3)\n",
    "\n",
    "    e_conv3_head = Conv2D(filters=filters_base*4, kernel_size=3, strides=1, padding='same',\n",
    "                          kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(e_conv2)\n",
    "    e_conv3_tail = AveragePooling2D((2, 2))(e_conv3_head)\n",
    "    \n",
    "    # 加drop引入噪声\n",
    "#     e_conv3_tail = Dropout(DropoutRatio)(e_conv3_tail)\n",
    "    \n",
    "    d_conv3_head = encoder_layer(e_conv3_tail, filters_base*4, 3)\n",
    "    resid1 = Subtract()([e_conv3_tail, d_conv3_head])\n",
    "    d_conv3_tail = UpSampling2D(size=(2, 2))(resid1)\n",
    "#     d_conv3_tail = Dropout(DropoutRatio)(d_conv3_tail)\n",
    "\n",
    "\n",
    "    d_conv4_head = decoder_layer(d_conv3_tail, e_conv3_head, filters_base*2, 3)\n",
    "    resid2 = Subtract()([d_conv4_head, e_conv2_tail])\n",
    "    d_conv4_tail = UpSampling2D(size=(2, 2))(resid2)\n",
    "#     d_conv4_tail = Dropout(DropoutRatio)(d_conv4_tail)\n",
    "\n",
    "\n",
    "    d_conv5_head = decoder_layer(d_conv4_tail, e_conv2_head, filters_base*1, 3)\n",
    "    resid3 = Subtract()([d_conv5_head, e_conv1_tail])\n",
    "    d_conv5_tail = UpSampling2D(size=(2, 2))(resid3)\n",
    "#     d_conv5_tail = Dropout(DropoutRatio)(d_conv5_tail)\n",
    "\n",
    "    d_conv6_head = decoder_layer(d_conv5_tail, e_conv1_head, filters_base//2, 3, bn=False)\n",
    "\n",
    "\n",
    "    outputs = Conv2D(1, 1, activation = 'relu', kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(d_conv6_head)\n",
    "\n",
    "    # Setup the model inputs / outputs\n",
    "    model = Model(inputs=history_traffic_volume, outputs=outputs)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer = Adam(lr=learn_rate_g),\n",
    "        loss='mse'\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty_loss(y_true, y_pred, averaged_samples):\n",
    "    \"\"\"\n",
    "    Computes gradient penalty based on prediction and weighted real / fake samples\n",
    "    \"\"\"\n",
    "    gradients = K.gradients(y_pred, averaged_samples)[0]\n",
    "    # compute the euclidean norm by squaring ...\n",
    "    gradients_sqr = K.square(gradients)\n",
    "    #   ... summing over the rows ...\n",
    "    gradients_sqr_sum = K.sum(gradients_sqr,\n",
    "                              axis=np.arange(1, len(gradients_sqr.shape)))\n",
    "    #   ... and sqrt\n",
    "    gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
    "    # compute lambda * (1 - ||grad||)^2 still for each single sample\n",
    "    gradient_penalty = K.square(1 - gradient_l2_norm)\n",
    "    # return the mean as loss over all the batch samples\n",
    "    return K.mean(gradient_penalty)\n",
    "\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)\n",
    "\n",
    "def neg_wasserstein_loss(y_true, y_pred):\n",
    "    return -K.mean(y_true * y_pred)\n",
    "\n",
    "def neg_mean_squared_error(y_true, y_pred):\n",
    "    return -K.mean(K.square(y_pred - y_true), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomWeightedAverage(_Merge):\n",
    "    \"\"\"Provides a (random) weighted average between real and generated image samples\"\"\"\n",
    "    def _merge_function(self, inputs):\n",
    "        alpha = K.random_uniform((64, 1, 1, 1))\n",
    "        return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])\n",
    "    \n",
    "    \n",
    "class GradNorm(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(GradNorm, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(GradNorm, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        vaild_interpolated, interpolation_volume = inputs\n",
    "        grads = K.gradients(vaild_interpolated, interpolation_volume)\n",
    "        assert len(grads) == 1\n",
    "        grad = grads[0]\n",
    "#         a = K.sqrt(K.sum(K.batch_flatten(K.square(grad)), axis=1, keepdims=True))\n",
    "        return grad\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (MAX_BATCH_SIZE,) + true_volume_shape\n",
    "    \n",
    "    def compute_output_shape(self, input_shapes):\n",
    "        return (MAX_BATCH_SIZE,) + true_volume_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_filters_base = 32\n",
    "# Input shape\n",
    "\n",
    "# Discriminator\n",
    "def build_spatial_discriminator():\n",
    "    def d_layer(layer_input, filters, f_size=3, bn=True, stride=1):\n",
    "        \"\"\"Discriminator layer\"\"\"\n",
    "        d = Conv2D(filters, kernel_size=f_size, strides=stride, padding='same', kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(layer_input)\n",
    "        if bn:\n",
    "            d = BatchNormalization()(d)\n",
    "        d = LeakyReLU(alpha=0.1)(d)\n",
    "        return d\n",
    "    \n",
    "    matrix_A = Input(shape=true_volume_shape)\n",
    "    matrix_B = Input(shape=history_volume_shape)\n",
    "\n",
    "    # Concatenate image and conditioning image生成输入对象\n",
    "    combined_matrix = Concatenate(axis=-1)([matrix_A, matrix_B])\n",
    "\n",
    "    d1 = d_layer(combined_matrix, d_filters_base, bn=False)\n",
    "    d2 = d_layer(d1, d_filters_base*2, stride=2)\n",
    "#     d2 = AveragePooling2D((2, 2))(d2)\n",
    "    d3 = d_layer(d2, d_filters_base*4, stride=2)\n",
    "#     d3 = AveragePooling2D((2, 2))(d3)\n",
    "    d4 = d_layer(d3, d_filters_base*8, stride=2)\n",
    "#     d4 = AveragePooling2D((2, 2))(d4)\n",
    "    d4 = d_layer(d4, d_filters_base*4)\n",
    "    d5 = d_layer(d4, d_filters_base*2)\n",
    "    d6 = d_layer(d5, d_filters_base*1)\n",
    "    \n",
    "    validity = Conv2D(1, kernel_size=3, strides=1, padding='same')(d6)\n",
    "    model = Model([matrix_A, matrix_B], validity)\n",
    "#     model.compile(optimizer=RMSprop(lr=learn_rate_d), loss='mse', metrics=['mse']) \n",
    "    model.compile(optimizer=Adam(lr=learn_rate_d), loss=wasserstein_loss, metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def build_temporal_discriminator():\n",
    "    def d_layer(layer_input, filters, f_size=3, bn=True, stride=1):\n",
    "        \"\"\"Discriminator layer\"\"\"\n",
    "        d = Conv2D(filters, kernel_size=f_size, strides=stride, padding='same', kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(layer_input)\n",
    "        if bn:\n",
    "            d = BatchNormalization()(d)\n",
    "        d = LeakyReLU(alpha=0.1)(d)\n",
    "        return d\n",
    "\n",
    "    matrix_A = Input(shape=true_volume_shape)\n",
    "    matrix_B = Input(shape=history_volume_shape)\n",
    "\n",
    "    # Concatenate image and conditioning image生成输入对象\n",
    "    combined_matrix = Concatenate(axis=-1)([matrix_B, matrix_A])\n",
    "    combined_matrix = Reshape((6, 32, 32, 1))(combined_matrix)\n",
    "    \n",
    "    cl1 = ConvLSTM2D(filters=d_filters_base, kernel_size=(3, 3), strides=2, \n",
    "                     padding='same', return_sequences=True)(combined_matrix)\n",
    "    cl1 = BatchNormalization()(cl1)\n",
    "\n",
    "#     cl2 = ConvLSTM2D(filters=d_filters_base*2, kernel_size=(3, 3), strides=2,\n",
    "#                        padding='same', return_sequences=True)(cl1)\n",
    "#     cl2 = BatchNormalization()(cl2)\n",
    "\n",
    "    cl3 = ConvLSTM2D(filters=d_filters_base, kernel_size=(3, 3), strides=2,\n",
    "                       padding='same', return_sequences=False)(cl1)\n",
    "    cl3 = BatchNormalization()(cl3)\n",
    "    \n",
    "    cl3 = d_layer(cl3, d_filters_base//2, stride=2)\n",
    "    cl3 = d_layer(cl3, d_filters_base//4)\n",
    "    \n",
    "    validity = Conv2D(1, kernel_size=3, strides=1, padding='same')(cl3)\n",
    "    \n",
    "    model = Model([matrix_A, matrix_B], validity)\n",
    "    model.compile(optimizer=RMSprop(lr=learn_rate_d), loss='mse', metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "temporal_discriminator = build_temporal_discriminator()\n",
    "spatial_discriminator = build_spatial_discriminator()\n",
    "generator = build_generator()\n",
    "\n",
    "\n",
    "true_volume = Input(shape=true_volume_shape)\n",
    "history_volume = Input(shape=history_volume_shape)\n",
    "interpolation_volume = Input(shape=true_volume_shape)\n",
    "\n",
    "forecast_volume = generator(history_volume)\n",
    "\n",
    "temporal_discriminator.trainable = False\n",
    "spatial_discriminator.trainable = False\n",
    "temporal_true_vaild = temporal_discriminator([true_volume, history_volume])\n",
    "temporal_fake_vaild = temporal_discriminator([forecast_volume, history_volume])\n",
    "spatial_true_vaild = spatial_discriminator([true_volume, history_volume])\n",
    "spatial_fake_vaild = spatial_discriminator([forecast_volume, history_volume])\n",
    "\n",
    "\n",
    "# gp = gradient_penalty_loss(true_volume, forecast_volume, interpolation_volume)\n",
    "temporal_norm = GradNorm()([temporal_discriminator([interpolation_volume, history_volume]), interpolation_volume])\n",
    "spatial_norm = GradNorm()([spatial_discriminator([interpolation_volume, history_volume]), interpolation_volume])\n",
    "\n",
    "combined = Model(inputs=[true_volume, history_volume, interpolation_volume],\n",
    "                    outputs=[temporal_true_vaild, temporal_fake_vaild, temporal_norm, spatial_true_vaild, spatial_fake_vaild, spatial_norm, forecast_volume])\n",
    "# combined.compile(loss=[wasserstein_loss,\n",
    "#                         neg_wasserstein_loss,\n",
    "#                        neg_mean_squared_error,\n",
    "#                        wasserstein_loss,\n",
    "#                         neg_wasserstein_loss,\n",
    "#                        neg_mean_squared_error,\n",
    "#                         'mse'],\n",
    "#                         optimizer=RMSprop(lr=learn_rate_c),\n",
    "#                         loss_weights=[1, 1, 5, 1, 1, 5, 10])\n",
    "#按照目标函数，loss最小化\n",
    "combined.compile(loss=[neg_wasserstein_loss,\n",
    "                        wasserstein_loss,\n",
    "                       'mse',\n",
    "                       neg_wasserstein_loss,\n",
    "                        wasserstein_loss,\n",
    "                       'mse',\n",
    "                        'mse'],\n",
    "                        optimizer=RMSprop(lr=learn_rate_c),\n",
    "                        loss_weights=[1, 1, 5, 1, 1, 5, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_step = []\n",
    "l2_validation = []\n",
    "\n",
    "def train(train_matrix, epochs, batch_size=MAX_BATCH_SIZE, learn_rate=0.01):\n",
    "\n",
    "    min_mse = 999\n",
    "    start_time = datetime.datetime.now()\n",
    "    print(\"train start \"+str(start_time))\n",
    "\n",
    "    # Adversarial loss ground truths\n",
    "#     valid = np.ones((MAX_BATCH_SIZE,) + disc_patch)+np.random.rand(MAX_BATCH_SIZE, patch, patch, 1)/5\n",
    "#     fake = np.zeros((MAX_BATCH_SIZE,) + disc_patch)+np.random.rand(MAX_BATCH_SIZE, patch, patch, 1)/5\n",
    "    valid = np.ones((MAX_BATCH_SIZE,) + disc_patch)\n",
    "    fake = -np.ones((MAX_BATCH_SIZE,) + disc_patch)\n",
    "    dummy = np.ones((MAX_BATCH_SIZE,) + true_volume_shape)\n",
    "\n",
    "    #　周期修改学习率　https://zhuanlan.zhihu.com/p/52084949\n",
    "    for epoch in range(epochs):\n",
    "        if epoch>=50 and epoch % 10 == 0 and epoch != 0:\n",
    "            generator_lr = K.get_value(generator.optimizer.lr)\n",
    "            temporal_discriminator_lr = K.get_value(temporal_discriminator.optimizer.lr)\n",
    "            spatial_discriminator_lr = K.get_value(spatial_discriminator.optimizer.lr)\n",
    "            combined_lr = K.get_value(combined.optimizer.lr)\n",
    "            if generator_lr>0.0001:\n",
    "                K.set_value(generator.optimizer.lr, generator_lr*0.9)\n",
    "            if temporal_discriminator_lr>0.0005:\n",
    "                K.set_value(temporal_discriminator.optimizer.lr, temporal_discriminator_lr*0.9)\n",
    "                K.set_value(spatial_discriminator.optimizer.lr, spatial_discriminator_lr*0.9)\n",
    "            if combined_lr>0.0001:\n",
    "                K.set_value(combined.optimizer.lr, combined_lr*0.9)\n",
    "\n",
    "        for batch_i, (true_volume, history_volume) in enumerate(load_data(train_matrix,batch_size)):\n",
    "            # true_volume 真实待预测路网交通量  history_volume 路网交通量历史数据\n",
    "            #  训练 Discriminator\n",
    "\n",
    "            # 根据历史数据生成预测数据\n",
    "            forecast_volume = generator.predict(history_volume)\n",
    "\n",
    "            epsilon = np.random.uniform(0, 1, size=(MAX_BATCH_SIZE,1,1,1))\n",
    "            interpolation_volume = epsilon*true_volume + (1-epsilon)*forecast_volume\n",
    "            # 训练 the discriminators (original images = real / generated = Fake)\n",
    "            temporal_discriminator.trainable = True\n",
    "            dt_loss_real = temporal_discriminator.train_on_batch([true_volume, history_volume], valid)\n",
    "            dt_loss_fake = temporal_discriminator.train_on_batch([forecast_volume, history_volume], fake)\n",
    "            temporal_discriminator.trainable = False\n",
    "            spatial_discriminator.trainable = True\n",
    "            ds_loss_real = spatial_discriminator.train_on_batch([true_volume, history_volume], valid)\n",
    "            ds_loss_fake = spatial_discriminator.train_on_batch([forecast_volume, history_volume], fake)\n",
    "            spatial_discriminator.trainable = False\n",
    "            dt_loss = 0.5 * np.add(dt_loss_real, dt_loss_fake)\n",
    "            ds_loss = 0.5 * np.add(ds_loss_real, ds_loss_fake)\n",
    "            \n",
    "            #  训练 Generator\n",
    "            g_loss = combined.train_on_batch([true_volume, history_volume, interpolation_volume], [valid, fake, dummy, valid, fake, dummy, true_volume])\n",
    "\n",
    "            elapsed_time = datetime.datetime.now() - start_time\n",
    "\n",
    "        # Plot the progress\n",
    "        y_pred = generator.predict(X_test[:, :, :, 1:])\n",
    "        y_true = X_test[:, :, :, :1]\n",
    "\n",
    "        l2_epoch_validation = l2(y_true, y_pred)\n",
    "        l1_epoch_validation = l1(y_true, y_pred)\n",
    "        \n",
    "        y_pred[y_true==0] += 1\n",
    "        y_true[y_true==0] += 1\n",
    "        mape_epoch_validation = mape(y_true, y_pred)\n",
    "        \n",
    "#         lr_step.append(K.get_value(discriminator.optimizer.lr))\n",
    "        if(l2_epoch_validation<12 and l2_epoch_validation < min_mse):\n",
    "            generator.save_weights('./model/wganpg/tmp/min_generator_wganpg.h5')\n",
    "            spatial_discriminator.save_weights('./model/wganpg/tmp/min_spatial_discriminator_wganpg.h5')\n",
    "            temporal_discriminator.save_weights('./model/wganpg/tmp/min_temporal_discriminator_wganpg.h5')\n",
    "            combined.save_weights('./model/wganpg/tmp/min_combined_wganpg.h5')\n",
    "            min_mse = l2_epoch_validation\n",
    "            \n",
    "        l2_validation.append(l2_epoch_validation)\n",
    "        if epoch%1==0:\n",
    "#             print(\"unet lr:\"+ str(K.get_value(unet.optimizer.lr)))\n",
    "            print (\"[Epoch %d/%d][Dt: %f, Ds: %f, mse: %f, mae: %f, mape: %f, G loss: %f] time: %s\" % (epoch+1, epochs,\n",
    "                                                                    dt_loss[0], ds_loss[0], l2_epoch_validation,\n",
    "                                                                    l1_epoch_validation,\n",
    "                                                                    mape_epoch_validation,\n",
    "                                                                    g_loss[0],\n",
    "                                                                    elapsed_time))\n",
    "        # If at show interval => show generated image samples\n",
    "#             if epoch % show_interval == 0:\n",
    "#                     show_images(dataset_name,epoch, batch_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train start 2019-12-16 15:11:31.778773\n",
      "[Epoch 1/200][Dt: 0.127942, Ds: 0.068623, mse: 67.195795, mae: 46.648702, mape: 18.982771, G loss: 28588.060547] time: 0:03:43.085421\n",
      "[Epoch 2/200][Dt: 0.113218, Ds: 0.019872, mse: 53.769090, mae: 37.174087, mape: 15.157514, G loss: 18850.140625] time: 0:06:33.022207\n",
      "[Epoch 3/200][Dt: 0.121349, Ds: 0.136930, mse: 49.240425, mae: 34.790395, mape: 14.350637, G loss: 14639.798828] time: 0:09:25.643732\n",
      "[Epoch 4/200][Dt: 0.071645, Ds: 0.017191, mse: 52.276190, mae: 37.787050, mape: 15.273900, G loss: 14432.174805] time: 0:12:17.995234\n",
      "[Epoch 5/200][Dt: 0.099851, Ds: 0.050229, mse: 55.731216, mae: 40.880922, mape: 16.364853, G loss: 15066.519531] time: 0:15:08.930040\n",
      "[Epoch 6/200][Dt: 0.062291, Ds: 0.249502, mse: 53.756669, mae: 39.534917, mape: 15.800261, G loss: 12247.383789] time: 0:17:59.387272\n",
      "[Epoch 7/200][Dt: 0.058439, Ds: 0.033904, mse: 62.880312, mae: 46.784979, mape: 18.349749, G loss: 20253.849609] time: 0:20:48.937926\n",
      "[Epoch 8/200][Dt: 0.035311, Ds: 0.080938, mse: 36.665119, mae: 25.720264, mape: 10.424398, G loss: 6390.515625] time: 0:23:38.512572\n",
      "[Epoch 9/200][Dt: 0.026416, Ds: 0.117676, mse: 30.839005, mae: 21.037487, mape: 8.749125, G loss: 5403.597168] time: 0:26:27.978418\n",
      "[Epoch 10/200][Dt: 0.040206, Ds: 0.150988, mse: 21.304585, mae: 13.171381, mape: 6.271817, G loss: 4675.319824] time: 0:29:18.618265\n",
      "[Epoch 11/200][Dt: 0.033397, Ds: 0.489116, mse: 18.985097, mae: 11.204896, mape: 5.774901, G loss: 4540.665527] time: 0:32:09.663851\n",
      "[Epoch 12/200][Dt: 0.030766, Ds: 0.267625, mse: 22.705379, mae: 14.482701, mape: 6.440863, G loss: 4389.349121] time: 0:35:00.948741\n",
      "[Epoch 13/200][Dt: 0.036021, Ds: 0.037810, mse: 22.298851, mae: 14.228484, mape: 6.294449, G loss: 4241.303223] time: 0:37:52.292096\n",
      "[Epoch 14/200][Dt: 0.025294, Ds: 0.214209, mse: 18.029475, mae: 10.571875, mape: 5.554176, G loss: 4253.013672] time: 0:40:42.876730\n",
      "[Epoch 15/200][Dt: 0.265125, Ds: 0.011642, mse: 24.706108, mae: 16.097100, mape: 6.652592, G loss: 4138.134277] time: 0:43:33.061780\n",
      "[Epoch 16/200][Dt: 0.073790, Ds: 0.027539, mse: 22.642226, mae: 14.343359, mape: 6.184758, G loss: 4024.885986] time: 0:46:24.210981\n",
      "[Epoch 17/200][Dt: 0.025498, Ds: 0.011594, mse: 18.049694, mae: 10.631354, mape: 5.308237, G loss: 3892.857666] time: 0:49:16.809769\n",
      "[Epoch 18/200][Dt: 0.022205, Ds: 0.129610, mse: 27.031844, mae: 18.109257, mape: 7.219055, G loss: 4085.482178] time: 0:52:07.566984\n",
      "[Epoch 19/200][Dt: 0.025952, Ds: 0.037012, mse: 17.281656, mae: 10.094655, mape: 5.181031, G loss: 3742.029541] time: 0:54:59.780890\n",
      "[Epoch 20/200][Dt: 0.025053, Ds: 0.099125, mse: 16.526284, mae: 9.670547, mape: 5.088355, G loss: 3598.160156] time: 0:57:54.428810\n",
      "[Epoch 21/200][Dt: 0.026389, Ds: 0.231027, mse: 17.773864, mae: 10.853685, mape: 5.533127, G loss: 3598.583496] time: 1:00:45.240807\n",
      "[Epoch 22/200][Dt: 1.672735, Ds: 0.015598, mse: 16.395830, mae: 9.632733, mape: 5.078610, G loss: 3514.525635] time: 1:03:35.353733\n",
      "[Epoch 23/200][Dt: 0.030592, Ds: 0.373311, mse: 22.672278, mae: 14.919646, mape: 6.247489, G loss: 3706.908691] time: 1:06:27.477616\n",
      "[Epoch 24/200][Dt: 0.588472, Ds: 0.011582, mse: 18.119823, mae: 11.204829, mape: 5.253627, G loss: 3391.583740] time: 1:09:17.492916\n",
      "[Epoch 25/200][Dt: 0.037097, Ds: 0.049880, mse: 23.130638, mae: 15.181219, mape: 6.176593, G loss: 3549.650391] time: 1:12:10.926267\n",
      "[Epoch 26/200][Dt: 0.645005, Ds: 0.051152, mse: 19.186603, mae: 12.181586, mape: 5.581904, G loss: 3283.394775] time: 1:15:03.025390\n",
      "[Epoch 27/200][Dt: 0.030220, Ds: 0.101430, mse: 15.911527, mae: 9.604327, mape: 5.267344, G loss: 3538.616699] time: 1:17:54.739099\n",
      "[Epoch 28/200][Dt: 0.030390, Ds: 0.018698, mse: 17.050954, mae: 10.504174, mape: 5.041343, G loss: 3066.175537] time: 1:20:46.362959\n",
      "[Epoch 29/200][Dt: 0.053006, Ds: 0.000215, mse: 15.176076, mae: 9.122085, mape: 4.929267, G loss: 3126.895996] time: 1:23:37.659659\n",
      "[Epoch 30/200][Dt: 0.599985, Ds: 0.000123, mse: 17.500101, mae: 11.042352, mape: 5.254644, G loss: 3062.616943] time: 1:26:29.099671\n",
      "[Epoch 31/200][Dt: 0.023775, Ds: 0.000114, mse: 15.694310, mae: 9.548359, mape: 4.840134, G loss: 2926.955811] time: 1:29:21.517737\n",
      "[Epoch 32/200][Dt: 0.025334, Ds: 0.000124, mse: 15.237086, mae: 9.137837, mape: 4.816692, G loss: 2899.980469] time: 1:32:19.640343\n",
      "[Epoch 33/200][Dt: 0.043897, Ds: 0.000129, mse: 14.633715, mae: 8.760609, mape: 4.769941, G loss: 2905.448975] time: 1:35:10.653726\n",
      "[Epoch 34/200][Dt: 0.032845, Ds: 0.000130, mse: 16.850275, mae: 10.614816, mape: 5.047942, G loss: 2775.722656] time: 1:38:01.790488\n",
      "[Epoch 35/200][Dt: 0.027673, Ds: 0.000125, mse: 15.378492, mae: 9.497138, mape: 5.124030, G loss: 2983.757080] time: 1:40:53.560032\n",
      "[Epoch 36/200][Dt: 0.026282, Ds: 0.000118, mse: 15.735864, mae: 9.816636, mape: 4.765967, G loss: 2740.676758] time: 1:43:45.794572\n",
      "[Epoch 37/200][Dt: 0.024386, Ds: 0.000126, mse: 16.632587, mae: 10.565632, mape: 5.009643, G loss: 2660.833252] time: 1:46:36.842121\n",
      "[Epoch 38/200][Dt: 0.024524, Ds: 0.000134, mse: 14.575674, mae: 8.816800, mape: 4.689156, G loss: 2653.552734] time: 1:49:27.829123\n",
      "[Epoch 39/200][Dt: 0.024266, Ds: 0.000187, mse: 13.907708, mae: 8.404205, mape: 4.539423, G loss: 2597.273438] time: 1:52:19.160982\n",
      "[Epoch 40/200][Dt: 0.019663, Ds: 0.000491, mse: 14.059771, mae: 8.515238, mape: 4.588726, G loss: 2586.997314] time: 1:55:09.747815\n",
      "[Epoch 41/200][Dt: 0.041964, Ds: 0.000291, mse: 14.496260, mae: 8.809964, mape: 4.571617, G loss: 2551.132080] time: 1:57:59.824356\n",
      "[Epoch 42/200][Dt: 0.034445, Ds: 0.000258, mse: 15.888234, mae: 10.002553, mape: 4.802806, G loss: 2589.146973] time: 2:00:51.278844\n",
      "[Epoch 43/200][Dt: 0.019857, Ds: 0.001164, mse: 13.515966, mae: 8.164927, mape: 4.395120, G loss: 2496.788818] time: 2:03:42.416126\n",
      "[Epoch 44/200][Dt: 0.019159, Ds: 0.020228, mse: 15.299101, mae: 9.539938, mape: 4.684879, G loss: 2465.089355] time: 2:06:33.125955\n",
      "[Epoch 45/200][Dt: 0.024491, Ds: 0.000040, mse: 27.205625, mae: 18.859293, mape: 7.206355, G loss: 3603.520020] time: 2:09:23.542303\n",
      "[Epoch 46/200][Dt: 0.019505, Ds: 0.000038, mse: 13.542781, mae: 8.153976, mape: 4.362447, G loss: 2431.458496] time: 2:12:14.605469\n",
      "[Epoch 47/200][Dt: 0.018661, Ds: 0.000041, mse: 14.492951, mae: 8.977607, mape: 4.743672, G loss: 2538.628906] time: 2:15:05.180011\n",
      "[Epoch 48/200][Dt: 0.017562, Ds: 0.000044, mse: 14.208717, mae: 8.515176, mape: 4.381697, G loss: 2329.391357] time: 2:17:55.951071\n",
      "[Epoch 49/200][Dt: 0.018904, Ds: 0.000047, mse: 13.660644, mae: 8.275514, mape: 4.462731, G loss: 2317.294434] time: 2:20:47.028834\n",
      "[Epoch 50/200][Dt: 0.071593, Ds: 0.000050, mse: 20.130761, mae: 13.306511, mape: 5.468363, G loss: 2517.342529] time: 2:23:38.115227\n",
      "[Epoch 51/200][Dt: 0.025693, Ds: 0.000047, mse: 13.224075, mae: 7.952852, mape: 4.204832, G loss: 2319.240967] time: 2:26:33.090436\n",
      "[Epoch 52/200][Dt: 0.019951, Ds: 0.000049, mse: 22.549654, mae: 15.268486, mape: 6.272592, G loss: 2689.308350] time: 2:29:23.428744\n",
      "[Epoch 53/200][Dt: 0.018134, Ds: 0.000053, mse: 17.399509, mae: 11.180704, mape: 4.893138, G loss: 2380.959717] time: 2:32:14.734879\n",
      "[Epoch 54/200][Dt: 0.020238, Ds: 0.000083, mse: 16.196404, mae: 10.156457, mape: 4.667844, G loss: 2368.290771] time: 2:35:05.720823\n",
      "[Epoch 55/200][Dt: 0.019686, Ds: 0.000102, mse: 18.601225, mae: 12.090104, mape: 5.123142, G loss: 2533.275635] time: 2:37:56.959296\n",
      "[Epoch 56/200][Dt: 0.020939, Ds: 0.000156, mse: 12.967482, mae: 7.770735, mape: 4.213510, G loss: 2259.046631] time: 2:40:48.792026\n",
      "[Epoch 57/200][Dt: 0.015500, Ds: 0.000194, mse: 14.833798, mae: 9.117502, mape: 4.423810, G loss: 2215.116455] time: 2:43:41.215648\n",
      "[Epoch 58/200][Dt: 0.013530, Ds: 0.000275, mse: 13.672909, mae: 8.494116, mape: 4.609019, G loss: 2269.019287] time: 2:46:33.912286\n",
      "[Epoch 59/200][Dt: 0.014455, Ds: 0.000281, mse: 18.034945, mae: 11.567210, mape: 5.021809, G loss: 2941.029053] time: 2:49:25.851506\n",
      "[Epoch 60/200][Dt: 0.014151, Ds: 0.000357, mse: 14.025474, mae: 8.301403, mape: 4.092666, G loss: 2096.743164] time: 2:52:16.589882\n",
      "[Epoch 61/200][Dt: 0.017907, Ds: 0.000420, mse: 15.026222, mae: 9.251668, mape: 4.370385, G loss: 2180.456055] time: 2:55:09.980131\n",
      "[Epoch 62/200][Dt: 0.015042, Ds: 0.000275, mse: 13.803522, mae: 8.221736, mape: 4.123842, G loss: 2047.464111] time: 2:58:01.464488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 63/200][Dt: 0.012774, Ds: 0.000284, mse: 13.962219, mae: 8.481581, mape: 4.221798, G loss: 2065.988525] time: 3:00:52.134888\n",
      "[Epoch 64/200][Dt: 0.019385, Ds: 0.000280, mse: 12.599076, mae: 7.549550, mape: 4.212799, G loss: 2110.810059] time: 3:03:44.708102\n",
      "[Epoch 65/200][Dt: 0.014539, Ds: 0.000270, mse: 20.383188, mae: 13.717934, mape: 5.696064, G loss: 2839.990234] time: 3:06:36.211216\n",
      "[Epoch 66/200][Dt: 0.013303, Ds: 0.000305, mse: 12.974719, mae: 7.934083, mape: 4.476236, G loss: 2189.883301] time: 3:09:28.039053\n",
      "[Epoch 67/200][Dt: 0.016604, Ds: 0.000255, mse: 15.833541, mae: 9.781916, mape: 4.456772, G loss: 2204.685791] time: 3:12:20.016127\n",
      "[Epoch 68/200][Dt: 0.013423, Ds: 0.000300, mse: 18.462959, mae: 11.807880, mape: 4.947887, G loss: 2426.237061] time: 3:15:13.211407\n",
      "[Epoch 69/200][Dt: 0.013357, Ds: 0.000283, mse: 14.581757, mae: 9.642268, mape: 5.297415, G loss: 2379.273438] time: 3:18:07.515275\n",
      "[Epoch 70/200][Dt: 0.016130, Ds: 0.000320, mse: 19.116388, mae: 12.344218, mape: 5.097271, G loss: 2548.670166] time: 3:20:59.560383\n",
      "[Epoch 71/200][Dt: 0.012150, Ds: 0.000277, mse: 20.647994, mae: 13.768567, mape: 5.634061, G loss: 3038.031006] time: 3:23:52.652410\n",
      "[Epoch 72/200][Dt: 0.013030, Ds: 0.177082, mse: 13.613776, mae: 8.202297, mape: 4.064397, G loss: 1896.001831] time: 3:26:43.293320\n",
      "[Epoch 73/200][Dt: 0.012183, Ds: 0.000924, mse: 12.431245, mae: 7.545064, mape: 4.212419, G loss: 1933.706909] time: 3:29:33.779527\n",
      "[Epoch 74/200][Dt: 0.016689, Ds: 0.000022, mse: 12.459964, mae: 7.403073, mape: 4.021772, G loss: 1924.599854] time: 3:32:24.473627\n",
      "[Epoch 75/200][Dt: 0.009543, Ds: 0.000023, mse: 15.725192, mae: 9.706547, mape: 4.394491, G loss: 1904.023682] time: 3:35:15.218265\n",
      "[Epoch 76/200][Dt: 0.012516, Ds: 0.000025, mse: 13.148552, mae: 7.893821, mape: 4.026305, G loss: 1862.885254] time: 3:38:06.032736\n",
      "[Epoch 77/200][Dt: 0.011436, Ds: 0.000026, mse: 15.030840, mae: 9.951504, mape: 5.159099, G loss: 2545.917236] time: 3:40:56.757051\n",
      "[Epoch 78/200][Dt: 0.012413, Ds: 0.000027, mse: 11.906933, mae: 7.156475, mape: 3.956269, G loss: 1837.862061] time: 3:43:47.291975\n",
      "[Epoch 79/200][Dt: 0.010859, Ds: 0.000028, mse: 13.153408, mae: 7.793919, mape: 3.974815, G loss: 1782.728516] time: 3:46:48.718124\n",
      "[Epoch 80/200][Dt: 0.020656, Ds: 0.000030, mse: 15.610660, mae: 9.890693, mape: 4.479710, G loss: 2064.697021] time: 3:49:39.403949\n",
      "[Epoch 81/200][Dt: 0.013234, Ds: 0.000029, mse: 14.972210, mae: 9.935410, mape: 5.210287, G loss: 2437.228760] time: 3:52:30.514299\n",
      "[Epoch 82/200][Dt: 0.015783, Ds: 0.000034, mse: 12.452116, mae: 7.566959, mape: 4.141477, G loss: 1903.925903] time: 3:55:21.600775\n",
      "[Epoch 83/200][Dt: 0.018748, Ds: 0.000048, mse: 12.773749, mae: 7.984183, mape: 4.390055, G loss: 1853.126465] time: 3:58:12.296652\n",
      "[Epoch 84/200][Dt: 0.009855, Ds: 0.000080, mse: 12.200115, mae: 7.222899, mape: 3.836258, G loss: 1744.271484] time: 4:01:03.063105\n",
      "[Epoch 85/200][Dt: 0.012029, Ds: 0.000124, mse: 24.534812, mae: 17.055084, mape: 6.654912, G loss: 2843.331787] time: 4:03:53.963594\n",
      "[Epoch 86/200][Dt: 0.012753, Ds: 0.000144, mse: 12.033025, mae: 7.142070, mape: 3.913484, G loss: 1761.698364] time: 4:06:44.866640\n",
      "[Epoch 87/200][Dt: 0.008831, Ds: 0.000163, mse: 11.844231, mae: 7.173799, mape: 3.930034, G loss: 1738.084229] time: 4:09:35.634095\n",
      "[Epoch 88/200][Dt: 0.066909, Ds: 0.000172, mse: 12.630913, mae: 7.347363, mape: 3.859603, G loss: 1662.770752] time: 4:12:26.911273\n",
      "[Epoch 89/200][Dt: 0.019426, Ds: 0.000178, mse: 12.337538, mae: 7.556609, mape: 4.121136, G loss: 1803.798096] time: 4:15:17.202908\n",
      "[Epoch 90/200][Dt: 0.011744, Ds: 0.000187, mse: 12.221093, mae: 7.137803, mape: 3.749748, G loss: 1648.502686] time: 4:18:07.684771\n",
      "[Epoch 91/200][Dt: 0.007294, Ds: 0.000155, mse: 12.953717, mae: 8.122127, mape: 4.350590, G loss: 1757.752686] time: 4:20:57.941995\n",
      "[Epoch 92/200][Dt: 0.008791, Ds: 0.000145, mse: 16.062734, mae: 10.266510, mape: 4.553597, G loss: 1827.745117] time: 4:23:48.297995\n",
      "[Epoch 93/200][Dt: 0.010207, Ds: 0.000139, mse: 11.746595, mae: 7.019780, mape: 3.883470, G loss: 1746.993530] time: 4:26:38.728196\n",
      "[Epoch 94/200][Dt: 0.013370, Ds: 0.000144, mse: 12.491466, mae: 7.354825, mape: 3.955130, G loss: 1656.822632] time: 4:29:30.426951\n",
      "[Epoch 95/200][Dt: 0.007116, Ds: 0.000159, mse: 12.523940, mae: 7.271543, mape: 3.803431, G loss: 1587.740356] time: 4:32:20.827336\n",
      "[Epoch 96/200][Dt: 0.008339, Ds: 0.000166, mse: 13.167213, mae: 7.862141, mape: 3.838229, G loss: 1633.637695] time: 4:35:11.181072\n",
      "[Epoch 97/200][Dt: 0.012354, Ds: 0.000176, mse: 12.580988, mae: 7.895679, mape: 4.296771, G loss: 1707.345337] time: 4:38:01.703202\n",
      "[Epoch 98/200][Dt: 0.012304, Ds: 0.000180, mse: 12.257350, mae: 7.518565, mape: 4.126609, G loss: 1684.500732] time: 4:40:52.203378\n",
      "[Epoch 99/200][Dt: 0.008528, Ds: 0.000146, mse: 12.721358, mae: 7.343516, mape: 3.745004, G loss: 1539.860840] time: 4:43:42.980265\n",
      "[Epoch 100/200][Dt: 0.011854, Ds: 0.000132, mse: 11.729314, mae: 6.766600, mape: 3.593772, G loss: 1523.020752] time: 4:46:34.326234\n",
      "[Epoch 101/200][Dt: 0.010276, Ds: 0.000137, mse: 14.734758, mae: 9.117400, mape: 4.150274, G loss: 1666.630615] time: 4:49:26.356843\n",
      "[Epoch 102/200][Dt: 0.008185, Ds: 0.000147, mse: 12.267497, mae: 7.390172, mape: 4.015516, G loss: 1627.415405] time: 4:52:20.786675\n",
      "[Epoch 103/200][Dt: 0.009524, Ds: 0.000142, mse: 12.688475, mae: 7.405680, mape: 3.764361, G loss: 1506.835693] time: 4:55:14.771157\n",
      "[Epoch 104/200][Dt: 0.010365, Ds: 0.000129, mse: 12.134378, mae: 7.007851, mape: 3.684159, G loss: 1528.458740] time: 4:58:05.904157\n",
      "[Epoch 105/200][Dt: 0.011309, Ds: 0.000136, mse: 12.374376, mae: 7.706901, mape: 4.171932, G loss: 1515.081665] time: 5:01:01.334953\n",
      "[Epoch 106/200][Dt: 0.010239, Ds: 0.000148, mse: 12.614867, mae: 7.865001, mape: 4.262326, G loss: 1688.511353] time: 5:03:54.238145\n",
      "[Epoch 107/200][Dt: 0.009534, Ds: 0.000146, mse: 13.077571, mae: 8.338003, mape: 4.425947, G loss: 1634.199951] time: 5:06:46.410790\n",
      "[Epoch 108/200][Dt: 0.010657, Ds: 0.000196, mse: 11.987845, mae: 6.890857, mape: 3.720780, G loss: 1499.605713] time: 5:09:36.942192\n",
      "[Epoch 109/200][Dt: 0.012291, Ds: 0.000143, mse: 11.781649, mae: 6.751643, mape: 3.579580, G loss: 1457.895142] time: 5:12:27.305711\n",
      "[Epoch 110/200][Dt: 0.010152, Ds: 0.000132, mse: 12.914504, mae: 7.541097, mape: 3.682538, G loss: 1515.434082] time: 5:15:17.299768\n",
      "[Epoch 111/200][Dt: 0.011702, Ds: 0.000143, mse: 11.484032, mae: 6.717124, mape: 3.671964, G loss: 1474.592896] time: 5:18:06.549183\n",
      "[Epoch 112/200][Dt: 0.009607, Ds: 0.000130, mse: 12.813755, mae: 8.009332, mape: 4.139413, G loss: 1576.071533] time: 5:20:59.955362\n",
      "[Epoch 113/200][Dt: 0.007145, Ds: 0.000135, mse: 11.768030, mae: 6.813673, mape: 3.627141, G loss: 1434.555054] time: 5:23:50.281004\n",
      "[Epoch 114/200][Dt: 0.015256, Ds: 0.000183, mse: 11.436885, mae: 6.688502, mape: 3.621820, G loss: 1471.029419] time: 5:26:40.258942\n",
      "[Epoch 115/200][Dt: 0.008739, Ds: 0.000161, mse: 17.825831, mae: 11.855569, mape: 5.005644, G loss: 1890.512329] time: 5:29:31.898681\n",
      "[Epoch 116/200][Dt: 0.008702, Ds: 0.000160, mse: 13.529674, mae: 8.755796, mape: 4.470573, G loss: 1678.208496] time: 5:32:24.251111\n",
      "[Epoch 117/200][Dt: 0.010634, Ds: 0.000142, mse: 12.810676, mae: 7.457121, mape: 3.662896, G loss: 1410.969604] time: 5:35:14.930969\n",
      "[Epoch 118/200][Dt: 0.009099, Ds: 0.000146, mse: 12.185382, mae: 7.209218, mape: 3.844306, G loss: 1484.169556] time: 5:38:05.700292\n",
      "[Epoch 119/200][Dt: 0.013839, Ds: 0.000139, mse: 12.559435, mae: 7.250378, mape: 3.588253, G loss: 1409.826782] time: 5:40:56.573796\n",
      "[Epoch 120/200][Dt: 0.011389, Ds: 0.000150, mse: 11.620242, mae: 6.862294, mape: 3.744250, G loss: 1474.323730] time: 5:43:45.247078\n",
      "[Epoch 121/200][Dt: 0.007763, Ds: 0.000148, mse: 12.938606, mae: 8.247883, mape: 4.207905, G loss: 1543.128418] time: 5:46:34.792406\n",
      "[Epoch 122/200][Dt: 0.008259, Ds: 0.000156, mse: 12.879831, mae: 7.606998, mape: 3.690323, G loss: 1380.895386] time: 5:49:24.305681\n",
      "[Epoch 123/200][Dt: 0.007943, Ds: 0.000162, mse: 11.666913, mae: 6.651942, mape: 3.420400, G loss: 1373.009033] time: 5:52:13.545207\n",
      "[Epoch 124/200][Dt: 0.008616, Ds: 0.000161, mse: 11.557760, mae: 6.670564, mape: 3.542851, G loss: 1364.637695] time: 5:55:02.589653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 125/200][Dt: 0.006820, Ds: 0.000139, mse: 13.176470, mae: 8.533642, mape: 4.416020, G loss: 1699.206055] time: 5:57:51.743051\n",
      "[Epoch 126/200][Dt: 0.009403, Ds: 0.000164, mse: 12.066570, mae: 7.259082, mape: 3.780733, G loss: 1405.660034] time: 6:00:40.744760\n",
      "[Epoch 127/200][Dt: 0.015508, Ds: 0.000160, mse: 12.173751, mae: 6.942093, mape: 3.552321, G loss: 1342.791260] time: 6:03:30.882584\n",
      "[Epoch 128/200][Dt: 0.009905, Ds: 0.000141, mse: 13.582811, mae: 8.739257, mape: 4.320291, G loss: 1431.123657] time: 6:06:19.936903\n",
      "[Epoch 129/200][Dt: 0.069923, Ds: 0.000135, mse: 11.504374, mae: 6.749068, mape: 3.742879, G loss: 1406.042725] time: 6:09:08.764568\n",
      "[Epoch 130/200][Dt: 0.011692, Ds: 0.000138, mse: 11.691753, mae: 6.690093, mape: 3.468912, G loss: 1353.281128] time: 6:11:58.460491\n",
      "[Epoch 131/200][Dt: 0.010025, Ds: 0.000138, mse: 14.966062, mae: 10.015233, mape: 4.698442, G loss: 1760.187622] time: 6:14:47.638529\n",
      "[Epoch 132/200][Dt: 0.006150, Ds: 0.000143, mse: 11.763529, mae: 6.733355, mape: 3.445538, G loss: 1336.437012] time: 6:17:36.623894\n",
      "[Epoch 133/200][Dt: 0.010776, Ds: 0.000147, mse: 16.692160, mae: 11.429377, mape: 5.340980, G loss: 1810.604492] time: 6:20:26.938082\n",
      "[Epoch 134/200][Dt: 0.008920, Ds: 0.000141, mse: 12.179709, mae: 6.930833, mape: 3.511453, G loss: 1318.003784] time: 6:23:16.123876\n",
      "[Epoch 135/200][Dt: 0.010147, Ds: 0.000149, mse: 12.382067, mae: 7.112202, mape: 3.486573, G loss: 1325.946045] time: 6:26:06.774266\n",
      "[Epoch 136/200][Dt: 0.008522, Ds: 0.000150, mse: 11.573389, mae: 6.546880, mape: 3.357443, G loss: 1303.879883] time: 6:28:56.738047\n",
      "[Epoch 137/200][Dt: 0.007803, Ds: 0.000162, mse: 12.238741, mae: 7.498341, mape: 3.944345, G loss: 1491.354614] time: 6:31:46.413150\n",
      "[Epoch 138/200][Dt: 0.007817, Ds: 0.000158, mse: 11.488621, mae: 6.486954, mape: 3.450151, G loss: 1316.588501] time: 6:34:35.984831\n",
      "[Epoch 139/200][Dt: 0.011327, Ds: 0.000146, mse: 11.718102, mae: 6.619374, mape: 3.418075, G loss: 1300.156616] time: 6:37:25.712529\n",
      "[Epoch 140/200][Dt: 0.009610, Ds: 0.000151, mse: 11.649644, mae: 6.776195, mape: 3.526048, G loss: 1344.652100] time: 6:40:16.775275\n",
      "[Epoch 141/200][Dt: 0.009309, Ds: 0.000151, mse: 11.351222, mae: 6.704466, mape: 3.679326, G loss: 1382.266235] time: 6:43:06.899395\n",
      "[Epoch 142/200][Dt: 0.010461, Ds: 0.000152, mse: 11.988877, mae: 6.850947, mape: 3.407265, G loss: 1293.303589] time: 6:45:58.884156\n",
      "[Epoch 143/200][Dt: 0.011676, Ds: 0.000150, mse: 16.059387, mae: 10.216935, mape: 4.438157, G loss: 1787.611572] time: 6:48:49.536205\n",
      "[Epoch 144/200][Dt: 0.007142, Ds: 0.000148, mse: 11.684432, mae: 6.605136, mape: 3.487914, G loss: 1290.493774] time: 6:51:38.699136\n",
      "[Epoch 145/200][Dt: 0.007454, Ds: 0.000150, mse: 12.133204, mae: 6.849024, mape: 3.397696, G loss: 1299.324829] time: 6:54:27.835195\n",
      "[Epoch 146/200][Dt: 0.007987, Ds: 0.000138, mse: 11.188288, mae: 6.504854, mape: 3.459156, G loss: 1322.207153] time: 6:57:17.243248\n",
      "[Epoch 147/200][Dt: 0.009938, Ds: 0.000145, mse: 12.913648, mae: 8.127665, mape: 4.204023, G loss: 1562.706909] time: 7:00:08.158714\n",
      "[Epoch 148/200][Dt: 0.008153, Ds: 0.000145, mse: 13.595761, mae: 8.182170, mape: 3.730045, G loss: 1347.028809] time: 7:03:00.190923\n",
      "[Epoch 149/200][Dt: 0.009680, Ds: 0.000145, mse: 11.651869, mae: 6.518965, mape: 3.334472, G loss: 1273.659668] time: 7:05:51.523860\n",
      "[Epoch 150/200][Dt: 0.007290, Ds: 0.000148, mse: 12.299405, mae: 6.984257, mape: 3.407445, G loss: 1290.017822] time: 7:08:45.266786\n",
      "[Epoch 151/200][Dt: 0.007326, Ds: 0.000152, mse: 12.784807, mae: 8.133220, mape: 4.039872, G loss: 1379.102539] time: 7:11:38.318137\n",
      "[Epoch 152/200][Dt: 0.011902, Ds: 0.000154, mse: 11.459538, mae: 6.400646, mape: 3.278713, G loss: 1263.103027] time: 7:14:31.015873\n",
      "[Epoch 153/200][Dt: 0.008206, Ds: 0.000160, mse: 11.031811, mae: 6.317520, mape: 3.418865, G loss: 1286.271240] time: 7:17:24.310327\n",
      "[Epoch 154/200][Dt: 0.009119, Ds: 0.000149, mse: 11.542189, mae: 6.529012, mape: 3.447492, G loss: 1291.757202] time: 7:20:16.572823\n",
      "[Epoch 155/200][Dt: 0.009535, Ds: 0.000144, mse: 19.048522, mae: 13.087284, mape: 5.386603, G loss: 1613.266724] time: 7:23:07.036241\n",
      "[Epoch 156/200][Dt: 0.007792, Ds: 0.000143, mse: 11.320261, mae: 6.433276, mape: 3.359853, G loss: 1295.326538] time: 7:25:56.479436\n",
      "[Epoch 157/200][Dt: 0.008598, Ds: 0.000141, mse: 13.639508, mae: 8.982182, mape: 4.508311, G loss: 1487.799316] time: 7:28:45.476355\n",
      "[Epoch 158/200][Dt: 0.012219, Ds: 0.000144, mse: 11.499882, mae: 6.485308, mape: 3.283965, G loss: 1244.682617] time: 7:31:36.430067\n",
      "[Epoch 159/200][Dt: 0.010978, Ds: 0.000145, mse: 12.148795, mae: 6.870002, mape: 3.381876, G loss: 1261.897095] time: 7:34:25.663914\n",
      "[Epoch 160/200][Dt: 0.007857, Ds: 0.000153, mse: 11.319944, mae: 6.386984, mape: 3.315383, G loss: 1246.663818] time: 7:37:18.124569\n",
      "[Epoch 161/200][Dt: 0.008420, Ds: 0.000147, mse: 11.561485, mae: 6.485165, mape: 3.325107, G loss: 1239.039673] time: 7:40:07.860840\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-f2845cdbc646>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMAX_BATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearn_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearn_rate_c\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-16-044e0a6a2153>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(train_matrix, epochs, batch_size, learn_rate)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[1;31m#  训练 Generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m             \u001b[0mg_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcombined\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrue_volume\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory_volume\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolation_volume\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvalid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfake\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdummy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfake\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdummy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_volume\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1213\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1214\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1215\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1216\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2664\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2666\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2667\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2668\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2635\u001b[0m                                 session)\n\u001b[1;32m-> 2636\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2637\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(X_train, epochs=200, batch_size=MAX_BATCH_SIZE, learn_rate=learn_rate_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator.save_weights('./model/wganpg/generator_167epoch_11rmse.h5')\n",
    "# discriminator.save_weights('./model/wganpg/discriminator_167epoch_11rmse.h5')\n",
    "# combined.save_weights('./model/wganpg/combined_167epoch_11rmse.h5')\n",
    "\n",
    "generator.load_weights('./model/wganpg/tmp/min_generator_wganpg.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.031811488857523"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = generator.predict(X_test[:, :, :, 1:])\n",
    "y_true = X_test[:, :, :, :1]\n",
    "\n",
    "l2(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': [<matplotlib.lines.Line2D at 0x24e30721d30>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x24e30729780>,\n",
       "  <matplotlib.lines.Line2D at 0x24e30729ba8>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x24e30732438>],\n",
       " 'means': [],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x24e30729fd0>],\n",
       " 'whiskers': [<matplotlib.lines.Line2D at 0x24e30721e80>,\n",
       "  <matplotlib.lines.Line2D at 0x24e30729358>]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24e3069d470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://matplotlib.org/gallery/pyplots/boxplot_demo_pyplot.html#sphx-glr-gallery-pyplots-boxplot-demo-pyplot-py\n",
    "plt.boxplot(np.sqrt(np.mean(np.square(y_true - y_pred), axis=0)).reshape(1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': [<matplotlib.lines.Line2D at 0x24e306b8d30>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x24e306c1780>,\n",
       "  <matplotlib.lines.Line2D at 0x24e306c1ba8>],\n",
       " 'fliers': [],\n",
       " 'means': [],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x24e306c1fd0>],\n",
       " 'whiskers': [<matplotlib.lines.Line2D at 0x24e306b8e80>,\n",
       "  <matplotlib.lines.Line2D at 0x24e306c1358>]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24e312b3c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(np.mean(np.abs(y_true - y_pred), axis=0).reshape(1024), showfliers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.sqrt(np.sum(np.mean(np.square(y_true - y_pred), axis=0))/1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2(y_true, y_pred+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y = y_true.reshape(-1,)[1600:1700]\n",
    "x = np.linspace(0, len(y), len(y))\n",
    "\n",
    "yi = y_pred.reshape(-1,)[1600:1700]\n",
    "xi = np.linspace(0, len(yi), len(yi))\n",
    "fig, ax = plt.subplots(figsize=(25, 6))\n",
    "# ax.plot(x, y, '.', linewidth=1, markersize=10)\n",
    "lines = plt.plot(xi, yi, 'k^--', x, y, 'ro-',linewidth=1, markersize=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yi = l2_validation\n",
    "xi = np.linspace(0, len(yi), len(yi))\n",
    "\n",
    "y = [i*10000 for i in lr_step]\n",
    "x = np.linspace(0, len(y), len(y))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "lines = plt.plot(x, y, 'ko-', xi, yi, 'k^--', linewidth=1, markersize=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = lr_step\n",
    "x = np.linspace(0, len(y), len(y))\n",
    "# fig, ax = plt.subplots(figsize=(6, 6))\n",
    "# lines = plt.plot(x, y, 'ko-', linewidth=1, markersize=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_true.reshape(-1,)[3600:3700]\n",
    "x = np.linspace(0, len(y), len(y))\n",
    "\n",
    "yi = y_pred.reshape(-1,)[3600:3700]\n",
    "xi = np.linspace(0, len(yi), len(yi))\n",
    "fig, ax = plt.subplots(figsize=(25, 6))\n",
    "ax.plot(x, y, '.', linewidth=1, markersize=10)\n",
    "lines = plt.plot(xi, yi, 'k^--', x, y, 'ro-',linewidth=1, markersize=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = 0\n",
    "y = y_true.reshape(-1,)[start_time: start_time+100]\n",
    "x = np.linspace(0, len(y), len(y))\n",
    "\n",
    "yi = y_pred.reshape(-1,)[start_time: start_time+100]\n",
    "xi = np.linspace(0, len(yi), len(yi))\n",
    "fig, ax = plt.subplots(figsize=(25, 6))\n",
    "# ax.plot(x, y, '.', linewidth=1, markersize=10)\n",
    "lines = plt.plot(xi, yi, 'k^--', x, y, 'ro-',linewidth=1, markersize=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
