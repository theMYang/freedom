{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import scipy\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import transform\n",
    "\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, concatenate, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D, Add, Subtract, ConvLSTM2D\n",
    "from keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D ,AveragePooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU, ELU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam, Nadam, RMSprop\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.merge import _Merge\n",
    "from keras.engine.topology import Layer\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "import gc\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, TensorBoard\n",
    "from keras import backend as K\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from keras.models import load_model  \n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载  预处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交通矩阵为 matrix_length*matrix_length\n",
    "matrix_length = 32\n",
    "\n",
    "matrix_df = pd.read_csv('./data/trafficV_M.csv', index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def createTrainArray(week_history_num=0, minute_history_num=0):\n",
    "#     week_delta_list = [pd.Timedelta(i+1, unit='W') for i in range(week_history_num)]\n",
    "#     minute_delta_list = [pd.Timedelta((i+1)*15, unit='m') for i in range(minute_history_num)]\n",
    "#     # 参考历史数据时间点list\n",
    "#     delta_list = week_delta_list+minute_delta_list\n",
    "#     print(delta_list)\n",
    "    \n",
    "#     set_up_time = pd.Timedelta(week_history_num, unit='W')\n",
    "#     # 根据历史数据选取多少，重新构建数据集\n",
    "#     # 相当于去除最开始week_history_num个周的数据，因为这些数据无法找到更前的数据\n",
    "#     train_df = matrix_df.truncate(before=matrix_df.index.min() + set_up_time)\n",
    "    \n",
    "#     train_ago_array_tuple = tuple([np.array(matrix_df.loc[train_df.index - i]).reshape(-1, matrix_length, matrix_length, 1) for i in delta_list])\n",
    "#     train_df = np.array(train_df).reshape(-1, matrix_length, matrix_length, 1)\n",
    "#     # concatenate保持 待修复数据在前，参考历史数据在后。与random_mask函数生成mask相一致\n",
    "#     train_array = np.concatenate((train_df,)+train_ago_array_tuple, axis=3)\n",
    "#     print(train_array.shape)\n",
    "#     return train_array\n",
    "\n",
    "\n",
    "\n",
    "def createTrainArray(week_history_num=0, minute_history_num=0):\n",
    "    week_delta_list = [pd.Timedelta(week_history_num-i, unit='W') for i in range(week_history_num)]\n",
    "    minute_delta_list = [pd.Timedelta((minute_history_num-i)*15, unit='m') for i in range(minute_history_num)]\n",
    "    # 参考历史数据时间点list\n",
    "    delta_list = minute_delta_list+week_delta_list\n",
    "    print(delta_list)\n",
    "    \n",
    "    set_up_time = pd.Timedelta(week_history_num, unit='W')\n",
    "    # 根据历史数据选取多少，重新构建数据集\n",
    "    # 相当于去除最开始week_history_num个周的数据，因为这些数据无法找到更前的数据\n",
    "    train_df = matrix_df.truncate(before=matrix_df.index.min() + set_up_time)\n",
    "    \n",
    "    train_ago_array_tuple = tuple([np.array(matrix_df.loc[train_df.index - i]).reshape(-1, matrix_length, matrix_length, 1) for i in delta_list])\n",
    "    train_df = np.array(train_df).reshape(-1, matrix_length, matrix_length, 1)\n",
    "    # concatenate保持 待修复数据在前，参考历史数据在后。与random_mask函数生成mask相一致\n",
    "    train_array = np.concatenate((train_df,)+train_ago_array_tuple, axis=3)\n",
    "    print(train_array.shape)\n",
    "    return train_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Timedelta('0 days 00:45:00'), Timedelta('0 days 00:30:00'), Timedelta('0 days 00:15:00'), Timedelta('14 days 00:00:00'), Timedelta('7 days 00:00:00')]\n",
      "(16032, 32, 32, 6)\n"
     ]
    }
   ],
   "source": [
    "week_history_num = 2\n",
    "minute_history_num = 3\n",
    "\n",
    "channel_num = week_history_num +minute_history_num +1\n",
    "smooth_time = channel_num-1\n",
    "\n",
    "# train_array为(16704, 32, 32, 3)，16704个矩阵，32*32采集点，3从上到下为当前时间，上一周，上一15min\n",
    "train_array = createTrainArray(week_history_num, minute_history_num)\n",
    "X_train, X_test = train_test_split(train_array, test_size = 0.1, random_state=42, shuffle=False)\n",
    "# X_train, X_val = train_test_split(train_array, test_size = 0.1, random_state=42, shuffle=False) # 不shuffle可用于查看数据正确性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14428, 32, 32, 6), (1604, 32, 32, 6))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225, 25)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_BATCH_SIZE = 64\n",
    "epoch_steps = X_train.shape[0] // MAX_BATCH_SIZE\n",
    "test_steps = X_test.shape[0] // MAX_BATCH_SIZE\n",
    "epoch_steps, test_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "def load_data(volume_matrix, batch_size=MAX_BATCH_SIZE):\n",
    "    n_batches=batch_size\n",
    "    len_of_matrix = len(volume_matrix)\n",
    "\n",
    "    batch_i = 0\n",
    "    while ((batch_i+1)*batch_size < len_of_matrix):\n",
    "        batch_matrix = volume_matrix[batch_i*batch_size: (batch_i+1)*batch_size]\n",
    "        true_volume, history_volume = batch_matrix[:, :, :, :1], batch_matrix[:, :, :, 1:]\n",
    "#         history_volume = normalization(history_volume)\n",
    "        batch_i+=1\n",
    "\n",
    "        yield true_volume, history_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def l2(y_true, y_pred):\n",
    "    return math.sqrt(np.sum(np.mean(np.square(y_true - y_pred), axis=0))/1024)\n",
    "\n",
    "def l1(y_true, y_pred):\n",
    "    return np.sum(np.mean(np.abs(y_true - y_pred), axis=0))/(matrix_length*matrix_length)\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    return np.sum(np.mean((np.abs(y_true - y_pred)/y_true)*100, axis=0))/(matrix_length*matrix_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算D输出valid大小（PatchGAN）\n",
    "patch = 4\n",
    "disc_patch = (patch, patch, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (3, 3)\n",
    "g_filters_base = 32\n",
    "DropoutRatio = 0\n",
    "learn_rate_g = 0.0002\n",
    "learn_rate_d = 0.001\n",
    "learn_rate_c = 0.0002\n",
    "\n",
    "# channels = 3\n",
    "matrix_shape = (matrix_length, matrix_length, channel_num)\n",
    "true_volume_shape = (matrix_length, matrix_length, 1)\n",
    "history_volume_shape = (matrix_length, matrix_length, channel_num-1)\n",
    "\n",
    "kernel_init = 'glorot_uniform'\n",
    "bias_init = 'zeros'\n",
    "kernel_regul = regularizers.l2(1)\n",
    "activity_regul = regularizers.l2(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet block\n",
    "def identity_block(X, filters, f):\n",
    "\n",
    "    F1, F2 = filters\n",
    "\n",
    "    X_shortcut = X\n",
    "\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(filters=F1, kernel_size=(f, f), strides=(1, 1), padding='same',\n",
    "               kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "              kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(X)\n",
    "\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same',\n",
    "               kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "              kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(X)\n",
    "\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X\n",
    "\n",
    "# ENCODER\n",
    "def encoder_layer(img_in, filters, kernel_size, bn=True, resid=True):\n",
    "    # conv = Conv2D(filters=filters, kernel_size=kernel_size, strides=(1, 1), padding='same')(img_in)\n",
    "    conv = img_in\n",
    "    if bn:\n",
    "        conv = BatchNormalization()(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "#             conv = MaxPooling2D((2, 2))(conv)\n",
    "\n",
    "\n",
    "    if resid:\n",
    "        conv = identity_block(conv, (filters, filters), kernel_size)\n",
    "\n",
    "    return conv\n",
    "\n",
    "# DECODER\n",
    "def decoder_layer(img_in, e_conv, filters, kernel_size, bn=True, resid=True):\n",
    "    # up_img = UpSampling2D(size=(2,2))(img_in)\n",
    "    up_img = img_in\n",
    "    concat_img = Concatenate(axis=3)([e_conv,up_img])\n",
    "    conv = Conv2D(filters=filters, kernel_size=kernel_size, strides=(1, 1), padding='same',\n",
    "                  kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "              kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(concat_img)\n",
    "    if bn:\n",
    "        conv = BatchNormalization()(conv)\n",
    "    conv = LeakyReLU(alpha=0)(conv)\n",
    "\n",
    "    if resid:\n",
    "        conv = identity_block(conv, (filters, filters), kernel_size)\n",
    "    return conv\n",
    "\n",
    "\n",
    "\n",
    "def build_generator():      \n",
    "\n",
    "    # INPUTS\n",
    "    history_traffic_volume = Input(shape=history_volume_shape)\n",
    "\n",
    "    # kernel_init = initializers.he_normal()\n",
    "    # bias_init = initializers.he_normal()\n",
    "    kernel_init = 'glorot_uniform'\n",
    "    bias_init = 'zeros'\n",
    "\n",
    "#         kernel_init = initializers.he_uniform()\n",
    "#         bias_init = 'Orthogonal'\n",
    "    kernel_regul = regularizers.l2(1)\n",
    "    activity_regul = regularizers.l2(1)\n",
    "\n",
    "    filters_base = 32\n",
    "    e_conv1_head = Conv2D(filters=filters_base, kernel_size=3, strides=1, padding='same',\n",
    "                          kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(history_traffic_volume)\n",
    "#         e_conv1_head = Conv2D(filters=filters_base*1, kernel_size=3, strides=1, padding='same',\n",
    "#                               kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "#                       kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(e_conv1_head)\n",
    "    e_conv1_tail = AveragePooling2D((2, 2))(e_conv1_head)\n",
    "#     e_conv1_tail = Dropout(DropoutRatio/2)(e_conv1_tail)\n",
    "    e_conv1 = encoder_layer(e_conv1_tail, filters_base, 3, bn=False)\n",
    "\n",
    "    e_conv2_head = Conv2D(filters=filters_base*2, kernel_size=3, strides=1, padding='same',\n",
    "                          kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(e_conv1)\n",
    "    e_conv2_tail = AveragePooling2D((2, 2))(e_conv2_head)\n",
    "#     e_conv2_tail = Dropout(DropoutRatio)(e_conv2_tail)\n",
    "    e_conv2 = encoder_layer(e_conv2_tail, filters_base*2, 3)\n",
    "\n",
    "    e_conv3_head = Conv2D(filters=filters_base*4, kernel_size=3, strides=1, padding='same',\n",
    "                          kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(e_conv2)\n",
    "    e_conv3_tail = AveragePooling2D((2, 2))(e_conv3_head)\n",
    "    \n",
    "    # 加drop引入噪声\n",
    "#     e_conv3_tail = Dropout(DropoutRatio)(e_conv3_tail)\n",
    "    \n",
    "    d_conv3_head = encoder_layer(e_conv3_tail, filters_base*4, 3)\n",
    "    resid1 = Subtract()([e_conv3_tail, d_conv3_head])\n",
    "    d_conv3_tail = UpSampling2D(size=(2, 2))(resid1)\n",
    "#     d_conv3_tail = Dropout(DropoutRatio)(d_conv3_tail)\n",
    "\n",
    "\n",
    "    d_conv4_head = decoder_layer(d_conv3_tail, e_conv3_head, filters_base*2, 3)\n",
    "    resid2 = Subtract()([d_conv4_head, e_conv2_tail])\n",
    "    d_conv4_tail = UpSampling2D(size=(2, 2))(resid2)\n",
    "#     d_conv4_tail = Dropout(DropoutRatio)(d_conv4_tail)\n",
    "\n",
    "\n",
    "    d_conv5_head = decoder_layer(d_conv4_tail, e_conv2_head, filters_base*1, 3)\n",
    "    resid3 = Subtract()([d_conv5_head, e_conv1_tail])\n",
    "    d_conv5_tail = UpSampling2D(size=(2, 2))(resid3)\n",
    "#     d_conv5_tail = Dropout(DropoutRatio)(d_conv5_tail)\n",
    "\n",
    "    d_conv6_head = decoder_layer(d_conv5_tail, e_conv1_head, filters_base//2, 3, bn=False)\n",
    "\n",
    "\n",
    "    outputs = Conv2D(1, 1, activation = 'relu', kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(d_conv6_head)\n",
    "\n",
    "    # Setup the model inputs / outputs\n",
    "    model = Model(inputs=history_traffic_volume, outputs=outputs)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer = Adam(lr=learn_rate_g),\n",
    "        loss='mse'\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty_loss(y_true, y_pred, averaged_samples):\n",
    "    \"\"\"\n",
    "    Computes gradient penalty based on prediction and weighted real / fake samples\n",
    "    \"\"\"\n",
    "    gradients = K.gradients(y_pred, averaged_samples)[0]\n",
    "    # compute the euclidean norm by squaring ...\n",
    "    gradients_sqr = K.square(gradients)\n",
    "    #   ... summing over the rows ...\n",
    "    gradients_sqr_sum = K.sum(gradients_sqr,\n",
    "                              axis=np.arange(1, len(gradients_sqr.shape)))\n",
    "    #   ... and sqrt\n",
    "    gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
    "    # compute lambda * (1 - ||grad||)^2 still for each single sample\n",
    "    gradient_penalty = K.square(1 - gradient_l2_norm)\n",
    "    # return the mean as loss over all the batch samples\n",
    "    return K.mean(gradient_penalty)\n",
    "\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)\n",
    "\n",
    "def neg_wasserstein_loss(y_true, y_pred):\n",
    "    return -K.mean(y_true * y_pred)\n",
    "\n",
    "def neg_mean_squared_error(y_true, y_pred):\n",
    "    return -K.mean(K.square(y_pred - y_true), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomWeightedAverage(_Merge):\n",
    "    \"\"\"Provides a (random) weighted average between real and generated image samples\"\"\"\n",
    "    def _merge_function(self, inputs):\n",
    "        alpha = K.random_uniform((64, 1, 1, 1))\n",
    "        return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])\n",
    "    \n",
    "    \n",
    "class GradNorm(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(GradNorm, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(GradNorm, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        vaild_interpolated, interpolation_volume = inputs\n",
    "        grads = K.gradients(vaild_interpolated, interpolation_volume)\n",
    "        assert len(grads) == 1\n",
    "        grad = grads[0]\n",
    "#         a = K.sqrt(K.sum(K.batch_flatten(K.square(grad)), axis=1, keepdims=True))\n",
    "        return grad\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (MAX_BATCH_SIZE,) + true_volume_shape\n",
    "    \n",
    "    def compute_output_shape(self, input_shapes):\n",
    "        return (MAX_BATCH_SIZE,) + true_volume_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_filters_base = 32\n",
    "# Input shape\n",
    "\n",
    "# Discriminator\n",
    "def build_spatial_discriminator():\n",
    "    def d_layer(layer_input, filters, f_size=3, bn=True, stride=1):\n",
    "        \"\"\"Discriminator layer\"\"\"\n",
    "        d = Conv2D(filters, kernel_size=f_size, strides=stride, padding='same', kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(layer_input)\n",
    "        if bn:\n",
    "            d = BatchNormalization()(d)\n",
    "        d = LeakyReLU(alpha=0.1)(d)\n",
    "        return d\n",
    "    \n",
    "    matrix_A = Input(shape=true_volume_shape)\n",
    "    matrix_B = Input(shape=history_volume_shape)\n",
    "\n",
    "    # Concatenate image and conditioning image生成输入对象\n",
    "    combined_matrix = Concatenate(axis=-1)([matrix_A, matrix_B])\n",
    "\n",
    "    d1 = d_layer(combined_matrix, d_filters_base, bn=False)\n",
    "    d2 = d_layer(d1, d_filters_base*2, stride=2)\n",
    "#     d2 = AveragePooling2D((2, 2))(d2)\n",
    "    d3 = d_layer(d2, d_filters_base*4, stride=2)\n",
    "#     d3 = AveragePooling2D((2, 2))(d3)\n",
    "    d4 = d_layer(d3, d_filters_base*8, stride=2)\n",
    "#     d4 = AveragePooling2D((2, 2))(d4)\n",
    "    d4 = d_layer(d4, d_filters_base*4)\n",
    "    d5 = d_layer(d4, d_filters_base*2)\n",
    "    d6 = d_layer(d5, d_filters_base*1)\n",
    "    \n",
    "    validity = Conv2D(1, kernel_size=3, strides=1, padding='same')(d6)\n",
    "    model = Model([matrix_A, matrix_B], validity)\n",
    "#     model.compile(optimizer=RMSprop(lr=learn_rate_d), loss='mse', metrics=['mse']) \n",
    "    model.compile(optimizer=Adam(lr=learn_rate_d), loss=wasserstein_loss, metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def build_temporal_discriminator():\n",
    "    def d_layer(layer_input, filters, f_size=3, bn=True, stride=1):\n",
    "        \"\"\"Discriminator layer\"\"\"\n",
    "        d = Conv2D(filters, kernel_size=f_size, strides=stride, padding='same', kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(layer_input)\n",
    "        if bn:\n",
    "            d = BatchNormalization()(d)\n",
    "        d = LeakyReLU(alpha=0.1)(d)\n",
    "        return d\n",
    "\n",
    "    matrix_A = Input(shape=true_volume_shape)\n",
    "    matrix_B = Input(shape=history_volume_shape)\n",
    "\n",
    "    # Concatenate image and conditioning image生成输入对象\n",
    "    combined_matrix = Concatenate(axis=-1)([matrix_B, matrix_A])\n",
    "    combined_matrix = Reshape((6, 32, 32, 1))(combined_matrix)\n",
    "    \n",
    "    cl1 = ConvLSTM2D(filters=d_filters_base, kernel_size=(3, 3), strides=2, \n",
    "                     padding='same', return_sequences=True)(combined_matrix)\n",
    "    cl1 = BatchNormalization()(cl1)\n",
    "\n",
    "#     cl2 = ConvLSTM2D(filters=d_filters_base*2, kernel_size=(3, 3), strides=2,\n",
    "#                        padding='same', return_sequences=True)(cl1)\n",
    "#     cl2 = BatchNormalization()(cl2)\n",
    "\n",
    "    cl3 = ConvLSTM2D(filters=d_filters_base, kernel_size=(3, 3), strides=2,\n",
    "                       padding='same', return_sequences=False)(cl1)\n",
    "    cl3 = BatchNormalization()(cl3)\n",
    "    \n",
    "    cl3 = d_layer(cl3, d_filters_base//2, stride=2)\n",
    "    cl3 = d_layer(cl3, d_filters_base//4)\n",
    "    \n",
    "    validity = Conv2D(1, kernel_size=3, strides=1, padding='same')(cl3)\n",
    "    \n",
    "    model = Model([matrix_A, matrix_B], validity)\n",
    "    model.compile(optimizer=RMSprop(lr=learn_rate_d), loss='mse', metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "temporal_discriminator = build_temporal_discriminator()\n",
    "spatial_discriminator = build_spatial_discriminator()\n",
    "generator = build_generator()\n",
    "\n",
    "\n",
    "true_volume = Input(shape=true_volume_shape)\n",
    "history_volume = Input(shape=history_volume_shape)\n",
    "interpolation_volume = Input(shape=true_volume_shape)\n",
    "\n",
    "forecast_volume = generator(history_volume)\n",
    "\n",
    "temporal_discriminator.trainable = False\n",
    "spatial_discriminator.trainable = False\n",
    "temporal_true_vaild = temporal_discriminator([true_volume, history_volume])\n",
    "temporal_fake_vaild = temporal_discriminator([forecast_volume, history_volume])\n",
    "spatial_true_vaild = spatial_discriminator([true_volume, history_volume])\n",
    "spatial_fake_vaild = spatial_discriminator([forecast_volume, history_volume])\n",
    "\n",
    "\n",
    "# gp = gradient_penalty_loss(true_volume, forecast_volume, interpolation_volume)\n",
    "temporal_norm = GradNorm()([temporal_discriminator([interpolation_volume, history_volume]), interpolation_volume])\n",
    "spatial_norm = GradNorm()([spatial_discriminator([interpolation_volume, history_volume]), interpolation_volume])\n",
    "\n",
    "combined = Model(inputs=[true_volume, history_volume, interpolation_volume],\n",
    "                    outputs=[temporal_true_vaild, temporal_fake_vaild, temporal_norm, spatial_true_vaild, spatial_fake_vaild, spatial_norm, forecast_volume])\n",
    "# combined.compile(loss=[wasserstein_loss,\n",
    "#                         neg_wasserstein_loss,\n",
    "#                        neg_mean_squared_error,\n",
    "#                        wasserstein_loss,\n",
    "#                         neg_wasserstein_loss,\n",
    "#                        neg_mean_squared_error,\n",
    "#                         'mse'],\n",
    "#                         optimizer=RMSprop(lr=learn_rate_c),\n",
    "#                         loss_weights=[1, 1, 5, 1, 1, 5, 10])\n",
    "#按照目标函数，loss最小化\n",
    "combined.compile(loss=[neg_wasserstein_loss,\n",
    "                        wasserstein_loss,\n",
    "                       'mse',\n",
    "                       neg_wasserstein_loss,\n",
    "                        wasserstein_loss,\n",
    "                       'mse',\n",
    "                        'mse'],\n",
    "                        optimizer=RMSprop(lr=learn_rate_c),\n",
    "                        loss_weights=[1, 1, 5, 1, 1, 5, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_step = []\n",
    "l2_validation = []\n",
    "\n",
    "def train(train_matrix, epochs, batch_size=MAX_BATCH_SIZE, learn_rate=0.01):\n",
    "\n",
    "    min_mse = 999\n",
    "    start_time = datetime.datetime.now()\n",
    "    print(\"train start \"+str(start_time))\n",
    "\n",
    "    # Adversarial loss ground truths\n",
    "#     valid = np.ones((MAX_BATCH_SIZE,) + disc_patch)+np.random.rand(MAX_BATCH_SIZE, patch, patch, 1)/5\n",
    "#     fake = np.zeros((MAX_BATCH_SIZE,) + disc_patch)+np.random.rand(MAX_BATCH_SIZE, patch, patch, 1)/5\n",
    "    valid = np.ones((MAX_BATCH_SIZE,) + disc_patch)\n",
    "    fake = -np.ones((MAX_BATCH_SIZE,) + disc_patch)\n",
    "    dummy = np.ones((MAX_BATCH_SIZE,) + true_volume_shape)\n",
    "\n",
    "    #　周期修改学习率　https://zhuanlan.zhihu.com/p/52084949\n",
    "    for epoch in range(epochs):\n",
    "        if epoch>=80 and epoch % 5 == 0 and epoch != 0:\n",
    "            generator_lr = K.get_value(generator.optimizer.lr)\n",
    "            temporal_discriminator_lr = K.get_value(temporal_discriminator.optimizer.lr)\n",
    "            spatial_discriminator_lr = K.get_value(spatial_discriminator.optimizer.lr)\n",
    "            combined_lr = K.get_value(combined.optimizer.lr)\n",
    "            if generator_lr>0.0001:\n",
    "                K.set_value(generator.optimizer.lr, generator_lr*0.9)\n",
    "            if temporal_discriminator_lr>0.0005:\n",
    "                K.set_value(temporal_discriminator.optimizer.lr, temporal_discriminator*0.9)\n",
    "                K.set_value(spatial_discriminator.optimizer.lr, spatial_discriminator*0.9)\n",
    "            if combined_lr>0.0001:\n",
    "                K.set_value(combined.optimizer.lr, combined_lr*0.9)\n",
    "\n",
    "        for batch_i, (true_volume, history_volume) in enumerate(load_data(train_matrix,batch_size)):\n",
    "            # true_volume 真实待预测路网交通量  history_volume 路网交通量历史数据\n",
    "            #  训练 Discriminator\n",
    "\n",
    "            # 根据历史数据生成预测数据\n",
    "            forecast_volume = generator.predict(history_volume)\n",
    "\n",
    "            epsilon = np.random.uniform(0, 1, size=(MAX_BATCH_SIZE,1,1,1))\n",
    "            interpolation_volume = epsilon*true_volume + (1-epsilon)*forecast_volume\n",
    "            # 训练 the discriminators (original images = real / generated = Fake)\n",
    "            temporal_discriminator.trainable = True\n",
    "            dt_loss_real = temporal_discriminator.train_on_batch([true_volume, history_volume], valid)\n",
    "            dt_loss_fake = temporal_discriminator.train_on_batch([forecast_volume, history_volume], fake)\n",
    "            temporal_discriminator.trainable = False\n",
    "            spatial_discriminator.trainable = True\n",
    "            ds_loss_real = spatial_discriminator.train_on_batch([true_volume, history_volume], valid)\n",
    "            ds_loss_fake = spatial_discriminator.train_on_batch([forecast_volume, history_volume], fake)\n",
    "            spatial_discriminator.trainable = False\n",
    "            dt_loss = 0.5 * np.add(dt_loss_real, dt_loss_fake)\n",
    "            ds_loss = 0.5 * np.add(ds_loss_real, ds_loss_fake)\n",
    "            \n",
    "            #  训练 Generator\n",
    "            g_loss = combined.train_on_batch([true_volume, history_volume, interpolation_volume], [valid, fake, dummy, valid, fake, dummy, true_volume])\n",
    "\n",
    "            elapsed_time = datetime.datetime.now() - start_time\n",
    "\n",
    "        # Plot the progress\n",
    "        y_pred = generator.predict(X_test[:, :, :, 1:])\n",
    "        y_true = X_test[:, :, :, :1]\n",
    "\n",
    "        l2_epoch_validation = l2(y_true, y_pred)\n",
    "        l1_epoch_validation = l1(y_true, y_pred)\n",
    "        \n",
    "        y_pred[y_true==0] += 1\n",
    "        y_true[y_true==0] += 1\n",
    "        mape_epoch_validation = mape(y_true, y_pred)\n",
    "        \n",
    "#         lr_step.append(K.get_value(discriminator.optimizer.lr))\n",
    "        if(l2_epoch_validation<12 and l2_epoch_validation < min_mse):\n",
    "            generator.save_weights('./model/wganpg/tmp/min_generator_wganpg.h5')\n",
    "            spatial_discriminator.save_weights('./model/wganpg/tmp/min_spatial_discriminator_wganpg.h5')\n",
    "            temporal_discriminator.save_weights('./model/wganpg/tmp/min_temporal_discriminator_wganpg.h5')\n",
    "            combined.save_weights('./model/wganpg/tmp/min_combined_wganpg.h5')\n",
    "            min_mse = l2_epoch_validation\n",
    "            \n",
    "        l2_validation.append(l2_epoch_validation)\n",
    "        if epoch%1==0:\n",
    "#             print(\"unet lr:\"+ str(K.get_value(unet.optimizer.lr)))\n",
    "            print (\"[Epoch %d/%d][Dt: %f, Ds: %f, mse: %f, mae: %f, mape: %f, G loss: %f] time: %s\" % (epoch+1, epochs,\n",
    "                                                                    dt_loss[0], ds_loss[0], l2_epoch_validation,\n",
    "                                                                    l1_epoch_validation,\n",
    "                                                                    mape_epoch_validation,\n",
    "                                                                    g_loss[0],\n",
    "                                                                    elapsed_time))\n",
    "        # If at show interval => show generated image samples\n",
    "#             if epoch % show_interval == 0:\n",
    "#                     show_images(dataset_name,epoch, batch_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train start 2019-12-12 19:08:27.477429\n",
      "[Epoch 1/200][Dt: 0.170167, Ds: 0.198187, mse: 97.614342, mae: 71.606274, mape: 30.548261, G loss: 83714.812500] time: 0:04:30.019960\n",
      "[Epoch 2/200][Dt: 0.090981, Ds: 0.041101, mse: 89.546168, mae: 68.356085, mape: 28.028175, G loss: 53649.675781] time: 0:07:36.786350\n",
      "[Epoch 3/200][Dt: 0.087096, Ds: 0.107986, mse: 77.256741, mae: 58.761808, mape: 24.490472, G loss: 33359.558594] time: 0:10:34.159516\n",
      "[Epoch 4/200][Dt: 0.081732, Ds: 0.081906, mse: 54.016526, mae: 40.053185, mape: 17.589337, G loss: 26136.335938] time: 0:13:31.473777\n",
      "[Epoch 5/200][Dt: 0.057653, Ds: 0.129678, mse: 56.327860, mae: 42.192152, mape: 18.433326, G loss: 20423.761719] time: 0:16:29.037427\n",
      "[Epoch 6/200][Dt: 0.040704, Ds: 0.258137, mse: 51.298056, mae: 38.267781, mape: 16.719091, G loss: 16202.378906] time: 0:19:26.456446\n",
      "[Epoch 7/200][Dt: 0.050499, Ds: 0.297262, mse: 32.770957, mae: 22.882624, mape: 10.302389, G loss: 6667.543945] time: 0:22:23.861799\n",
      "[Epoch 8/200][Dt: 0.034097, Ds: 0.062536, mse: 33.545324, mae: 23.736255, mape: 10.672243, G loss: 7191.194336] time: 0:25:21.515261\n",
      "[Epoch 9/200][Dt: 0.047619, Ds: 0.240676, mse: 24.135878, mae: 15.889658, mape: 7.714998, G loss: 5476.603516] time: 0:28:19.127871\n",
      "[Epoch 10/200][Dt: 0.046383, Ds: 0.031037, mse: 20.291340, mae: 12.511191, mape: 6.380833, G loss: 4826.712891] time: 0:31:16.649242\n",
      "[Epoch 11/200][Dt: 0.032537, Ds: 0.065603, mse: 19.827259, mae: 12.301683, mape: 6.317297, G loss: 4728.001953] time: 0:34:22.531203\n",
      "[Epoch 12/200][Dt: 0.030508, Ds: 0.147204, mse: 20.496371, mae: 13.067978, mape: 6.619359, G loss: 4690.813477] time: 0:37:26.580659\n",
      "[Epoch 13/200][Dt: 0.040988, Ds: 0.191795, mse: 18.948741, mae: 11.778281, mape: 6.174134, G loss: 4361.985840] time: 0:40:27.209667\n",
      "[Epoch 14/200][Dt: 0.039583, Ds: 0.000065, mse: 19.052517, mae: 11.967190, mape: 6.212461, G loss: 4294.243164] time: 0:43:33.190636\n",
      "[Epoch 15/200][Dt: 0.545404, Ds: 0.000060, mse: 24.520058, mae: 16.802348, mape: 8.138111, G loss: 6573.946289] time: 0:46:39.235119\n",
      "[Epoch 16/200][Dt: 2.080028, Ds: 0.000067, mse: 20.216679, mae: 12.874011, mape: 5.966698, G loss: 3825.672363] time: 0:49:36.210589\n",
      "[Epoch 17/200][Dt: 0.277760, Ds: 0.000076, mse: 20.940766, mae: 13.848289, mape: 6.958618, G loss: 4943.440918] time: 0:52:35.509885\n",
      "[Epoch 18/200][Dt: 0.796329, Ds: 0.000085, mse: 25.949989, mae: 17.779246, mape: 7.480518, G loss: 3927.499023] time: 0:55:34.331594\n",
      "[Epoch 19/200][Dt: 0.801966, Ds: 0.000095, mse: 19.435603, mae: 12.681772, mape: 6.450336, G loss: 4411.363281] time: 0:58:32.318905\n",
      "[Epoch 20/200][Dt: 0.235595, Ds: 0.000104, mse: 20.965089, mae: 14.076360, mape: 6.915428, G loss: 4569.479492] time: 1:01:29.909636\n",
      "[Epoch 21/200][Dt: 0.395640, Ds: 0.000112, mse: 16.158786, mae: 9.784428, mape: 4.928791, G loss: 3291.566895] time: 1:04:25.641453\n",
      "[Epoch 22/200][Dt: 0.874367, Ds: 0.000121, mse: 16.712008, mae: 10.235176, mape: 5.020612, G loss: 3304.706543] time: 1:07:20.786980\n",
      "[Epoch 23/200][Dt: 0.348467, Ds: 0.000133, mse: 15.062829, mae: 9.093384, mape: 4.858765, G loss: 3226.834473] time: 1:10:16.659332\n",
      "[Epoch 24/200][Dt: 0.093851, Ds: 0.000162, mse: 16.721063, mae: 10.301570, mape: 4.994042, G loss: 3237.672119] time: 1:13:12.278740\n",
      "[Epoch 25/200][Dt: 0.685245, Ds: 0.000221, mse: 15.510376, mae: 9.697914, mape: 5.226288, G loss: 3202.978760] time: 1:16:07.157752\n",
      "[Epoch 26/200][Dt: 1.459754, Ds: 0.000304, mse: 23.937752, mae: 16.416404, mape: 6.975709, G loss: 3775.856689] time: 1:19:04.865118\n",
      "[Epoch 27/200][Dt: 0.054419, Ds: 0.023799, mse: 22.457406, mae: 15.257129, mape: 6.701663, G loss: 3547.617920] time: 1:22:03.063594\n",
      "[Epoch 28/200][Dt: 1.834935, Ds: 0.154540, mse: 17.805950, mae: 11.317911, mape: 5.220493, G loss: 3095.406006] time: 1:25:05.121139\n",
      "[Epoch 29/200][Dt: 0.147193, Ds: 0.000049, mse: 18.223387, mae: 12.185999, mape: 6.038319, G loss: 3587.953369] time: 1:28:02.412684\n",
      "[Epoch 30/200][Dt: 2.294958, Ds: 0.000052, mse: 21.821462, mae: 15.146105, mape: 7.139195, G loss: 3699.828125] time: 1:31:02.174784\n",
      "[Epoch 31/200][Dt: 0.060825, Ds: 0.000057, mse: 16.045878, mae: 9.955233, mape: 4.796955, G loss: 2996.085693] time: 1:34:00.010483\n",
      "[Epoch 32/200][Dt: 0.039047, Ds: 0.000062, mse: 19.380432, mae: 13.095657, mape: 6.106844, G loss: 3535.909180] time: 1:37:01.249180\n",
      "[Epoch 33/200][Dt: 0.123110, Ds: 0.000067, mse: 14.096323, mae: 8.511395, mape: 4.455200, G loss: 2742.274414] time: 1:40:00.197279\n",
      "[Epoch 34/200][Dt: 0.044864, Ds: 0.000072, mse: 23.833810, mae: 16.416038, mape: 6.990393, G loss: 4048.268066] time: 1:42:57.007036\n",
      "[Epoch 35/200][Dt: 0.051549, Ds: 0.000077, mse: 16.686310, mae: 10.573872, mape: 4.973815, G loss: 2910.590332] time: 1:45:55.924815\n",
      "[Epoch 36/200][Dt: 2.676888, Ds: 0.000082, mse: 13.924631, mae: 8.458524, mape: 4.464212, G loss: 2691.441895] time: 1:48:56.709273\n",
      "[Epoch 37/200][Dt: 0.212265, Ds: 0.000092, mse: 16.753763, mae: 10.747351, mape: 5.040697, G loss: 2883.708740] time: 1:51:54.180713\n",
      "[Epoch 38/200][Dt: 0.066116, Ds: 0.000121, mse: 16.420206, mae: 10.460819, mape: 4.918633, G loss: 2772.742676] time: 1:54:56.441286\n",
      "[Epoch 39/200][Dt: 0.111811, Ds: 0.000206, mse: 13.347756, mae: 8.148261, mape: 4.259658, G loss: 2562.557861] time: 1:57:59.964943\n",
      "[Epoch 40/200][Dt: 0.214789, Ds: 0.000327, mse: 15.313209, mae: 9.672724, mape: 4.634751, G loss: 2662.826416] time: 2:00:59.510058\n",
      "[Epoch 41/200][Dt: 0.810465, Ds: 0.000476, mse: 13.366765, mae: 8.257597, mape: 4.326069, G loss: 2576.603760] time: 2:04:00.782124\n",
      "[Epoch 42/200][Dt: 1.059004, Ds: 0.000512, mse: 15.894797, mae: 10.052607, mape: 4.755688, G loss: 2735.683350] time: 2:07:02.300115\n",
      "[Epoch 43/200][Dt: 0.056903, Ds: 0.001412, mse: 15.053797, mae: 9.475406, mape: 4.688149, G loss: 2613.300049] time: 2:09:57.204471\n",
      "[Epoch 44/200][Dt: 0.040296, Ds: 0.002949, mse: 16.333536, mae: 10.452232, mape: 4.898276, G loss: 2677.588379] time: 2:12:55.400210\n",
      "[Epoch 45/200][Dt: 0.620175, Ds: 0.000624, mse: 16.248653, mae: 10.341409, mape: 4.864780, G loss: 2652.115234] time: 2:15:56.342226\n",
      "[Epoch 46/200][Dt: 0.115419, Ds: 0.001796, mse: 16.775060, mae: 11.188617, mape: 5.484999, G loss: 2803.017578] time: 2:18:55.505570\n",
      "[Epoch 47/200][Dt: 0.061877, Ds: 0.000504, mse: 13.124416, mae: 8.026454, mape: 4.123704, G loss: 2404.047363] time: 2:21:53.091172\n",
      "[Epoch 48/200][Dt: 0.026932, Ds: 0.000522, mse: 15.069492, mae: 9.507083, mape: 4.611068, G loss: 2535.843262] time: 2:24:57.770951\n",
      "[Epoch 49/200][Dt: 0.077528, Ds: 0.000692, mse: 14.950479, mae: 9.353390, mape: 4.464422, G loss: 2486.917725] time: 2:28:02.528721\n",
      "[Epoch 50/200][Dt: 0.024066, Ds: 0.000505, mse: 14.903551, mae: 9.668956, mape: 4.926479, G loss: 2545.599609] time: 2:31:03.730386\n",
      "[Epoch 51/200][Dt: 0.040491, Ds: 0.000614, mse: 13.106124, mae: 7.978688, mape: 4.071157, G loss: 2334.659912] time: 2:34:02.021028\n",
      "[Epoch 52/200][Dt: 0.454438, Ds: 0.174057, mse: 13.584171, mae: 8.527758, mape: 4.368049, G loss: 2353.952148] time: 2:36:59.087025\n",
      "[Epoch 53/200][Dt: 0.444743, Ds: 0.000048, mse: 14.389314, mae: 9.067722, mape: 4.327447, G loss: 2362.058105] time: 2:39:55.012396\n",
      "[Epoch 54/200][Dt: 0.028899, Ds: 0.000050, mse: 17.914978, mae: 11.985451, mape: 5.407774, G loss: 2815.229248] time: 2:42:50.264657\n",
      "[Epoch 55/200][Dt: 0.028255, Ds: 0.000052, mse: 15.744782, mae: 10.442034, mape: 5.094778, G loss: 2530.287598] time: 2:45:46.316497\n",
      "[Epoch 56/200][Dt: 0.075892, Ds: 0.000055, mse: 12.599025, mae: 7.630889, mape: 3.919872, G loss: 2220.923828] time: 2:48:42.936917\n",
      "[Epoch 57/200][Dt: 0.033924, Ds: 0.000058, mse: 12.448288, mae: 7.525858, mape: 3.870426, G loss: 2197.467285] time: 2:51:38.818339\n",
      "[Epoch 58/200][Dt: 0.043076, Ds: 0.000060, mse: 12.648043, mae: 7.727875, mape: 3.944265, G loss: 2181.333008] time: 2:54:37.368659\n",
      "[Epoch 59/200][Dt: 0.024575, Ds: 0.000062, mse: 13.256281, mae: 8.130920, mape: 4.049506, G loss: 2162.619873] time: 2:57:37.305648\n",
      "[Epoch 60/200][Dt: 0.031553, Ds: 0.000064, mse: 12.523239, mae: 7.535586, mape: 3.859079, G loss: 2128.838867] time: 3:00:32.824351\n",
      "[Epoch 61/200][Dt: 0.023205, Ds: 0.000068, mse: 13.689740, mae: 8.440307, mape: 4.090749, G loss: 2147.655029] time: 3:03:29.366347\n",
      "[Epoch 62/200][Dt: 0.061256, Ds: 0.000084, mse: 14.788464, mae: 9.685239, mape: 4.728005, G loss: 2232.076172] time: 3:06:25.535884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 63/200][Dt: 0.023232, Ds: 0.000157, mse: 13.570278, mae: 8.477086, mape: 4.180438, G loss: 2066.164062] time: 3:09:25.932201\n",
      "[Epoch 64/200][Dt: 0.074226, Ds: 0.000303, mse: 12.862290, mae: 7.795378, mape: 3.895943, G loss: 2094.735596] time: 3:12:21.775897\n",
      "[Epoch 65/200][Dt: 0.038773, Ds: 0.000446, mse: 15.361614, mae: 9.855635, mape: 4.464519, G loss: 2262.014160] time: 3:15:17.008240\n",
      "[Epoch 66/200][Dt: 0.023401, Ds: 0.000513, mse: 14.420120, mae: 9.148165, mape: 4.345001, G loss: 2225.787842] time: 3:18:13.490951\n",
      "[Epoch 67/200][Dt: 0.307118, Ds: 0.000571, mse: 12.121226, mae: 7.301187, mape: 3.773805, G loss: 1990.308228] time: 3:21:11.668693\n",
      "[Epoch 68/200][Dt: 1.439999, Ds: 0.000581, mse: 12.991931, mae: 8.047819, mape: 4.154332, G loss: 2002.483032] time: 3:24:07.179812\n",
      "[Epoch 69/200][Dt: 0.035247, Ds: 0.000607, mse: 12.195832, mae: 7.345731, mape: 3.795059, G loss: 1987.357178] time: 3:27:03.063501\n",
      "[Epoch 70/200][Dt: 0.027063, Ds: 0.000604, mse: 15.302407, mae: 10.169981, mape: 4.863448, G loss: 2810.033447] time: 3:29:58.259228\n",
      "[Epoch 71/200][Dt: 0.019570, Ds: 0.000677, mse: 13.315868, mae: 8.489316, mape: 4.276693, G loss: 1985.368652] time: 3:32:53.967724\n",
      "[Epoch 72/200][Dt: 0.037237, Ds: 0.000604, mse: 13.638407, mae: 8.629934, mape: 4.311632, G loss: 1966.680786] time: 3:35:50.468291\n",
      "[Epoch 73/200][Dt: 0.029111, Ds: 0.000653, mse: 12.186649, mae: 7.523673, mape: 3.944246, G loss: 1965.325684] time: 3:38:46.684938\n",
      "[Epoch 74/200][Dt: 0.025985, Ds: 0.000581, mse: 12.384943, mae: 7.452373, mape: 3.774989, G loss: 1905.101318] time: 3:41:42.762906\n",
      "[Epoch 75/200][Dt: 0.049595, Ds: 0.000640, mse: 17.822878, mae: 12.241936, mape: 5.772579, G loss: 2433.616211] time: 3:44:38.461642\n",
      "[Epoch 76/200][Dt: 0.032357, Ds: 0.000749, mse: 13.194717, mae: 8.142040, mape: 3.930675, G loss: 2016.831421] time: 3:47:35.795011\n"
     ]
    }
   ],
   "source": [
    "train(X_train, epochs=200, batch_size=MAX_BATCH_SIZE, learn_rate=learn_rate_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator.save_weights('./model/wganpg/generator_167epoch_11rmse.h5')\n",
    "# discriminator.save_weights('./model/wganpg/discriminator_167epoch_11rmse.h5')\n",
    "# combined.save_weights('./model/wganpg/combined_167epoch_11rmse.h5')\n",
    "\n",
    "# generator.load_weights('./model/wganpg/DS_rmse11/generator_167epoch_11rmse.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = generator.predict(X_test[:, :, :, 1:])\n",
    "y_true = X_test[:, :, :, :1]\n",
    "\n",
    "l2(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.sqrt(np.sum(np.mean(np.square(y_true - y_pred), axis=0))/1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2(y_true, y_pred+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y = y_true.reshape(-1,)[1600:1700]\n",
    "x = np.linspace(0, len(y), len(y))\n",
    "\n",
    "yi = y_pred.reshape(-1,)[1600:1700]\n",
    "xi = np.linspace(0, len(yi), len(yi))\n",
    "fig, ax = plt.subplots(figsize=(25, 6))\n",
    "# ax.plot(x, y, '.', linewidth=1, markersize=10)\n",
    "lines = plt.plot(xi, yi, 'k^--', x, y, 'ro-',linewidth=1, markersize=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yi = l2_validation\n",
    "xi = np.linspace(0, len(yi), len(yi))\n",
    "\n",
    "y = [i*10000 for i in lr_step]\n",
    "x = np.linspace(0, len(y), len(y))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "lines = plt.plot(x, y, 'ko-', xi, yi, 'k^--', linewidth=1, markersize=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = lr_step\n",
    "x = np.linspace(0, len(y), len(y))\n",
    "# fig, ax = plt.subplots(figsize=(6, 6))\n",
    "# lines = plt.plot(x, y, 'ko-', linewidth=1, markersize=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_true.reshape(-1,)[3600:3700]\n",
    "x = np.linspace(0, len(y), len(y))\n",
    "\n",
    "yi = y_pred.reshape(-1,)[3600:3700]\n",
    "xi = np.linspace(0, len(yi), len(yi))\n",
    "fig, ax = plt.subplots(figsize=(25, 6))\n",
    "ax.plot(x, y, '.', linewidth=1, markersize=10)\n",
    "lines = plt.plot(xi, yi, 'k^--', x, y, 'ro-',linewidth=1, markersize=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = 0\n",
    "y = y_true.reshape(-1,)[start_time: start_time+100]\n",
    "x = np.linspace(0, len(y), len(y))\n",
    "\n",
    "yi = y_pred.reshape(-1,)[start_time: start_time+100]\n",
    "xi = np.linspace(0, len(yi), len(yi))\n",
    "fig, ax = plt.subplots(figsize=(25, 6))\n",
    "# ax.plot(x, y, '.', linewidth=1, markersize=10)\n",
    "lines = plt.plot(xi, yi, 'k^--', x, y, 'ro-',linewidth=1, markersize=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
