{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import scipy\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import transform\n",
    "\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, concatenate, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D, Add, Subtract\n",
    "from keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D ,AveragePooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU, ELU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam, Nadam, RMSprop\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "import gc\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, TensorBoard\n",
    "from keras import backend as K\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from keras.models import load_model  \n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载  预处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交通矩阵为 matrix_length*matrix_length\n",
    "matrix_length = 32\n",
    "\n",
    "matrix_df = pd.read_csv('./data/trafficV_M.csv', index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTrainArray(week_history_num=0, minute_history_num=0):\n",
    "    week_delta_list = [pd.Timedelta(i+1, unit='W') for i in range(week_history_num)]\n",
    "    minute_delta_list = [pd.Timedelta((i+1)*15, unit='m') for i in range(minute_history_num)]\n",
    "    # 参考历史数据时间点list\n",
    "    delta_list = week_delta_list+minute_delta_list\n",
    "    print(delta_list)\n",
    "    \n",
    "    set_up_time = pd.Timedelta(week_history_num, unit='W')\n",
    "    # 根据历史数据选取多少，重新构建数据集\n",
    "    # 相当于去除最开始week_history_num个周的数据，因为这些数据无法找到更前的数据\n",
    "    train_df = matrix_df.truncate(before=matrix_df.index.min() + set_up_time)\n",
    "    \n",
    "    train_ago_array_tuple = tuple([np.array(matrix_df.loc[train_df.index - i]).reshape(-1, matrix_length, matrix_length, 1) for i in delta_list])\n",
    "    train_df = np.array(train_df).reshape(-1, matrix_length, matrix_length, 1)\n",
    "    # concatenate保持 待修复数据在前，参考历史数据在后。与random_mask函数生成mask相一致\n",
    "    train_array = np.concatenate((train_df,)+train_ago_array_tuple, axis=3)\n",
    "    print(train_array.shape)\n",
    "    return train_array\n",
    "\n",
    "\n",
    "def normalization(matrix):\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(matrix.shape[-1]):\n",
    "            cur_time = matrix[i][:, :, j]\n",
    "#             mean_val = cur_time.mean()\n",
    "            mx = cur_time.max()\n",
    "            mn = cur_time.min()\n",
    "            matrix[i][:, :, j] = np.divide((cur_time-mn), (mx-mn))\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Timedelta('7 days 00:00:00'), Timedelta('14 days 00:00:00'), Timedelta('0 days 00:15:00'), Timedelta('0 days 00:30:00'), Timedelta('0 days 00:45:00')]\n",
      "(16032, 32, 32, 6)\n"
     ]
    }
   ],
   "source": [
    "week_history_num = 2\n",
    "minute_history_num = 3\n",
    "\n",
    "channel_num = week_history_num +minute_history_num +1\n",
    "smooth_time = channel_num-1\n",
    "\n",
    "# train_array为(16704, 32, 32, 3)，16704个矩阵，32*32采集点，3从上到下为当前时间，上一周，上一15min\n",
    "train_array = createTrainArray(week_history_num, minute_history_num)\n",
    "X_train, X_test = train_test_split(train_array, test_size = 0.1, random_state=42, shuffle=False)\n",
    "# X_train, X_val = train_test_split(train_array, test_size = 0.1, random_state=42, shuffle=False) # 不shuffle可用于查看数据正确性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14428, 32, 32, 6), (1604, 32, 32, 6))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225, 25)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_BATCH_SIZE = 64\n",
    "epoch_steps = X_train.shape[0] // MAX_BATCH_SIZE\n",
    "test_steps = X_test.shape[0] // MAX_BATCH_SIZE\n",
    "epoch_steps, test_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "def load_data(volume_matrix, batch_size=MAX_BATCH_SIZE):\n",
    "    n_batches=batch_size\n",
    "    len_of_matrix = len(volume_matrix)\n",
    "\n",
    "    batch_i = 0\n",
    "    while ((batch_i+1)*batch_size < len_of_matrix):\n",
    "        batch_matrix = volume_matrix[batch_i*batch_size: (batch_i+1)*batch_size]\n",
    "        true_volume, history_volume = batch_matrix[:, :, :, :1], batch_matrix[:, :, :, 1:]\n",
    "#         history_volume = normalization(history_volume)\n",
    "        batch_i+=1\n",
    "\n",
    "        yield true_volume, history_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def l2(y_true, y_pred):\n",
    "    return math.sqrt(np.sum(np.mean(np.square(y_true - y_pred), axis=0))/1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算D输出valid大小（PatchGAN）\n",
    "patch = 4\n",
    "disc_patch = (patch, patch, 1)\n",
    "\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "def wgan_gp_distance(y_true, y_pred):\n",
    "    # WGAN-GP代码注释\n",
    "#     eps = K.random_uniform([MAX_BATCH_SIZE, 1], minval=0., maxval=1.) #eps是U[0,1]的随机数\n",
    "#     X_inter = eps*y_true + (1. - eps)*y_pred  #在真实样本和生成样本之间随机插值，希望这个约束可以“布满”真实样本和生成样本之间的空间\n",
    "#     grad = K.gradients(D(X_inter), [X_inter])[0] #求梯度\n",
    "#     grad_norm = K.sqrt(K.reduce_sum((grad)**2, axis=1)) #求梯度的二范数\n",
    "#     grad_pen = 0 #10 * K.reduce_mean(K.nn.relu(grad_norm - 1.)) #Lipschitz限制是要求判别器的梯度不超过K，这个loss项是希望判别器的梯度离K（此处K设为1）越近越好\n",
    "\n",
    "#     #判别器损失函数\n",
    "#     D_loss = K.reduce_mean(y_true) - K.reduce_mean(y_pred) + grad_pen\n",
    "    return K.mean(y_true * y_pred)\n",
    "#     return wasserstein_distance(K.eval(K.reshape(K.mean(y_true, axis=0), [1,-1])).tolist(), K.eval(K.reshape(K.mean(y_pred, axis=0), [1,-1])).tolist())\n",
    "#     return wasserstein_distance(K.mean(y_true, axis=0).reshape(patch*patch).tolist(), K.mean(y_pred, axis=0).reshape(patch*patch).tolist())\n",
    "\n",
    "\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BatchActivate(x, bn=True):\n",
    "    if bn:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    return x\n",
    "\n",
    "def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n",
    "    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n",
    "    if activation == True:\n",
    "        x = BatchActivate(x)\n",
    "    return x\n",
    "\n",
    "def residual_block(blockInput, num_filters=16, batch_activate = False):\n",
    "    x = BatchActivate(blockInput)\n",
    "    x = convolution_block(x, num_filters, (3,3) )\n",
    "    x = convolution_block(x, num_filters, (3,3), activation=False)\n",
    "    x = Add()([x, blockInput])\n",
    "    if batch_activate:\n",
    "        x = BatchActivate(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_generator():      \n",
    "\n",
    "#     # INPUTS\n",
    "#     input_matrix = Input(shape=history_volume_shape)\n",
    "#     # kernel_init = initializers.he_normal()\n",
    "#     # bias_init = initializers.he_normal()\n",
    "#     kernel_init = 'glorot_uniform'\n",
    "#     bias_init = 'zeros'\n",
    "\n",
    "#     # kernel_init = initializers.he_uniform()\n",
    "#     # bias_init = initializers.he_uniform()\n",
    "#     kernel_regul = regularizers.l2(1)\n",
    "#     activity_regul = regularizers.l2(1)\n",
    "\n",
    "#     # ENCODER\n",
    "#     def encoder_layer(img_in, filters, kernel_size, bn=True, resid=True):\n",
    "#         # conv = Conv2D(filters=filters, kernel_size=kernel_size, strides=(1, 1), padding='same')(img_in)\n",
    "#         conv = Conv2D(filters, (kernel_size, kernel_size), padding=\"same\",\n",
    "#            strides=1,kernel_initializer='glorot_uniform')(img_in)\n",
    "#         if bn:\n",
    "#             conv = BatchNormalization()(conv)\n",
    "# #         conv = Activation('relu')(conv)\n",
    "#         conv = LeakyReLU(alpha=0.1)(conv)\n",
    "\n",
    "#         conv = Conv2D(filters, (kernel_size, kernel_size), padding=\"same\",\n",
    "#            strides=1,kernel_initializer='glorot_uniform')(conv)\n",
    "#         conv = BatchNormalization()(conv)\n",
    "# #         conv = Activation('relu')(conv)\n",
    "#         conv = LeakyReLU(alpha=0.1)(conv)\n",
    "#         return conv\n",
    "\n",
    "#     # DECODER\n",
    "#     def decoder_layer(img_in, filters, kernel_size, bn=True, resid=True):\n",
    "#         conv = Conv2D(filters, (3, 3), padding=\"same\",\n",
    "#            strides=1,kernel_initializer='glorot_uniform')(img_in)\n",
    "#         conv = BatchNormalization()(conv)\n",
    "#         conv = LeakyReLU(alpha=0.1)(conv)\n",
    "# #         conv = Activation('relu')(conv)\n",
    "\n",
    "#         conv = Conv2D(filters//2, (3, 3), padding=\"same\",\n",
    "#            strides=1,kernel_initializer='glorot_uniform')(conv)\n",
    "# #             if bn:\n",
    "#         conv = BatchNormalization()(conv)\n",
    "# #         conv = Activation('relu')(conv)\n",
    "#         conv = LeakyReLU(alpha=0.1)(conv)\n",
    "\n",
    "#         conv = UpSampling2D(size = (2,2))(conv)\n",
    "#         return conv\n",
    "\n",
    "#     encoder_layer.counter = 0\n",
    "#     conv1 = encoder_layer(input_matrix, 32, 3, bn=False)\n",
    "#     pool1 = AveragePooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "#     conv2 = encoder_layer(pool1, 64, 3, bn=True)\n",
    "#     pool2 = AveragePooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "#     conv3 = encoder_layer(pool2, 128, 3, bn=True)\n",
    "#     pool3 = AveragePooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "# #         conv4 = encoder_layer(pool3, 256, 3, bn=True)\n",
    "# #         pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "#     conv5 = decoder_layer(pool3, 256, 3, bn=True)\n",
    "#     merge1 = Concatenate()([conv3,conv5])\n",
    "\n",
    "#     conv6 = decoder_layer(merge1, 128, 3, bn=True)\n",
    "#     merge2 = Concatenate()([conv2,conv6])\n",
    "\n",
    "#     conv7 = decoder_layer(merge2, 64, 3, bn=True)\n",
    "#     merge3 = Concatenate()([conv1,conv7])\n",
    "\n",
    "# #         conv8 = decoder_layer(merge3, 32, 3, bn=True)\n",
    "# #         merge4 = Concatenate()([conv1,conv8])\n",
    "\n",
    "#     conv9 = encoder_layer(merge3, 32, 3, bn=False)\n",
    "    \n",
    "#     model_output = Conv2D(1, (1, 1), \n",
    "#            use_bias=False, padding=\"same\",activation=\"linear\",\n",
    "#            strides=1,kernel_initializer='glorot_uniform',\n",
    "#            name='block9_conv3')(conv9)\n",
    "\n",
    "#     # Setup the model inputs / outputs\n",
    "#     model = Model(inputs=input_matrix, outputs=model_output)\n",
    "\n",
    "#     # Compile the model\n",
    "#     model.compile(optimizer = Adam(lr=learn_rate), loss='mse')\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (3, 3)\n",
    "g_filters_base = 32\n",
    "DropoutRatio = 0\n",
    "learn_rate_g = 0.001\n",
    "learn_rate_d = 0.001\n",
    "learn_rate_c = 0.001\n",
    "\n",
    "# channels = 3\n",
    "matrix_shape = (matrix_length, matrix_length, channel_num)\n",
    "true_volume_shape = (matrix_length, matrix_length, 1)\n",
    "history_volume_shape = (matrix_length, matrix_length, channel_num-1)\n",
    "\n",
    "kernel_init = 'glorot_uniform'\n",
    "bias_init = 'zeros'\n",
    "kernel_regul = regularizers.l2(1)\n",
    "activity_regul = regularizers.l2(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet block\n",
    "def identity_block(X, filters, f):\n",
    "\n",
    "    F1, F2 = filters\n",
    "\n",
    "    X_shortcut = X\n",
    "\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(filters=F1, kernel_size=(f, f), strides=(1, 1), padding='same',\n",
    "               kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "              kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(X)\n",
    "\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same',\n",
    "               kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "              kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(X)\n",
    "\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X\n",
    "\n",
    "# ENCODER\n",
    "def encoder_layer(img_in, filters, kernel_size, bn=True, resid=True):\n",
    "    # conv = Conv2D(filters=filters, kernel_size=kernel_size, strides=(1, 1), padding='same')(img_in)\n",
    "    conv = img_in\n",
    "    if bn:\n",
    "        conv = BatchNormalization()(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "#             conv = MaxPooling2D((2, 2))(conv)\n",
    "\n",
    "\n",
    "    if resid:\n",
    "        conv = identity_block(conv, (filters, filters), kernel_size)\n",
    "\n",
    "    return conv\n",
    "\n",
    "# DECODER\n",
    "def decoder_layer(img_in, e_conv, filters, kernel_size, bn=True, resid=True):\n",
    "    # up_img = UpSampling2D(size=(2,2))(img_in)\n",
    "    up_img = img_in\n",
    "    concat_img = Concatenate(axis=3)([e_conv,up_img])\n",
    "    conv = Conv2D(filters=filters, kernel_size=kernel_size, strides=(1, 1), padding='same',\n",
    "                  kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "              kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(concat_img)\n",
    "    if bn:\n",
    "        conv = BatchNormalization()(conv)\n",
    "    conv = LeakyReLU(alpha=0)(conv)\n",
    "\n",
    "    if resid:\n",
    "        conv = identity_block(conv, (filters, filters), kernel_size)\n",
    "    return conv\n",
    "\n",
    "\n",
    "\n",
    "def build_generator():      \n",
    "\n",
    "    # INPUTS\n",
    "    history_traffic_volume = Input(shape=history_volume_shape)\n",
    "\n",
    "    # kernel_init = initializers.he_normal()\n",
    "    # bias_init = initializers.he_normal()\n",
    "    kernel_init = 'glorot_uniform'\n",
    "    bias_init = 'zeros'\n",
    "\n",
    "#         kernel_init = initializers.he_uniform()\n",
    "#         bias_init = 'Orthogonal'\n",
    "    kernel_regul = regularizers.l2(1)\n",
    "    activity_regul = regularizers.l2(1)\n",
    "\n",
    "    filters_base = 32\n",
    "    e_conv1_head = Conv2D(filters=filters_base, kernel_size=3, strides=1, padding='same',\n",
    "                          kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(history_traffic_volume)\n",
    "#         e_conv1_head = Conv2D(filters=filters_base*1, kernel_size=3, strides=1, padding='same',\n",
    "#                               kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "#                       kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(e_conv1_head)\n",
    "    e_conv1_tail = AveragePooling2D((2, 2))(e_conv1_head)\n",
    "#     e_conv1_tail = Dropout(DropoutRatio/2)(e_conv1_tail)\n",
    "    e_conv1 = encoder_layer(e_conv1_tail, filters_base, 3, bn=False)\n",
    "\n",
    "    e_conv2_head = Conv2D(filters=filters_base*2, kernel_size=3, strides=1, padding='same',\n",
    "                          kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(e_conv1)\n",
    "    e_conv2_tail = AveragePooling2D((2, 2))(e_conv2_head)\n",
    "#     e_conv2_tail = Dropout(DropoutRatio)(e_conv2_tail)\n",
    "    e_conv2 = encoder_layer(e_conv2_tail, filters_base*2, 3)\n",
    "\n",
    "    e_conv3_head = Conv2D(filters=filters_base*4, kernel_size=3, strides=1, padding='same',\n",
    "                          kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(e_conv2)\n",
    "    e_conv3_tail = AveragePooling2D((2, 2))(e_conv3_head)\n",
    "    \n",
    "    # 加drop引入噪声\n",
    "#     e_conv3_tail = Dropout(DropoutRatio)(e_conv3_tail)\n",
    "    \n",
    "    d_conv3_head = encoder_layer(e_conv3_tail, filters_base*4, 3)\n",
    "    resid1 = Subtract()([e_conv3_tail, d_conv3_head])\n",
    "    d_conv3_tail = UpSampling2D(size=(2, 2))(resid1)\n",
    "#     d_conv3_tail = Dropout(DropoutRatio)(d_conv3_tail)\n",
    "\n",
    "\n",
    "    d_conv4_head = decoder_layer(d_conv3_tail, e_conv3_head, filters_base*2, 3)\n",
    "    resid2 = Subtract()([d_conv4_head, e_conv2_tail])\n",
    "    d_conv4_tail = UpSampling2D(size=(2, 2))(resid2)\n",
    "#     d_conv4_tail = Dropout(DropoutRatio)(d_conv4_tail)\n",
    "\n",
    "\n",
    "    d_conv5_head = decoder_layer(d_conv4_tail, e_conv2_head, filters_base*1, 3)\n",
    "    resid3 = Subtract()([d_conv5_head, e_conv1_tail])\n",
    "    d_conv5_tail = UpSampling2D(size=(2, 2))(resid3)\n",
    "#     d_conv5_tail = Dropout(DropoutRatio)(d_conv5_tail)\n",
    "\n",
    "    d_conv6_head = decoder_layer(d_conv5_tail, e_conv1_head, filters_base//2, 3, bn=False)\n",
    "\n",
    "\n",
    "    outputs = Conv2D(1, 1, activation = 'relu', kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(d_conv6_head)\n",
    "\n",
    "    # Setup the model inputs / outputs\n",
    "    model = Model(inputs=history_traffic_volume, outputs=outputs)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer = Adam(lr=learn_rate_g),\n",
    "        loss='mse'\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_filters_base = 32\n",
    "# Input shape\n",
    "\n",
    "# Discriminator\n",
    "def build_discriminator():\n",
    "    def d_layer(layer_input, filters, f_size=3, bn=True, stride=1):\n",
    "        \"\"\"Discriminator layer\"\"\"\n",
    "        d = Conv2D(filters, kernel_size=f_size, strides=stride, padding='same', kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(layer_input)\n",
    "        if bn:\n",
    "            d = BatchNormalization()(d)\n",
    "        d = LeakyReLU(alpha=0.1)(d)\n",
    "        return d\n",
    "    \n",
    "    matrix_A = Input(shape=true_volume_shape)\n",
    "    matrix_B = Input(shape=history_volume_shape)\n",
    "\n",
    "    # Concatenate image and conditioning image生成输入对象\n",
    "    combined_matrix = Concatenate(axis=-1)([matrix_A, matrix_B])\n",
    "\n",
    "    d1 = d_layer(combined_matrix, d_filters_base, bn=False)\n",
    "    d2 = d_layer(d1, d_filters_base*2, stride=2)\n",
    "#     d2 = AveragePooling2D((2, 2))(d2)\n",
    "    d3 = d_layer(d2, d_filters_base*4, stride=2)\n",
    "#     d3 = AveragePooling2D((2, 2))(d3)\n",
    "    d4 = d_layer(d3, d_filters_base*8, stride=2)\n",
    "#     d4 = AveragePooling2D((2, 2))(d4)\n",
    "    d4 = d_layer(d4, d_filters_base*4)\n",
    "    d5 = d_layer(d4, d_filters_base*2)\n",
    "    d6 = d_layer(d5, d_filters_base*1)\n",
    "    \n",
    "    validity = Conv2D(1, kernel_size=3, strides=1, padding='same')(d6)\n",
    "    model = Model([matrix_A, matrix_B], validity)\n",
    "    model.compile(optimizer=Adam(lr=learn_rate_d), loss=wasserstein_loss, metrics=['mse'])   #binary_crossentropy\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_filters_base = 32\n",
    "# # Input shape\n",
    "\n",
    "# # Discriminator\n",
    "# def build_critic():\n",
    "#     def d_layer(layer_input, filters, f_size=3, bn=True, stride=1):\n",
    "#         \"\"\"Discriminator layer\"\"\"\n",
    "#         d = Conv2D(filters, kernel_size=f_size, strides=stride, padding='same', kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "#                   kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(layer_input)\n",
    "#         if bn:\n",
    "#             d = BatchNormalization()(d)\n",
    "#         d = LeakyReLU(alpha=0.1)(d)\n",
    "#         return d\n",
    "    \n",
    "#     combined_matrix = Input(shape=matrix_shape)\n",
    "\n",
    "#     # Concatenate image and conditioning image生成输入对象\n",
    "# #     combined_matrix = Concatenate(axis=-1)([matrix_A, matrix_B])\n",
    "\n",
    "#     d1 = d_layer(combined_matrix, d_filters_base, bn=False)\n",
    "#     d2 = d_layer(d1, d_filters_base*2, stride=2)\n",
    "# #     d2 = AveragePooling2D((2, 2))(d2)\n",
    "#     d3 = d_layer(d2, d_filters_base*4, stride=2)\n",
    "# #     d3 = AveragePooling2D((2, 2))(d3)\n",
    "#     d4 = d_layer(d3, d_filters_base*8, stride=2)\n",
    "# #     d4 = AveragePooling2D((2, 2))(d4)\n",
    "#     d4 = d_layer(d4, d_filters_base*4)\n",
    "#     d5 = d_layer(d4, d_filters_base*2)\n",
    "#     d6 = d_layer(d5, d_filters_base*1)\n",
    "    \n",
    "#     validity = Conv2D(1, kernel_size=3, strides=1, padding='same')(d6)\n",
    "#     model = Model([matrix_A, matrix_B], validity)\n",
    "# #     model.compile(optimizer=Adam(lr=learn_rate_d), loss=wasserstein_loss, metrics=['mse'])   #binary_crossentropy\n",
    "#     return model\n",
    "\n",
    "# def build_discriminator():\n",
    "#     critic = build_critic()\n",
    "#     matrix_A = Input(shape=true_volume_shape)\n",
    "#     matrix_Fake = Input(shape=true_volume_shape)\n",
    "#     matrix_B = Input(shape=history_volume_shape)\n",
    "    \n",
    "#     true_vaild = critic.predict(Concatenate(axis=-1)([true_volume, history_volume]))\n",
    "#     fake_vaild = critic.predict(Concatenate(axis=-1)([forecast_volume, history_volume]))\n",
    "    \n",
    "#     # Construct weighted average between real and fake images\n",
    "#     interpolated_img = RandomWeightedAverage()([matrix_A, matrix_Fake])\n",
    "#     # Determine validity of weighted sample\n",
    "#     validity_interpolated = critic(interpolated_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=learn_rate_c)\n",
    "\n",
    "# Build and compile the discriminator\n",
    "discriminator = build_discriminator()\n",
    "\n",
    "# Build the generator\n",
    "generator = build_generator()\n",
    "\n",
    "# Input images and their conditioning images\n",
    "true_volume = Input(shape=true_volume_shape)\n",
    "history_volume = Input(shape=history_volume_shape)\n",
    "\n",
    "# By conditioning on B generate a fake version of A\n",
    "forecast_volume = generator(history_volume)\n",
    "\n",
    "# For the combined model we will only train the generator\n",
    "discriminator.trainable = False\n",
    "\n",
    "# Discriminators determines validity of translated images / condition pairs\n",
    "valid_gan = discriminator([forecast_volume, history_volume])\n",
    "\n",
    "combined = Model(inputs=[true_volume, history_volume], outputs=[valid_gan, forecast_volume])\n",
    "combined.compile(optimizer=optimizer, loss=[wasserstein_loss, 'mse'], loss_weights=[1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_step = []\n",
    "l2_validation = []\n",
    "\n",
    "def train(train_matrix, epochs, batch_size=MAX_BATCH_SIZE, learn_rate=0.01):\n",
    "\n",
    "    start_time = datetime.datetime.now()\n",
    "    print(\"train start \"+str(start_time))\n",
    "\n",
    "    # Adversarial loss ground truths\n",
    "#     valid = np.ones((MAX_BATCH_SIZE,) + disc_patch)+np.random.rand(MAX_BATCH_SIZE, patch, patch, 1)/5\n",
    "#     fake = np.zeros((MAX_BATCH_SIZE,) + disc_patch)+np.random.rand(MAX_BATCH_SIZE, patch, patch, 1)/5\n",
    "    valid = np.ones((MAX_BATCH_SIZE,) + disc_patch)\n",
    "#     fake = np.zeros((MAX_BATCH_SIZE,) + disc_patch)\n",
    "    fake = np.ones((MAX_BATCH_SIZE,) + disc_patch)*(-1)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        if epoch>=70 and epoch % 5 == 0 and epoch != 0:\n",
    "            generator_lr = K.get_value(generator.optimizer.lr)\n",
    "            discriminator_lr = K.get_value(discriminator.optimizer.lr)\n",
    "            combined_lr = K.get_value(combined.optimizer.lr)\n",
    "            if generator_lr>0.0002:\n",
    "                K.set_value(generator.optimizer.lr, generator_lr)\n",
    "            if discriminator_lr>0.0002:\n",
    "                K.set_value(discriminator.optimizer.lr, discriminator_lr)\n",
    "            if combined_lr>0.0002:\n",
    "                K.set_value(combined.optimizer.lr, combined_lr)\n",
    "\n",
    "        for batch_i, (true_volume, history_volume) in enumerate(load_data(train_matrix,batch_size)):\n",
    "            # true_volume 真实待预测路网交通量  history_volume 路网交通量历史数据\n",
    "            #  训练 Discriminator\n",
    "\n",
    "            # 根据历史数据生成预测数据\n",
    "            forecast_volume = generator.predict(history_volume)\n",
    "\n",
    "            # 训练 the discriminators (original images = real / generated = Fake)\n",
    "            discriminator.trainable = True\n",
    "            d_loss_real = discriminator.train_on_batch([true_volume, history_volume], valid)\n",
    "            d_loss_fake = discriminator.train_on_batch([forecast_volume, history_volume], fake)\n",
    "            discriminator.trainable = False\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "\n",
    "            #  训练 Generator\n",
    "            g_loss = combined.train_on_batch([true_volume, history_volume], [valid, true_volume])\n",
    "\n",
    "            elapsed_time = datetime.datetime.now() - start_time\n",
    "\n",
    "        # Plot the progress\n",
    "        y_pred = generator.predict(X_test[:, :, :, 1:])\n",
    "        y_true = X_test[:, :, :, :1]\n",
    "\n",
    "        l2_epoch_validation = l2(y_true, y_pred)\n",
    "        lr_step.append(K.get_value(discriminator.optimizer.lr))\n",
    "        l2_validation.append(l2_epoch_validation)\n",
    "        if epoch%1==0:\n",
    "#             print(\"discriminator lr:\"+ str(K.get_value(discriminator.optimizer.lr)))\n",
    "            print (\"[Epoch %d/%d]  [D loss: %f, mse: %f] [G loss: %f] time: %s\" % (epoch+1, epochs,\n",
    "                                                                    d_loss[0], l2_epoch_validation,\n",
    "                                                                    g_loss[0],\n",
    "                                                                    elapsed_time))\n",
    "        # If at show interval => show generated image samples\n",
    "#             if epoch % show_interval == 0:\n",
    "#                     show_images(dataset_name,epoch, batch_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train start 2019-11-19 15:19:07.826139\n",
      "[Epoch 1/200]  [D loss: 0.228623, mse: 30.229881] [G loss: 4376.897461] time: 0:01:10.369995\n",
      "[Epoch 2/200]  [D loss: 0.039145, mse: 28.159761] [G loss: 2739.358887] time: 0:01:54.305126\n",
      "[Epoch 3/200]  [D loss: 0.576702, mse: 28.821454] [G loss: 3711.226807] time: 0:02:38.934395\n",
      "[Epoch 4/200]  [D loss: 0.106777, mse: 22.911211] [G loss: 4088.189941] time: 0:03:22.601545\n",
      "[Epoch 5/200]  [D loss: 0.075902, mse: 23.102280] [G loss: 6522.322754] time: 0:04:05.930717\n",
      "[Epoch 6/200]  [D loss: 0.619265, mse: 22.241135] [G loss: 5198.023438] time: 0:04:49.335678\n",
      "[Epoch 7/200]  [D loss: 0.413778, mse: 21.378529] [G loss: 4871.110352] time: 0:05:32.503437\n",
      "[Epoch 8/200]  [D loss: 0.248781, mse: 21.258985] [G loss: 1875.571289] time: 0:06:16.298305\n",
      "[Epoch 9/200]  [D loss: 1.092792, mse: 20.512370] [G loss: 1747.031982] time: 0:06:59.257175\n",
      "[Epoch 10/200]  [D loss: 0.250272, mse: 20.911221] [G loss: 2829.020020] time: 0:07:42.530902\n",
      "[Epoch 11/200]  [D loss: 0.152685, mse: 21.360069] [G loss: 1646.360718] time: 0:08:25.408422\n",
      "[Epoch 12/200]  [D loss: 0.042228, mse: 20.008665] [G loss: 1621.191406] time: 0:09:07.958315\n",
      "[Epoch 13/200]  [D loss: 0.143013, mse: 21.089807] [G loss: 2417.724854] time: 0:09:50.408723\n",
      "[Epoch 14/200]  [D loss: 0.248421, mse: 20.248877] [G loss: 1607.814697] time: 0:10:32.888424\n",
      "[Epoch 15/200]  [D loss: 0.158790, mse: 22.339383] [G loss: 2205.751709] time: 0:11:15.399643\n",
      "[Epoch 16/200]  [D loss: 0.153002, mse: 20.291071] [G loss: 1581.843994] time: 0:11:58.280412\n",
      "[Epoch 17/200]  [D loss: 0.003263, mse: 22.398411] [G loss: 2187.483398] time: 0:12:41.861960\n",
      "[Epoch 18/200]  [D loss: 0.000060, mse: 22.898509] [G loss: 2264.531982] time: 0:13:25.896839\n",
      "[Epoch 19/200]  [D loss: 0.000066, mse: 19.004476] [G loss: 1496.344482] time: 0:14:11.096573\n",
      "[Epoch 20/200]  [D loss: 0.000074, mse: 448.650437] [G loss: 1795.546997] time: 0:14:56.153327\n",
      "[Epoch 21/200]  [D loss: 0.000081, mse: 21.733697] [G loss: 2023.045776] time: 0:15:41.053692\n",
      "[Epoch 22/200]  [D loss: 0.000087, mse: 19.948569] [G loss: 1936.402100] time: 0:16:27.328441\n",
      "[Epoch 23/200]  [D loss: 0.000091, mse: 19.037934] [G loss: 1555.441528] time: 0:17:12.586139\n",
      "[Epoch 24/200]  [D loss: 0.000095, mse: 19.013241] [G loss: 1504.386841] time: 0:17:55.708229\n",
      "[Epoch 25/200]  [D loss: 0.000101, mse: 19.923841] [G loss: 1455.930176] time: 0:18:39.400908\n",
      "[Epoch 26/200]  [D loss: 0.000123, mse: 28.067175] [G loss: 1419.271362] time: 0:19:23.042286\n",
      "[Epoch 27/200]  [D loss: 0.000191, mse: 21.464486] [G loss: 6690.803223] time: 0:20:05.786463\n",
      "[Epoch 28/200]  [D loss: 0.000274, mse: 18.740765] [G loss: 1354.494141] time: 0:20:49.543112\n",
      "[Epoch 29/200]  [D loss: 0.000341, mse: 67.820121] [G loss: 2203.181152] time: 0:21:33.089017\n",
      "[Epoch 30/200]  [D loss: 0.979542, mse: 18.330123] [G loss: 1506.353394] time: 0:22:16.050482\n",
      "[Epoch 31/200]  [D loss: 0.271524, mse: 18.168551] [G loss: 1289.115723] time: 0:22:59.597011\n",
      "[Epoch 32/200]  [D loss: 0.005225, mse: 52.819538] [G loss: 1298.703735] time: 0:23:44.868844\n",
      "[Epoch 33/200]  [D loss: 0.000058, mse: 20.565277] [G loss: 1632.046265] time: 0:24:28.181456\n",
      "[Epoch 34/200]  [D loss: 0.000062, mse: 18.085616] [G loss: 1822.935669] time: 0:25:11.635680\n",
      "[Epoch 35/200]  [D loss: 0.000066, mse: 18.169990] [G loss: 1582.468262] time: 0:25:54.648547\n",
      "[Epoch 36/200]  [D loss: 0.000069, mse: 24.028134] [G loss: 1550.838135] time: 0:26:37.646629\n",
      "[Epoch 37/200]  [D loss: 0.000072, mse: 18.002623] [G loss: 1853.837769] time: 0:27:20.581743\n",
      "[Epoch 38/200]  [D loss: 0.000075, mse: 18.886638] [G loss: 1279.313110] time: 0:28:03.743068\n",
      "[Epoch 39/200]  [D loss: 0.000076, mse: 19.088928] [G loss: 1509.699707] time: 0:28:46.771351\n",
      "[Epoch 40/200]  [D loss: 0.000080, mse: 19.867567] [G loss: 1595.680176] time: 0:29:29.805077\n",
      "[Epoch 41/200]  [D loss: 0.000096, mse: 17.868978] [G loss: 1450.007202] time: 0:30:13.722967\n",
      "[Epoch 42/200]  [D loss: 0.000142, mse: 22.399038] [G loss: 1374.060303] time: 0:30:57.862287\n",
      "[Epoch 43/200]  [D loss: 0.000236, mse: 17.919051] [G loss: 1341.598511] time: 0:31:41.782248\n",
      "[Epoch 44/200]  [D loss: 0.000361, mse: 22.139377] [G loss: 2703.712158] time: 0:32:25.220965\n",
      "[Epoch 45/200]  [D loss: 0.000512, mse: 17.469042] [G loss: 1175.239502] time: 0:33:09.071148\n",
      "[Epoch 46/200]  [D loss: 0.000694, mse: 17.761189] [G loss: 3225.552490] time: 0:33:52.663899\n",
      "[Epoch 47/200]  [D loss: 0.000563, mse: 17.632880] [G loss: 1138.800171] time: 0:34:35.517799\n",
      "[Epoch 48/200]  [D loss: 0.000671, mse: 19.416853] [G loss: 2105.710693] time: 0:35:18.331328\n",
      "[Epoch 49/200]  [D loss: 0.000678, mse: 21.581085] [G loss: 1427.533691] time: 0:36:01.199771\n",
      "[Epoch 50/200]  [D loss: 0.000646, mse: 19.462988] [G loss: 1792.302124] time: 0:36:43.983738\n",
      "[Epoch 51/200]  [D loss: 0.000597, mse: 17.167248] [G loss: 1188.545288] time: 0:37:26.874437\n",
      "[Epoch 52/200]  [D loss: 0.070532, mse: 17.470676] [G loss: 1986.590454] time: 0:38:09.828984\n",
      "[Epoch 53/200]  [D loss: 0.000043, mse: 19.067062] [G loss: 1122.264648] time: 0:38:52.681153\n",
      "[Epoch 54/200]  [D loss: 0.000046, mse: 18.172855] [G loss: 1605.229980] time: 0:39:35.683790\n",
      "[Epoch 55/200]  [D loss: 0.000048, mse: 18.813047] [G loss: 1852.407104] time: 0:40:18.613582\n",
      "[Epoch 56/200]  [D loss: 0.000050, mse: 17.186165] [G loss: 1311.494385] time: 0:41:01.548345\n",
      "[Epoch 57/200]  [D loss: 0.000052, mse: 20.291755] [G loss: 2305.427246] time: 0:41:44.719335\n",
      "[Epoch 58/200]  [D loss: 0.000057, mse: 23.764237] [G loss: 1129.684326] time: 0:42:28.629156\n",
      "[Epoch 59/200]  [D loss: 0.000065, mse: 19.632723] [G loss: 1311.996582] time: 0:43:12.497014\n",
      "[Epoch 60/200]  [D loss: 0.000075, mse: 19.583267] [G loss: 3342.873535] time: 0:43:56.507554\n",
      "[Epoch 61/200]  [D loss: 0.000084, mse: 17.006004] [G loss: 1266.103271] time: 0:44:40.107221\n",
      "[Epoch 62/200]  [D loss: 0.000117, mse: 18.062304] [G loss: 1390.456299] time: 0:45:22.988227\n",
      "[Epoch 63/200]  [D loss: 0.000182, mse: 20.168897] [G loss: 1198.157349] time: 0:46:05.973128\n",
      "[Epoch 64/200]  [D loss: 0.000352, mse: 16.708746] [G loss: 3180.584961] time: 0:46:48.703828\n",
      "[Epoch 65/200]  [D loss: 0.000401, mse: 16.843623] [G loss: 1101.078125] time: 0:47:31.845403\n",
      "[Epoch 66/200]  [D loss: 0.000557, mse: 18.040517] [G loss: 1659.993164] time: 0:48:14.861638\n",
      "[Epoch 67/200]  [D loss: 0.000582, mse: 16.674432] [G loss: 1311.822021] time: 0:48:57.712907\n",
      "[Epoch 68/200]  [D loss: 0.000623, mse: 18.078329] [G loss: 1039.013062] time: 0:49:40.777340\n",
      "[Epoch 69/200]  [D loss: 0.000626, mse: 21.628013] [G loss: 2835.122070] time: 0:50:23.976695\n",
      "[Epoch 70/200]  [D loss: 0.000618, mse: 17.667859] [G loss: 1013.526672] time: 0:51:06.930834\n",
      "[Epoch 71/200]  [D loss: 0.000587, mse: 22.775270] [G loss: 1431.520142] time: 0:51:56.951361\n",
      "[Epoch 72/200]  [D loss: 0.000579, mse: 27.396822] [G loss: 1075.586914] time: 0:52:40.187325\n",
      "[Epoch 73/200]  [D loss: 0.000560, mse: 24.172085] [G loss: 1289.610474] time: 0:53:23.092634\n",
      "[Epoch 74/200]  [D loss: 0.000580, mse: 19.037174] [G loss: 1776.652954] time: 0:54:06.404955\n",
      "[Epoch 75/200]  [D loss: 0.000706, mse: 16.800360] [G loss: 1023.979492] time: 0:54:48.639275\n",
      "[Epoch 76/200]  [D loss: 0.000524, mse: 17.319731] [G loss: 1577.931396] time: 0:55:30.928730\n",
      "[Epoch 77/200]  [D loss: 0.000704, mse: 18.888757] [G loss: 1032.354614] time: 0:56:13.259312\n",
      "[Epoch 78/200]  [D loss: 0.000458, mse: 20.235789] [G loss: 1364.063477] time: 0:56:55.531146\n",
      "[Epoch 79/200]  [D loss: 0.000630, mse: 26.665625] [G loss: 1812.833008] time: 0:57:37.816609\n",
      "[Epoch 80/200]  [D loss: 0.000648, mse: 19.904171] [G loss: 1085.734863] time: 0:58:20.185872\n",
      "[Epoch 81/200]  [D loss: 0.000470, mse: 16.558111] [G loss: 1211.703979] time: 0:59:02.445774\n",
      "[Epoch 82/200]  [D loss: 0.000514, mse: 16.733081] [G loss: 1165.972534] time: 0:59:44.763119\n",
      "[Epoch 83/200]  [D loss: 0.000600, mse: 17.495642] [G loss: 1176.340942] time: 1:00:27.014199\n",
      "[Epoch 84/200]  [D loss: 0.000645, mse: 17.440210] [G loss: 1040.269287] time: 1:01:09.285202\n",
      "[Epoch 85/200]  [D loss: 0.000557, mse: 16.849852] [G loss: 952.912598] time: 1:01:51.749184\n",
      "[Epoch 86/200]  [D loss: 0.000548, mse: 25.655752] [G loss: 1035.603394] time: 1:02:33.998967\n",
      "[Epoch 87/200]  [D loss: 0.000676, mse: 17.129616] [G loss: 966.445557] time: 1:03:16.269182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 88/200]  [D loss: 0.000600, mse: 21.047509] [G loss: 1670.166992] time: 1:03:58.512462\n",
      "[Epoch 89/200]  [D loss: 0.000540, mse: 65.157155] [G loss: 1102.854736] time: 1:04:40.826566\n",
      "[Epoch 90/200]  [D loss: 0.000563, mse: 18.372980] [G loss: 978.842346] time: 1:05:23.105784\n",
      "[Epoch 91/200]  [D loss: 0.000537, mse: 24.275285] [G loss: 980.084106] time: 1:06:05.404446\n",
      "[Epoch 92/200]  [D loss: 0.000831, mse: 16.249212] [G loss: 935.296936] time: 1:06:47.694437\n",
      "[Epoch 93/200]  [D loss: 0.000590, mse: 15.802173] [G loss: 885.407104] time: 1:07:29.925472\n",
      "[Epoch 94/200]  [D loss: 0.000602, mse: 18.207381] [G loss: 939.417664] time: 1:08:12.429527\n",
      "[Epoch 95/200]  [D loss: 0.000680, mse: 16.035847] [G loss: 880.101440] time: 1:08:54.744306\n",
      "[Epoch 96/200]  [D loss: 0.000571, mse: 16.991398] [G loss: 1064.237305] time: 1:09:37.071886\n",
      "[Epoch 97/200]  [D loss: 0.000633, mse: 19.346990] [G loss: 1147.437500] time: 1:10:19.306997\n",
      "[Epoch 98/200]  [D loss: 0.000776, mse: 16.134303] [G loss: 937.227722] time: 1:11:01.580901\n",
      "[Epoch 99/200]  [D loss: 0.000556, mse: 17.722441] [G loss: 944.273560] time: 1:11:43.851487\n",
      "[Epoch 100/200]  [D loss: 0.000496, mse: 15.634092] [G loss: 873.188538] time: 1:12:26.342820\n",
      "[Epoch 101/200]  [D loss: 0.000549, mse: 16.740066] [G loss: 871.029297] time: 1:13:08.577414\n",
      "[Epoch 102/200]  [D loss: 0.000578, mse: 19.896214] [G loss: 1218.992188] time: 1:13:50.819727\n",
      "[Epoch 103/200]  [D loss: 0.000555, mse: 18.595118] [G loss: 1081.673462] time: 1:14:33.134231\n",
      "[Epoch 104/200]  [D loss: 0.000605, mse: 17.619575] [G loss: 975.427368] time: 1:15:15.382623\n",
      "[Epoch 105/200]  [D loss: 0.000632, mse: 17.466454] [G loss: 946.025696] time: 1:15:57.806955\n",
      "[Epoch 106/200]  [D loss: 0.000715, mse: 17.292335] [G loss: 907.903259] time: 1:16:40.254156\n",
      "[Epoch 107/200]  [D loss: 0.000622, mse: 17.355609] [G loss: 1111.712158] time: 1:17:23.508288\n",
      "[Epoch 108/200]  [D loss: 0.000708, mse: 16.863855] [G loss: 1103.928345] time: 1:18:06.059355\n",
      "[Epoch 109/200]  [D loss: 0.000642, mse: 15.296714] [G loss: 1090.728638] time: 1:18:48.372310\n",
      "[Epoch 110/200]  [D loss: 0.000658, mse: 18.093472] [G loss: 1096.353394] time: 1:19:30.536992\n",
      "[Epoch 111/200]  [D loss: 0.000612, mse: 17.125791] [G loss: 944.811829] time: 1:20:12.602565\n",
      "[Epoch 112/200]  [D loss: 0.000625, mse: 15.717373] [G loss: 829.335571] time: 1:20:54.684333\n",
      "[Epoch 113/200]  [D loss: 0.000629, mse: 40.395028] [G loss: 825.340088] time: 1:21:37.231013\n",
      "[Epoch 114/200]  [D loss: 0.000659, mse: 16.613042] [G loss: 773.523315] time: 1:22:19.610205\n",
      "[Epoch 115/200]  [D loss: 0.000696, mse: 15.522643] [G loss: 835.667358] time: 1:23:02.060326\n",
      "[Epoch 116/200]  [D loss: 0.000655, mse: 17.102218] [G loss: 774.287292] time: 1:23:44.386343\n",
      "[Epoch 117/200]  [D loss: 0.000643, mse: 15.115572] [G loss: 778.925415] time: 1:24:27.308994\n",
      "[Epoch 118/200]  [D loss: 0.000662, mse: 17.171727] [G loss: 808.424927] time: 1:25:09.825832\n",
      "[Epoch 119/200]  [D loss: 0.000562, mse: 16.236804] [G loss: 799.145142] time: 1:25:52.295594\n",
      "[Epoch 120/200]  [D loss: 0.000632, mse: 16.885049] [G loss: 1102.095459] time: 1:26:34.704460\n",
      "[Epoch 121/200]  [D loss: 0.000567, mse: 22.449251] [G loss: 741.301270] time: 1:27:17.200018\n",
      "[Epoch 122/200]  [D loss: 0.000683, mse: 17.241969] [G loss: 2405.807861] time: 1:27:59.583841\n",
      "[Epoch 123/200]  [D loss: 0.000569, mse: 15.340003] [G loss: 673.934509] time: 1:28:42.207706\n",
      "[Epoch 124/200]  [D loss: 0.000581, mse: 17.935260] [G loss: 677.867004] time: 1:29:24.651953\n",
      "[Epoch 125/200]  [D loss: 0.000614, mse: 170.911940] [G loss: 664.498474] time: 1:30:07.032314\n",
      "[Epoch 126/200]  [D loss: 0.000625, mse: 20.331127] [G loss: 680.663147] time: 1:30:49.824757\n",
      "[Epoch 127/200]  [D loss: 0.000574, mse: 16.505910] [G loss: 1148.243408] time: 1:31:32.246828\n",
      "[Epoch 128/200]  [D loss: 0.000627, mse: 16.736701] [G loss: 646.691162] time: 1:32:14.903338\n",
      "[Epoch 129/200]  [D loss: 0.000641, mse: 15.165415] [G loss: 1050.539795] time: 1:32:57.552877\n",
      "[Epoch 130/200]  [D loss: 0.000604, mse: 14.641801] [G loss: 801.946533] time: 1:33:40.065449\n",
      "[Epoch 131/200]  [D loss: 0.000601, mse: 16.343837] [G loss: 648.704529] time: 1:34:22.508740\n",
      "[Epoch 132/200]  [D loss: 0.000603, mse: 16.417299] [G loss: 786.594116] time: 1:35:05.210054\n",
      "[Epoch 133/200]  [D loss: 0.000637, mse: 18.115328] [G loss: 1175.336670] time: 1:35:47.939906\n",
      "[Epoch 134/200]  [D loss: 0.000605, mse: 21.342149] [G loss: 790.674316] time: 1:36:30.468871\n",
      "[Epoch 135/200]  [D loss: 0.000652, mse: 190.211520] [G loss: 1691.273926] time: 1:37:13.161617\n",
      "[Epoch 136/200]  [D loss: 0.000570, mse: 17.756922] [G loss: 623.793884] time: 1:37:55.645992\n",
      "[Epoch 137/200]  [D loss: 0.000650, mse: 15.673340] [G loss: 794.865540] time: 1:38:38.170408\n",
      "[Epoch 138/200]  [D loss: 0.000589, mse: 14.738943] [G loss: 589.333557] time: 1:39:20.730305\n",
      "[Epoch 139/200]  [D loss: 0.000605, mse: 16.869612] [G loss: 629.529785] time: 1:40:03.157196\n",
      "[Epoch 140/200]  [D loss: 0.000705, mse: 18.223229] [G loss: 779.203247] time: 1:40:45.776904\n",
      "[Epoch 141/200]  [D loss: 0.000612, mse: 16.905364] [G loss: 619.858582] time: 1:41:28.237057\n",
      "[Epoch 142/200]  [D loss: 0.000667, mse: 24.619696] [G loss: 1200.134155] time: 1:42:11.032784\n",
      "[Epoch 143/200]  [D loss: 0.000611, mse: 14.370111] [G loss: 1139.571899] time: 1:42:53.843860\n",
      "[Epoch 144/200]  [D loss: 0.000700, mse: 14.656415] [G loss: 902.176453] time: 1:43:37.868179\n",
      "[Epoch 145/200]  [D loss: 0.000665, mse: 21.186121] [G loss: 611.483765] time: 1:44:22.171789\n",
      "[Epoch 146/200]  [D loss: 0.000599, mse: 15.550117] [G loss: 706.633789] time: 1:45:06.222628\n",
      "[Epoch 147/200]  [D loss: 0.000542, mse: 19.745741] [G loss: 689.786987] time: 1:45:49.669601\n",
      "[Epoch 148/200]  [D loss: 0.000633, mse: 17.606089] [G loss: 724.254700] time: 1:46:32.033239\n",
      "[Epoch 149/200]  [D loss: 0.000629, mse: 16.973440] [G loss: 957.439331] time: 1:47:14.224320\n",
      "[Epoch 150/200]  [D loss: 0.000622, mse: 16.857487] [G loss: 716.800171] time: 1:47:56.585913\n",
      "[Epoch 151/200]  [D loss: 0.000691, mse: 17.873786] [G loss: 638.302246] time: 1:48:39.286164\n",
      "[Epoch 152/200]  [D loss: 0.000695, mse: 18.762775] [G loss: 1073.798340] time: 1:49:21.710940\n",
      "[Epoch 153/200]  [D loss: 0.000661, mse: 17.232639] [G loss: 824.238708] time: 1:50:04.533366\n",
      "[Epoch 154/200]  [D loss: 0.000619, mse: 15.810437] [G loss: 659.103333] time: 1:50:47.384677\n",
      "[Epoch 155/200]  [D loss: 0.000685, mse: 15.877547] [G loss: 686.812195] time: 1:51:30.107327\n",
      "[Epoch 156/200]  [D loss: 0.000689, mse: 100.033977] [G loss: 727.990662] time: 1:52:12.963956\n",
      "[Epoch 157/200]  [D loss: 0.000547, mse: 86.008143] [G loss: 843.100037] time: 1:52:55.130767\n",
      "[Epoch 158/200]  [D loss: 0.000637, mse: 17.360964] [G loss: 703.370117] time: 1:53:37.269727\n",
      "[Epoch 159/200]  [D loss: 0.000598, mse: 16.990779] [G loss: 666.610718] time: 1:54:19.404138\n",
      "[Epoch 160/200]  [D loss: 0.000634, mse: 17.005557] [G loss: 683.268921] time: 1:55:01.874499\n",
      "[Epoch 161/200]  [D loss: 0.000678, mse: 20.781643] [G loss: 658.699585] time: 1:55:46.003660\n",
      "[Epoch 162/200]  [D loss: 0.000711, mse: 41.738193] [G loss: 951.419983] time: 1:56:28.377023\n",
      "[Epoch 163/200]  [D loss: 0.000690, mse: 16.927522] [G loss: 930.406616] time: 1:57:10.951936\n",
      "[Epoch 164/200]  [D loss: 0.000671, mse: 23.043832] [G loss: 577.516602] time: 1:57:55.623752\n",
      "[Epoch 165/200]  [D loss: 0.000652, mse: 44.233880] [G loss: 758.528137] time: 1:58:38.636036\n",
      "[Epoch 166/200]  [D loss: 0.000695, mse: 16.111265] [G loss: 868.502747] time: 1:59:21.910671\n",
      "[Epoch 167/200]  [D loss: 0.000653, mse: 19.985211] [G loss: 687.575317] time: 2:00:05.073954\n",
      "[Epoch 168/200]  [D loss: 0.000615, mse: 16.013872] [G loss: 1070.512451] time: 2:00:47.404419\n",
      "[Epoch 169/200]  [D loss: 0.000582, mse: 17.375405] [G loss: 770.670288] time: 2:01:29.700011\n",
      "[Epoch 170/200]  [D loss: 0.000663, mse: 15.129836] [G loss: 915.063293] time: 2:02:12.101991\n",
      "[Epoch 171/200]  [D loss: 0.000664, mse: 18.477145] [G loss: 741.651489] time: 2:02:54.298082\n",
      "[Epoch 172/200]  [D loss: 0.000594, mse: 18.418943] [G loss: 969.935913] time: 2:03:37.017935\n",
      "[Epoch 173/200]  [D loss: 0.000657, mse: 15.509058] [G loss: 865.671143] time: 2:04:20.868844\n",
      "[Epoch 174/200]  [D loss: 0.000603, mse: 20.273005] [G loss: 875.385742] time: 2:05:03.883210\n",
      "[Epoch 175/200]  [D loss: 0.000619, mse: 18.670429] [G loss: 748.348694] time: 2:05:46.567363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 176/200]  [D loss: 0.000598, mse: 23.055457] [G loss: 659.444153] time: 2:06:29.511516\n",
      "[Epoch 177/200]  [D loss: 0.000624, mse: 20.471444] [G loss: 997.841797] time: 2:07:11.800780\n",
      "[Epoch 178/200]  [D loss: 0.000621, mse: 26.117248] [G loss: 764.451660] time: 2:07:54.109440\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-148-f2845cdbc646>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMAX_BATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearn_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearn_rate_c\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-147-b83af471e705>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(train_matrix, epochs, batch_size, learn_rate)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[1;31m#  训练 Generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mg_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcombined\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrue_volume\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory_volume\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvalid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_volume\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1213\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1214\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1215\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1216\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2664\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2666\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2667\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2668\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2635\u001b[0m                                 session)\n\u001b[1;32m-> 2636\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2637\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(X_train, epochs=200, batch_size=MAX_BATCH_SIZE, learn_rate=learn_rate_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator.save_weights('/kaggle/working/generatorModel.h5')\n",
    "# generator.load_weights('/kaggle/working/generatorModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = generator.predict(X_test[:, :, :, 1:])\n",
    "y_true = X_test[:, :, :, :1]\n",
    "\n",
    "l2(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2(y_true, y_pred+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y = y_true.reshape(-1,)[1600:1700]\n",
    "x = np.linspace(0, len(y), len(y))\n",
    "\n",
    "yi = y_pred.reshape(-1,)[1600:1700]\n",
    "xi = np.linspace(0, len(yi), len(yi))\n",
    "fig, ax = plt.subplots(figsize=(25, 6))\n",
    "# ax.plot(x, y, '.', linewidth=1, markersize=10)\n",
    "lines = plt.plot(xi, yi, 'k^--', x, y, 'ro-',linewidth=1, markersize=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yi = l2_validation\n",
    "xi = np.linspace(0, len(yi), len(yi))\n",
    "\n",
    "y = [i*10000 for i in lr_step]\n",
    "x = np.linspace(0, len(y), len(y))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "lines = plt.plot(x, y, 'ko-', xi, yi, 'k^--', linewidth=1, markersize=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = lr_step\n",
    "x = np.linspace(0, len(y), len(y))\n",
    "# fig, ax = plt.subplots(figsize=(6, 6))\n",
    "# lines = plt.plot(x, y, 'ko-', linewidth=1, markersize=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_true.reshape(-1,)[3600:3700]\n",
    "x = np.linspace(0, len(y), len(y))\n",
    "\n",
    "yi = y_pred.reshape(-1,)[3600:3700]\n",
    "xi = np.linspace(0, len(yi), len(yi))\n",
    "fig, ax = plt.subplots(figsize=(25, 6))\n",
    "ax.plot(x, y, '.', linewidth=1, markersize=10)\n",
    "lines = plt.plot(xi, yi, 'k^--', x, y, 'ro-',linewidth=1, markersize=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = 0\n",
    "y = y_true.reshape(-1,)[start_time: start_time+100]\n",
    "x = np.linspace(0, len(y), len(y))\n",
    "\n",
    "yi = y_pred.reshape(-1,)[start_time: start_time+100]\n",
    "xi = np.linspace(0, len(yi), len(yi))\n",
    "fig, ax = plt.subplots(figsize=(25, 6))\n",
    "# ax.plot(x, y, '.', linewidth=1, markersize=10)\n",
    "lines = plt.plot(xi, yi, 'k^--', x, y, 'ro-',linewidth=1, markersize=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
