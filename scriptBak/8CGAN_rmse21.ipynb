{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport scipy\nfrom glob import glob\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom skimage import transform\n\nfrom keras.layers import Input, Dense, Reshape, Flatten, Dropout, concatenate, Concatenate\nfrom keras.layers import BatchNormalization, Activation, ZeroPadding2D, Add, Subtract\nfrom keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D ,AveragePooling2D\nfrom keras.layers.advanced_activations import LeakyReLU, ELU\nfrom keras.layers.convolutional import UpSampling2D, Conv2D\nfrom keras.models import Sequential, Model\nfrom keras.optimizers import Adam, Nadam, RMSprop\nimport datetime\nimport sys\nimport os\n\nimport gc\nfrom copy import deepcopy\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, TensorBoard\nfrom keras import backend as K\nfrom keras import initializers\nfrom keras import regularizers\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom keras.models import load_model  \nprint(os.listdir(\"../input\"))\n\n%matplotlib inline\n%load_ext autoreload\n%autoreload 2\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"},{"output_type":"stream","text":"['england-traffic-volume']\n/kaggle/input/england-traffic-volume/trafficV_M.csv\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"加载  预处理数据"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 交通矩阵为 matrix_length*matrix_length\nmatrix_length = 32\n\nmatrix_df = pd.read_csv('../input/england-traffic-volume/trafficV_M.csv', index_col=0, parse_dates=True)","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def createTrainArray(week_history_num=0, minute_history_num=0):\n    week_delta_list = [pd.Timedelta(i+1, unit='W') for i in range(week_history_num)]\n    minute_delta_list = [pd.Timedelta((i+1)*15, unit='m') for i in range(minute_history_num)]\n    # 参考历史数据时间点list\n    delta_list = week_delta_list+minute_delta_list\n    print(delta_list)\n    \n    set_up_time = pd.Timedelta(week_history_num, unit='W')\n    # 根据历史数据选取多少，重新构建数据集\n    # 相当于去除最开始week_history_num个周的数据，因为这些数据无法找到更前的数据\n    train_df = matrix_df.truncate(before=matrix_df.index.min() + set_up_time)\n    \n    train_ago_array_tuple = tuple([np.array(matrix_df.loc[train_df.index - i]).reshape(-1, matrix_length, matrix_length, 1) for i in delta_list])\n    train_df = np.array(train_df).reshape(-1, matrix_length, matrix_length, 1)\n    # concatenate保持 待修复数据在前，参考历史数据在后。与random_mask函数生成mask相一致\n    train_array = np.concatenate((train_df,)+train_ago_array_tuple, axis=3)\n    print(train_array.shape)\n    return train_array\n\n\ndef normalization(matrix):\n    for i in range(len(matrix)):\n        for j in range(matrix.shape[-1]):\n            cur_time = matrix[i][:, :, j]\n#             mean_val = cur_time.mean()\n            mx = cur_time.max()\n            mn = cur_time.min()\n            matrix[i][:, :, j] = np.divide((cur_time-mn), (mx-mn))\n    return matrix","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"week_history_num = 2\nminute_history_num = 3\n\nchannel_num = week_history_num +minute_history_num +1\nsmooth_time = channel_num-1\n\n# train_array为(16704, 32, 32, 3)，16704个矩阵，32*32采集点，3从上到下为当前时间，上一周，上一15min\ntrain_array = createTrainArray(week_history_num, minute_history_num)\nX_train, X_test = train_test_split(train_array, test_size = 0.2, random_state=42, shuffle=False)\n# X_train, X_val = train_test_split(train_array, test_size = 0.1, random_state=42, shuffle=False) # 不shuffle可用于查看数据正确性","execution_count":4,"outputs":[{"output_type":"stream","text":"[Timedelta('7 days 00:00:00'), Timedelta('14 days 00:00:00'), Timedelta('0 days 00:15:00'), Timedelta('0 days 00:30:00'), Timedelta('0 days 00:45:00')]\n(16032, 32, 32, 6)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape, X_test.shape","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"((12825, 32, 32, 6), (3207, 32, 32, 6))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_BATCH_SIZE = 32\nepoch_steps = X_train.shape[0] // MAX_BATCH_SIZE\ntest_steps = X_test.shape[0] // MAX_BATCH_SIZE\nepoch_steps, test_steps","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"(400, 100)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 加载数据\ndef load_data(volume_matrix, batch_size=MAX_BATCH_SIZE):\n    n_batches=batch_size\n    len_of_matrix = len(volume_matrix)\n\n    batch_i = 0\n    while ((batch_i+1)*batch_size < len_of_matrix):\n        batch_matrix = volume_matrix[batch_i*batch_size: (batch_i+1)*batch_size]\n        true_volume, history_volume = batch_matrix[:, :, :, :1], batch_matrix[:, :, :, 1:]\n#         history_volume = normalization(history_volume)\n        batch_i+=1\n\n        yield true_volume, history_volume","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\n\ndef l2(y_true, y_pred):\n    return math.sqrt(np.sum(np.mean(np.square(y_true - y_pred), axis=0))/1024)","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"模型"},{"metadata":{"trusted":true},"cell_type":"code","source":"def BatchActivate(x, bn=True):\n    if bn:\n        x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.2)(x)\n    return x\n\ndef convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n    if activation == True:\n        x = BatchActivate(x)\n    return x\n\ndef residual_block(blockInput, num_filters=16, batch_activate = False):\n    x = BatchActivate(blockInput)\n    x = convolution_block(x, num_filters, (3,3) )\n    x = convolution_block(x, num_filters, (3,3), activation=False)\n    x = Add()([x, blockInput])\n    if batch_activate:\n        x = BatchActivate(x)\n    return x","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def build_generator():      \n\n#     # INPUTS\n#     input_matrix = Input(shape=history_volume_shape)\n#     # kernel_init = initializers.he_normal()\n#     # bias_init = initializers.he_normal()\n#     kernel_init = 'glorot_uniform'\n#     bias_init = 'zeros'\n\n#     # kernel_init = initializers.he_uniform()\n#     # bias_init = initializers.he_uniform()\n#     kernel_regul = regularizers.l2(1)\n#     activity_regul = regularizers.l2(1)\n\n#     # ENCODER\n#     def encoder_layer(img_in, filters, kernel_size, bn=True, resid=True):\n#         # conv = Conv2D(filters=filters, kernel_size=kernel_size, strides=(1, 1), padding='same')(img_in)\n#         conv = Conv2D(filters, (kernel_size, kernel_size), padding=\"same\",\n#            strides=1,kernel_initializer='glorot_uniform')(img_in)\n#         if bn:\n#             conv = BatchNormalization()(conv)\n# #         conv = Activation('relu')(conv)\n#         conv = LeakyReLU(alpha=0.1)(conv)\n\n#         conv = Conv2D(filters, (kernel_size, kernel_size), padding=\"same\",\n#            strides=1,kernel_initializer='glorot_uniform')(conv)\n#         conv = BatchNormalization()(conv)\n# #         conv = Activation('relu')(conv)\n#         conv = LeakyReLU(alpha=0.1)(conv)\n#         return conv\n\n#     # DECODER\n#     def decoder_layer(img_in, filters, kernel_size, bn=True, resid=True):\n#         conv = Conv2D(filters, (3, 3), padding=\"same\",\n#            strides=1,kernel_initializer='glorot_uniform')(img_in)\n#         conv = BatchNormalization()(conv)\n#         conv = LeakyReLU(alpha=0.1)(conv)\n# #         conv = Activation('relu')(conv)\n\n#         conv = Conv2D(filters//2, (3, 3), padding=\"same\",\n#            strides=1,kernel_initializer='glorot_uniform')(conv)\n# #             if bn:\n#         conv = BatchNormalization()(conv)\n# #         conv = Activation('relu')(conv)\n#         conv = LeakyReLU(alpha=0.1)(conv)\n\n#         conv = UpSampling2D(size = (2,2))(conv)\n#         return conv\n\n#     encoder_layer.counter = 0\n#     conv1 = encoder_layer(input_matrix, 32, 3, bn=False)\n#     pool1 = AveragePooling2D(pool_size=(2, 2))(conv1)\n\n#     conv2 = encoder_layer(pool1, 64, 3, bn=True)\n#     pool2 = AveragePooling2D(pool_size=(2, 2))(conv2)\n\n#     conv3 = encoder_layer(pool2, 128, 3, bn=True)\n#     pool3 = AveragePooling2D(pool_size=(2, 2))(conv3)\n\n# #         conv4 = encoder_layer(pool3, 256, 3, bn=True)\n# #         pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n\n#     conv5 = decoder_layer(pool3, 256, 3, bn=True)\n#     merge1 = Concatenate()([conv3,conv5])\n\n#     conv6 = decoder_layer(merge1, 128, 3, bn=True)\n#     merge2 = Concatenate()([conv2,conv6])\n\n#     conv7 = decoder_layer(merge2, 64, 3, bn=True)\n#     merge3 = Concatenate()([conv1,conv7])\n\n# #         conv8 = decoder_layer(merge3, 32, 3, bn=True)\n# #         merge4 = Concatenate()([conv1,conv8])\n\n#     conv9 = encoder_layer(merge3, 32, 3, bn=False)\n    \n#     model_output = Conv2D(1, (1, 1), \n#            use_bias=False, padding=\"same\",activation=\"linear\",\n#            strides=1,kernel_initializer='glorot_uniform',\n#            name='block9_conv3')(conv9)\n\n#     # Setup the model inputs / outputs\n#     model = Model(inputs=input_matrix, outputs=model_output)\n\n#     # Compile the model\n#     model.compile(optimizer = Adam(lr=learn_rate), loss='mse')\n\n#     return model","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"size = (3, 3)\ng_filters_base = 32\nDropoutRatio = 0.5\nlearn_rate_g = 0.001\nlearn_rate_d = 0.001\nlearn_rate_c = 0.001\n\n# channels = 3\nmatrix_shape = (matrix_length, matrix_length, channel_num)\ntrue_volume_shape = (matrix_length, matrix_length, 1)\nhistory_volume_shape = (matrix_length, matrix_length, channel_num-1)\n\nkernel_init = 'glorot_uniform'\nbias_init = 'zeros'\nkernel_regul = regularizers.l2(1)\nactivity_regul = regularizers.l2(1)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ResNet block\ndef identity_block(X, filters, f):\n\n    F1, F2 = filters\n\n    X_shortcut = X\n\n    X = BatchNormalization(axis=3)(X)\n    X = Activation('relu')(X)\n    X = Conv2D(filters=F1, kernel_size=(f, f), strides=(1, 1), padding='same',\n               kernel_initializer=kernel_init, bias_initializer=bias_init,\n              kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(X)\n\n    X = BatchNormalization(axis=3)(X)\n    X = Activation('relu')(X)\n    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same',\n               kernel_initializer=kernel_init, bias_initializer=bias_init,\n              kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(X)\n\n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n\n    return X\n\n# ENCODER\ndef encoder_layer(img_in, filters, kernel_size, bn=True, resid=True):\n    # conv = Conv2D(filters=filters, kernel_size=kernel_size, strides=(1, 1), padding='same')(img_in)\n    conv = img_in\n    if bn:\n        conv = BatchNormalization()(conv)\n    conv = Activation('relu')(conv)\n#             conv = MaxPooling2D((2, 2))(conv)\n\n\n    if resid:\n        conv = identity_block(conv, (filters, filters), kernel_size)\n\n    return conv\n\n# DECODER\ndef decoder_layer(img_in, e_conv, filters, kernel_size, bn=True, resid=True):\n    # up_img = UpSampling2D(size=(2,2))(img_in)\n    up_img = img_in\n    concat_img = Concatenate(axis=3)([e_conv,up_img])\n    conv = Conv2D(filters=filters, kernel_size=kernel_size, strides=(1, 1), padding='same',\n                  kernel_initializer=kernel_init, bias_initializer=bias_init,\n              kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(concat_img)\n    if bn:\n        conv = BatchNormalization()(conv)\n    conv = LeakyReLU(alpha=0)(conv)\n\n    if resid:\n        conv = identity_block(conv, (filters, filters), kernel_size)\n    return conv\n\n\n\ndef build_generator():      \n\n    # INPUTS\n    history_traffic_volume = Input(shape=history_volume_shape)\n\n    # kernel_init = initializers.he_normal()\n    # bias_init = initializers.he_normal()\n    kernel_init = 'glorot_uniform'\n    bias_init = 'zeros'\n\n#         kernel_init = initializers.he_uniform()\n#         bias_init = 'Orthogonal'\n    kernel_regul = regularizers.l2(1)\n    activity_regul = regularizers.l2(1)\n\n    filters_base = 32\n    e_conv1_head = Conv2D(filters=filters_base, kernel_size=3, strides=1, padding='same',\n                          kernel_initializer=kernel_init, bias_initializer=bias_init,\n                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(history_traffic_volume)\n#         e_conv1_head = Conv2D(filters=filters_base*1, kernel_size=3, strides=1, padding='same',\n#                               kernel_initializer=kernel_init, bias_initializer=bias_init,\n#                       kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(e_conv1_head)\n    e_conv1_tail = AveragePooling2D((2, 2))(e_conv1_head)\n    e_conv1 = encoder_layer(e_conv1_tail, filters_base, 3, bn=False)\n\n    e_conv2_head = Conv2D(filters=filters_base*2, kernel_size=3, strides=1, padding='same',\n                          kernel_initializer=kernel_init, bias_initializer=bias_init,\n                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(e_conv1)\n    e_conv2_tail = AveragePooling2D((2, 2))(e_conv2_head)\n    e_conv2 = encoder_layer(e_conv2_tail, filters_base*2, 3)\n\n    e_conv3_head = Conv2D(filters=filters_base*4, kernel_size=3, strides=1, padding='same',\n                          kernel_initializer=kernel_init, bias_initializer=bias_init,\n                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(e_conv2)\n    e_conv3_tail = AveragePooling2D((2, 2))(e_conv3_head)\n    d_conv3_head = encoder_layer(e_conv3_tail, filters_base*4, 3)\n    resid1 = Subtract()([e_conv3_tail, d_conv3_head])\n    d_conv3_tail = UpSampling2D(size=(2, 2))(resid1)\n\n\n    d_conv4_head = decoder_layer(d_conv3_tail, e_conv3_head, filters_base*2, 3)\n    resid2 = Subtract()([d_conv4_head, e_conv2_tail])\n    d_conv4_tail = UpSampling2D(size=(2, 2))(resid2)\n\n\n    d_conv5_head = decoder_layer(d_conv4_tail, e_conv2_head, filters_base*1, 3)\n    resid3 = Subtract()([d_conv5_head, e_conv1_tail])\n    d_conv5_tail = UpSampling2D(size=(2, 2))(resid3)\n\n    d_conv6_head = decoder_layer(d_conv5_tail, e_conv1_head, filters_base//2, 3, bn=False)\n\n\n    outputs = Conv2D(1, 1, activation = 'relu', kernel_initializer=kernel_init, bias_initializer=bias_init,\n                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(d_conv6_head)\n\n    # Setup the model inputs / outputs\n    model = Model(inputs=history_traffic_volume, outputs=outputs)\n\n    # Compile the model\n    model.compile(\n        optimizer = Adam(lr=learn_rate_g),\n        loss='mse'\n    )\n\n    return model","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d_filters_base = 32\n# Input shape\n\n# Discriminator\ndef build_discriminator():\n    def d_layer(layer_input, filters, f_size=3, bn=True, stride=1):\n        \"\"\"Discriminator layer\"\"\"\n        d = Conv2D(filters, kernel_size=f_size, strides=stride, padding='same', kernel_initializer=kernel_init, bias_initializer=bias_init,\n                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(layer_input)\n        if bn:\n            d = BatchNormalization()(d)\n        d = LeakyReLU(alpha=0.1)(d)\n        return d\n    \n    matrix_A = Input(shape=true_volume_shape)\n    matrix_B = Input(shape=history_volume_shape)\n\n    # Concatenate image and conditioning image生成输入对象\n    combined_matrix = Concatenate(axis=-1)([matrix_A, matrix_B])\n\n    d1 = d_layer(combined_matrix, d_filters_base, bn=False)\n    d2 = d_layer(d1, d_filters_base*2, stride=2)\n#     d2 = AveragePooling2D((2, 2))(d2)\n    d3 = d_layer(d2, d_filters_base*4, stride=2)\n#     d3 = AveragePooling2D((2, 2))(d3)\n    d4 = d_layer(d3, d_filters_base*8, stride=2)\n#     d4 = AveragePooling2D((2, 2))(d4)\n    d4 = d_layer(d4, d_filters_base*4)\n    d5 = d_layer(d4, d_filters_base*2)\n    d6 = d_layer(d5, d_filters_base*1)\n    \n    validity = Conv2D(1, kernel_size=3, strides=1, padding='same')(d6)\n\n    model = Model([matrix_A, matrix_B], validity)\n    model.compile(loss='mse', optimizer=Adam(lr=learn_rate_d), metrics=['mse'])\n    return model","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 计算D输出valid大小（PatchGAN）\npatch = 4\ndisc_patch = (patch, patch, 1)\n\n# Number of filters in the first layer of G and D\ngf = 64\ndf = 64\n\noptimizer = Adam(lr=learn_rate_c)\n\n# Build and compile the discriminator\ndiscriminator = build_discriminator()\n\n# Build the generator\ngenerator = build_generator()\n\n# Input images and their conditioning images\ntrue_volume = Input(shape=true_volume_shape)\nhistory_volume = Input(shape=history_volume_shape)\n\n# By conditioning on B generate a fake version of A\nforecast_volume = generator(history_volume)\n\n# For the combined model we will only train the generator\ndiscriminator.trainable = False\n\n# Discriminators determines validity of translated images / condition pairs\nvalid_gan = discriminator([forecast_volume, history_volume])\n\ncombined = Model(inputs=[true_volume, history_volume], outputs=[valid_gan, forecast_volume])\ncombined.compile(loss=['mse', 'mse'], optimizer=optimizer)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_step = []\nl2_validation = []\n\ndef train(train_matrix, epochs, batch_size=MAX_BATCH_SIZE, learn_rate=0.01):\n\n    start_time = datetime.datetime.now()\n    print(\"train start \"+str(start_time))\n\n    # Adversarial loss ground truths\n#     valid = np.ones((MAX_BATCH_SIZE,) + disc_patch)+np.random.rand(MAX_BATCH_SIZE, patch, patch, 1)/5\n#     fake = np.zeros((MAX_BATCH_SIZE,) + disc_patch)+np.random.rand(MAX_BATCH_SIZE, patch, patch, 1)/5\n    valid = np.ones((MAX_BATCH_SIZE,) + disc_patch)\n    fake = np.zeros((MAX_BATCH_SIZE,) + disc_patch)\n\n    for epoch in range(epochs):\n        if epoch>9 and epoch % 2 == 0 and epoch != 0:\n            if learn_rate>0.001:\n                if epoch%3==0:\n                    learn_rate = 0.9*learn_rate\n                else:\n                    learn_rate = 0.9*learn_rate\n                K.set_value(generator.optimizer.lr, learn_rate)\n                K.set_value(discriminator.optimizer.lr, learn_rate)\n\n        for batch_i, (true_volume, history_volume) in enumerate(load_data(train_matrix,batch_size)):\n            # true_volume 真实待预测路网交通量  history_volume 路网交通量历史数据\n            #  训练 Discriminator\n\n            # 根据历史数据生成预测数据\n            forecast_volume = generator.predict(history_volume)\n\n            # 训练 the discriminators (original images = real / generated = Fake)\n            discriminator.trainable = True\n            d_loss_real = discriminator.train_on_batch([true_volume, history_volume], valid)\n            d_loss_fake = discriminator.train_on_batch([forecast_volume, history_volume], fake)\n            discriminator.trainable = False\n            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n\n\n            #  训练 Generator\n            g_loss = combined.train_on_batch([true_volume, history_volume], [valid, true_volume])\n\n            elapsed_time = datetime.datetime.now() - start_time\n\n        # Plot the progress\n        y_pred = generator.predict(X_test[:, :, :, 1:])\n        y_true = X_test[:, :, :, :1]\n\n        l2_epoch_validation = l2(y_true, y_pred)\n        lr_step.append(K.get_value(discriminator.optimizer.lr))\n        l2_validation.append(l2_epoch_validation)\n        if epoch%1==0:\n#             print(\"discriminator lr:\"+ str(K.get_value(discriminator.optimizer.lr)))\n            print (\"[Epoch %d/%d]  [D loss: %f, mse: %f] [G loss: %f] time: %s\" % (epoch+1, epochs,\n                                                                    d_loss[0], l2_epoch_validation,\n                                                                    g_loss[0],\n                                                                    elapsed_time))\n        # If at show interval => show generated image samples\n#             if epoch % show_interval == 0:\n#                     show_images(dataset_name,epoch, batch_i)","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train(X_train, epochs=50, batch_size=MAX_BATCH_SIZE, learn_rate=learn_rate_c)","execution_count":null,"outputs":[{"output_type":"stream","text":"train start 2019-10-18 06:16:15.904114\n[Epoch 1/50]  [D loss: 0.324831, mse: 52.668378] [G loss: 2146.386963] time: 0:00:40.477671\n[Epoch 2/50]  [D loss: 0.594125, mse: 27.318270] [G loss: 1092.804810] time: 0:01:04.844606\n[Epoch 3/50]  [D loss: 0.331617, mse: 26.202221] [G loss: 970.848145] time: 0:01:29.132854\n[Epoch 4/50]  [D loss: 0.473915, mse: 29.336246] [G loss: 834.681641] time: 0:01:53.097983\n[Epoch 5/50]  [D loss: 0.435174, mse: 27.064365] [G loss: 806.924255] time: 0:02:17.236074\n[Epoch 6/50]  [D loss: 0.303389, mse: 24.687080] [G loss: 749.700684] time: 0:02:41.274151\n[Epoch 7/50]  [D loss: 0.342476, mse: 24.143380] [G loss: 715.082458] time: 0:03:05.173190\n[Epoch 8/50]  [D loss: 0.591660, mse: 23.719183] [G loss: 719.846558] time: 0:03:29.319154\n[Epoch 9/50]  [D loss: 0.273295, mse: 23.340588] [G loss: 691.741333] time: 0:03:54.003508\n[Epoch 10/50]  [D loss: 0.291517, mse: 23.795860] [G loss: 766.389282] time: 0:04:18.034060\n[Epoch 11/50]  [D loss: 0.406804, mse: 22.541907] [G loss: 716.105652] time: 0:04:42.367686\n[Epoch 12/50]  [D loss: 0.348718, mse: 21.898039] [G loss: 694.967346] time: 0:05:06.488423\n[Epoch 13/50]  [D loss: 0.274554, mse: 22.286155] [G loss: 829.443298] time: 0:05:30.524475\n[Epoch 14/50]  [D loss: 0.375781, mse: 21.739569] [G loss: 767.221497] time: 0:05:54.424475\n[Epoch 15/50]  [D loss: 0.280715, mse: 21.717367] [G loss: 693.090210] time: 0:06:18.649987\n[Epoch 16/50]  [D loss: 0.265806, mse: 21.811448] [G loss: 695.083069] time: 0:06:42.560854\n[Epoch 17/50]  [D loss: 0.303681, mse: 22.738350] [G loss: 667.014526] time: 0:07:06.379554\n[Epoch 18/50]  [D loss: 0.316935, mse: 22.751260] [G loss: 708.250549] time: 0:07:30.435349\n[Epoch 19/50]  [D loss: 0.272741, mse: 24.101540] [G loss: 601.916809] time: 0:07:54.408687\n[Epoch 20/50]  [D loss: 0.250546, mse: 22.350722] [G loss: 764.016968] time: 0:08:18.402254\n[Epoch 21/50]  [D loss: 0.250538, mse: 22.600202] [G loss: 758.921753] time: 0:08:42.999278\n[Epoch 22/50]  [D loss: 0.250817, mse: 22.516098] [G loss: 743.372070] time: 0:09:07.180934\n[Epoch 23/50]  [D loss: 0.251037, mse: 22.520626] [G loss: 818.376404] time: 0:09:31.173181\n[Epoch 24/50]  [D loss: 0.250979, mse: 22.013715] [G loss: 748.412659] time: 0:09:55.275391\n[Epoch 25/50]  [D loss: 0.250978, mse: 23.483256] [G loss: 748.726196] time: 0:10:19.275012\n[Epoch 26/50]  [D loss: 0.250908, mse: 24.803854] [G loss: 693.790588] time: 0:10:43.196703\n[Epoch 27/50]  [D loss: 0.250744, mse: 21.845581] [G loss: 790.820190] time: 0:11:07.018002\n[Epoch 28/50]  [D loss: 0.251179, mse: 22.427425] [G loss: 907.911316] time: 0:11:31.149829\n[Epoch 29/50]  [D loss: 0.250992, mse: 22.074325] [G loss: 849.696472] time: 0:11:55.079175\n[Epoch 30/50]  [D loss: 0.250942, mse: 22.223305] [G loss: 844.721497] time: 0:12:18.967246\n[Epoch 31/50]  [D loss: 0.251001, mse: 22.636220] [G loss: 791.876831] time: 0:12:43.440479\n[Epoch 32/50]  [D loss: 0.477607, mse: 23.788499] [G loss: 827.965027] time: 0:13:07.397177\n[Epoch 33/50]  [D loss: 0.250356, mse: 23.478677] [G loss: 974.742920] time: 0:13:31.203851\n[Epoch 34/50]  [D loss: 0.250364, mse: 23.863932] [G loss: 854.910156] time: 0:13:55.649131\n[Epoch 35/50]  [D loss: 0.250381, mse: 23.670664] [G loss: 735.622803] time: 0:14:19.628375\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# generator.save_weights('/kaggle/working/generatorModel.h5')\n# generator.load_weights('/kaggle/working/generatorModel.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = generator.predict(X_test[:, :, :, 1:])\ny_true = X_test[:, :, :, :1]\n\nl2(y_true, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib as mpl\nimport matplotlib.pyplot as plt\n\ny = y_true.reshape(-1,)[1600:1700]\nx = np.linspace(0, len(y), len(y))\n\nyi = y_pred.reshape(-1,)[1600:1700]\nxi = np.linspace(0, len(yi), len(yi))\nfig, ax = plt.subplots(figsize=(25, 6))\n# ax.plot(x, y, '.', linewidth=1, markersize=10)\nlines = plt.plot(xi, yi, 'k^--', x, y, 'ro-',linewidth=1, markersize=6)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_step","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yi = l2_validation\nxi = np.linspace(0, len(yi), len(yi))\n\ny = [i*10000 for i in lr_step]\nx = np.linspace(0, len(y), len(y))\n\nfig, ax = plt.subplots(figsize=(6, 6))\nlines = plt.plot(x, y, 'ko-', xi, yi, 'k^--', linewidth=1, markersize=6)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = lr_step\nx = np.linspace(0, len(y), len(y))\n# fig, ax = plt.subplots(figsize=(6, 6))\n# lines = plt.plot(x, y, 'ko-', linewidth=1, markersize=6)\nlr_step","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = y_true.reshape(-1,)[3600:3700]\nx = np.linspace(0, len(y), len(y))\n\nyi = y_pred.reshape(-1,)[3600:3700]\nxi = np.linspace(0, len(yi), len(yi))\nfig, ax = plt.subplots(figsize=(25, 6))\nax.plot(x, y, '.', linewidth=1, markersize=10)\nlines = plt.plot(xi, yi, 'k^--', x, y, 'ro-',linewidth=1, markersize=6)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start_time = 0\ny = y_true.reshape(-1,)[start_time: start_time+100]\nx = np.linspace(0, len(y), len(y))\n\nyi = y_pred.reshape(-1,)[start_time: start_time+100]\nxi = np.linspace(0, len(yi), len(yi))\nfig, ax = plt.subplots(figsize=(25, 6))\n# ax.plot(x, y, '.', linewidth=1, markersize=10)\nlines = plt.plot(xi, yi, 'k^--', x, y, 'ro-',linewidth=1, markersize=6)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_true","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}