{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import scipy\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import transform\n",
    "\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, concatenate, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D, Add, Subtract\n",
    "from keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D ,AveragePooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU, ELU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam, Nadam, RMSprop\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.merge import _Merge\n",
    "from keras.engine.topology import Layer\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "import gc\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, TensorBoard\n",
    "from keras import backend as K\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from keras.models import load_model  \n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载  预处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交通矩阵为 matrix_length*matrix_length\n",
    "matrix_length = 32\n",
    "\n",
    "matrix_df = pd.read_csv('./data/trafficV_M.csv', index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTrainArray(week_history_num=0, minute_history_num=0):\n",
    "    week_delta_list = [pd.Timedelta(i+1, unit='W') for i in range(week_history_num)]\n",
    "    minute_delta_list = [pd.Timedelta((i+1)*15, unit='m') for i in range(minute_history_num)]\n",
    "    # 参考历史数据时间点list\n",
    "    delta_list = week_delta_list+minute_delta_list\n",
    "    print(delta_list)\n",
    "    \n",
    "    set_up_time = pd.Timedelta(week_history_num, unit='W')\n",
    "    # 根据历史数据选取多少，重新构建数据集\n",
    "    # 相当于去除最开始week_history_num个周的数据，因为这些数据无法找到更前的数据\n",
    "    train_df = matrix_df.truncate(before=matrix_df.index.min() + set_up_time)\n",
    "    \n",
    "    train_ago_array_tuple = tuple([np.array(matrix_df.loc[train_df.index - i]).reshape(-1, matrix_length, matrix_length, 1) for i in delta_list])\n",
    "    train_df = np.array(train_df).reshape(-1, matrix_length, matrix_length, 1)\n",
    "    # concatenate保持 待修复数据在前，参考历史数据在后。与random_mask函数生成mask相一致\n",
    "    train_array = np.concatenate((train_df,)+train_ago_array_tuple, axis=3)\n",
    "    print(train_array.shape)\n",
    "    return train_array\n",
    "\n",
    "\n",
    "\n",
    "# def createTrainArray(week_history_num=0, minute_history_num=0):\n",
    "#     week_delta_list = [pd.Timedelta(week_history_num-i, unit='W') for i in range(week_history_num)]\n",
    "#     minute_delta_list = [pd.Timedelta((minute_history_num-i)*15, unit='m') for i in range(minute_history_num)]\n",
    "#     # 参考历史数据时间点list\n",
    "#     delta_list = minute_delta_list+week_delta_list\n",
    "#     print(delta_list)\n",
    "    \n",
    "#     set_up_time = pd.Timedelta(week_history_num, unit='W')\n",
    "#     # 根据历史数据选取多少，重新构建数据集\n",
    "#     # 相当于去除最开始week_history_num个周的数据，因为这些数据无法找到更前的数据\n",
    "#     train_df = matrix_df.truncate(before=matrix_df.index.min() + set_up_time)\n",
    "    \n",
    "#     train_ago_array_tuple = tuple([np.array(matrix_df.loc[train_df.index - i]).reshape(-1, matrix_length, matrix_length, 1) for i in delta_list])\n",
    "#     train_df = np.array(train_df).reshape(-1, matrix_length, matrix_length, 1)\n",
    "#     # concatenate保持 待修复数据在前，参考历史数据在后。与random_mask函数生成mask相一致\n",
    "#     train_array = np.concatenate((train_df,)+train_ago_array_tuple, axis=3)\n",
    "#     print(train_array.shape)\n",
    "#     return train_array\n",
    "\n",
    "\n",
    "def normalization(matrix):\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(matrix.shape[-1]):\n",
    "            cur_time = matrix[i][:, :, j]\n",
    "#             mean_val = cur_time.mean()\n",
    "            mx = cur_time.max()\n",
    "            mn = cur_time.min()\n",
    "            matrix[i][:, :, j] = np.divide((cur_time-mn), (mx-mn))\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Timedelta('7 days 00:00:00'), Timedelta('14 days 00:00:00'), Timedelta('0 days 00:15:00'), Timedelta('0 days 00:30:00'), Timedelta('0 days 00:45:00')]\n",
      "(16032, 32, 32, 6)\n"
     ]
    }
   ],
   "source": [
    "week_history_num = 2\n",
    "minute_history_num = 3\n",
    "\n",
    "channel_num = week_history_num +minute_history_num +1\n",
    "smooth_time = channel_num-1\n",
    "\n",
    "# train_array为(16704, 32, 32, 3)，16704个矩阵，32*32采集点，3从上到下为当前时间，上一周，上一15min\n",
    "train_array = createTrainArray(week_history_num, minute_history_num)\n",
    "X_train, X_test = train_test_split(train_array, test_size = 0.1, random_state=42, shuffle=False)\n",
    "# X_train, X_val = train_test_split(train_array, test_size = 0.1, random_state=42, shuffle=False) # 不shuffle可用于查看数据正确性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14428, 32, 32, 6), (1604, 32, 32, 6))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225, 25)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_BATCH_SIZE = 64\n",
    "epoch_steps = X_train.shape[0] // MAX_BATCH_SIZE\n",
    "test_steps = X_test.shape[0] // MAX_BATCH_SIZE\n",
    "epoch_steps, test_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "def load_data(volume_matrix, batch_size=MAX_BATCH_SIZE):\n",
    "    n_batches=batch_size\n",
    "    len_of_matrix = len(volume_matrix)\n",
    "\n",
    "    batch_i = 0\n",
    "    while ((batch_i+1)*batch_size < len_of_matrix):\n",
    "        batch_matrix = volume_matrix[batch_i*batch_size: (batch_i+1)*batch_size]\n",
    "        true_volume, history_volume = batch_matrix[:, :, :, :1], batch_matrix[:, :, :, 1:]\n",
    "#         history_volume = normalization(history_volume)\n",
    "        batch_i+=1\n",
    "\n",
    "        yield true_volume, history_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def l2(y_true, y_pred):\n",
    "    return math.sqrt(np.sum(np.mean(np.square(y_true - y_pred), axis=0))/1024)\n",
    "\n",
    "def l1(y_true, y_pred):\n",
    "    return np.sum(np.mean(np.abs(y_true - y_pred), axis=0))/(matrix_length*matrix_length)\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    return np.sum(np.mean((np.abs(y_true - y_pred)/y_true)*100, axis=0))/(matrix_length*matrix_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算D输出valid大小（PatchGAN）\n",
    "patch = 4\n",
    "disc_patch = (patch, patch, 1)\n",
    "\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "def wgan_gp_distance(y_true, y_pred):\n",
    "    # WGAN-GP代码注释\n",
    "#     eps = K.random_uniform([MAX_BATCH_SIZE, 1], minval=0., maxval=1.) #eps是U[0,1]的随机数\n",
    "#     X_inter = eps*y_true + (1. - eps)*y_pred  #在真实样本和生成样本之间随机插值，希望这个约束可以“布满”真实样本和生成样本之间的空间\n",
    "#     grad = K.gradients(D(X_inter), [X_inter])[0] #求梯度\n",
    "#     grad_norm = K.sqrt(K.reduce_sum((grad)**2, axis=1)) #求梯度的二范数\n",
    "#     grad_pen = 0 #10 * K.reduce_mean(K.nn.relu(grad_norm - 1.)) #Lipschitz限制是要求判别器的梯度不超过K，这个loss项是希望判别器的梯度离K（此处K设为1）越近越好\n",
    "\n",
    "#     #判别器损失函数\n",
    "#     D_loss = K.reduce_mean(y_true) - K.reduce_mean(y_pred) + grad_pen\n",
    "    return K.mean(y_true * y_pred)\n",
    "#     return wasserstein_distance(K.eval(K.reshape(K.mean(y_true, axis=0), [1,-1])).tolist(), K.eval(K.reshape(K.mean(y_pred, axis=0), [1,-1])).tolist())\n",
    "#     return wasserstein_distance(K.mean(y_true, axis=0).reshape(patch*patch).tolist(), K.mean(y_pred, axis=0).reshape(patch*patch).tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (3, 3)\n",
    "g_filters_base = 32\n",
    "DropoutRatio = 0\n",
    "learn_rate_g = 0.0002\n",
    "learn_rate_d = 0.0008\n",
    "learn_rate_c = 0.0002\n",
    "\n",
    "# channels = 3\n",
    "matrix_shape = (matrix_length, matrix_length, channel_num)\n",
    "true_volume_shape = (matrix_length, matrix_length, 1)\n",
    "history_volume_shape = (matrix_length, matrix_length, channel_num-1)\n",
    "\n",
    "kernel_init = 'glorot_uniform'\n",
    "bias_init = 'zeros'\n",
    "kernel_regul = regularizers.l2(1)\n",
    "activity_regul = regularizers.l2(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet block\n",
    "def identity_block(X, filters, f):\n",
    "\n",
    "    F1, F2 = filters\n",
    "\n",
    "    X_shortcut = X\n",
    "\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(filters=F1, kernel_size=(f, f), strides=(1, 1), padding='same',\n",
    "               kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "              kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(X)\n",
    "\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same',\n",
    "               kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "              kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(X)\n",
    "\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X\n",
    "\n",
    "# ENCODER\n",
    "def encoder_layer(img_in, filters, kernel_size, bn=True, resid=True):\n",
    "    # conv = Conv2D(filters=filters, kernel_size=kernel_size, strides=(1, 1), padding='same')(img_in)\n",
    "    conv = img_in\n",
    "    if bn:\n",
    "        conv = BatchNormalization()(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "#             conv = MaxPooling2D((2, 2))(conv)\n",
    "\n",
    "\n",
    "    if resid:\n",
    "        conv = identity_block(conv, (filters, filters), kernel_size)\n",
    "\n",
    "    return conv\n",
    "\n",
    "# DECODER\n",
    "def decoder_layer(img_in, e_conv, filters, kernel_size, bn=True, resid=True):\n",
    "    # up_img = UpSampling2D(size=(2,2))(img_in)\n",
    "    up_img = img_in\n",
    "    concat_img = Concatenate(axis=3)([e_conv,up_img])\n",
    "    conv = Conv2D(filters=filters, kernel_size=kernel_size, strides=(1, 1), padding='same',\n",
    "                  kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "              kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(concat_img)\n",
    "    if bn:\n",
    "        conv = BatchNormalization()(conv)\n",
    "    conv = LeakyReLU(alpha=0)(conv)\n",
    "\n",
    "    if resid:\n",
    "        conv = identity_block(conv, (filters, filters), kernel_size)\n",
    "    return conv\n",
    "\n",
    "\n",
    "\n",
    "def build_generator():      \n",
    "\n",
    "    # INPUTS\n",
    "    history_traffic_volume = Input(shape=history_volume_shape)\n",
    "\n",
    "    # kernel_init = initializers.he_normal()\n",
    "    # bias_init = initializers.he_normal()\n",
    "    kernel_init = 'glorot_uniform'\n",
    "    bias_init = 'zeros'\n",
    "\n",
    "#         kernel_init = initializers.he_uniform()\n",
    "#         bias_init = 'Orthogonal'\n",
    "    kernel_regul = regularizers.l2(1)\n",
    "    activity_regul = regularizers.l2(1)\n",
    "\n",
    "    filters_base = 32\n",
    "    e_conv1_head = Conv2D(filters=filters_base, kernel_size=3, strides=1, padding='same',\n",
    "                          kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(history_traffic_volume)\n",
    "#         e_conv1_head = Conv2D(filters=filters_base*1, kernel_size=3, strides=1, padding='same',\n",
    "#                               kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "#                       kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(e_conv1_head)\n",
    "    e_conv1_tail = AveragePooling2D((2, 2))(e_conv1_head)\n",
    "#     e_conv1_tail = Dropout(DropoutRatio/2)(e_conv1_tail)\n",
    "    e_conv1 = encoder_layer(e_conv1_tail, filters_base, 3, bn=False)\n",
    "\n",
    "    e_conv2_head = Conv2D(filters=filters_base*2, kernel_size=3, strides=1, padding='same',\n",
    "                          kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(e_conv1)\n",
    "    e_conv2_tail = AveragePooling2D((2, 2))(e_conv2_head)\n",
    "#     e_conv2_tail = Dropout(DropoutRatio)(e_conv2_tail)\n",
    "    e_conv2 = encoder_layer(e_conv2_tail, filters_base*2, 3)\n",
    "\n",
    "    e_conv3_head = Conv2D(filters=filters_base*4, kernel_size=3, strides=1, padding='same',\n",
    "                          kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(e_conv2)\n",
    "    e_conv3_tail = AveragePooling2D((2, 2))(e_conv3_head)\n",
    "    \n",
    "    # 加drop引入噪声\n",
    "#     e_conv3_tail = Dropout(DropoutRatio)(e_conv3_tail)\n",
    "    \n",
    "    d_conv3_head = encoder_layer(e_conv3_tail, filters_base*4, 3)\n",
    "    resid1 = Subtract()([e_conv3_tail, d_conv3_head])\n",
    "    d_conv3_tail = UpSampling2D(size=(2, 2))(resid1)\n",
    "#     d_conv3_tail = Dropout(DropoutRatio)(d_conv3_tail)\n",
    "\n",
    "\n",
    "    d_conv4_head = decoder_layer(d_conv3_tail, e_conv3_head, filters_base*2, 3)\n",
    "    resid2 = Subtract()([d_conv4_head, e_conv2_tail])\n",
    "    d_conv4_tail = UpSampling2D(size=(2, 2))(resid2)\n",
    "#     d_conv4_tail = Dropout(DropoutRatio)(d_conv4_tail)\n",
    "\n",
    "\n",
    "    d_conv5_head = decoder_layer(d_conv4_tail, e_conv2_head, filters_base*1, 3)\n",
    "    resid3 = Subtract()([d_conv5_head, e_conv1_tail])\n",
    "    d_conv5_tail = UpSampling2D(size=(2, 2))(resid3)\n",
    "#     d_conv5_tail = Dropout(DropoutRatio)(d_conv5_tail)\n",
    "\n",
    "    d_conv6_head = decoder_layer(d_conv5_tail, e_conv1_head, filters_base//2, 3, bn=False)\n",
    "\n",
    "\n",
    "    outputs = Conv2D(1, 1, activation = 'relu', kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(d_conv6_head)\n",
    "\n",
    "    # Setup the model inputs / outputs\n",
    "    model = Model(inputs=history_traffic_volume, outputs=outputs)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer = Adam(lr=learn_rate_g),\n",
    "        loss='mse'\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty_loss(y_true, y_pred, averaged_samples):\n",
    "    \"\"\"\n",
    "    Computes gradient penalty based on prediction and weighted real / fake samples\n",
    "    \"\"\"\n",
    "    gradients = K.gradients(y_pred, averaged_samples)[0]\n",
    "    # compute the euclidean norm by squaring ...\n",
    "    gradients_sqr = K.square(gradients)\n",
    "    #   ... summing over the rows ...\n",
    "    gradients_sqr_sum = K.sum(gradients_sqr,\n",
    "                              axis=np.arange(1, len(gradients_sqr.shape)))\n",
    "    #   ... and sqrt\n",
    "    gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
    "    # compute lambda * (1 - ||grad||)^2 still for each single sample\n",
    "    gradient_penalty = K.square(1 - gradient_l2_norm)\n",
    "    # return the mean as loss over all the batch samples\n",
    "    return K.mean(gradient_penalty)\n",
    "\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)\n",
    "\n",
    "def neg_wasserstein_loss(y_true, y_pred):\n",
    "    return -K.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_filters_base = 32\n",
    "# Input shape\n",
    "\n",
    "# Discriminator\n",
    "def build_discriminator():\n",
    "    def d_layer(layer_input, filters, f_size=3, bn=True, stride=1):\n",
    "        \"\"\"Discriminator layer\"\"\"\n",
    "        d = Conv2D(filters, kernel_size=f_size, strides=stride, padding='same', kernel_initializer=kernel_init, bias_initializer=bias_init,\n",
    "                  kernel_regularizer=kernel_regul, bias_regularizer=activity_regul)(layer_input)\n",
    "        if bn:\n",
    "            d = BatchNormalization()(d)\n",
    "        d = LeakyReLU(alpha=0.1)(d)\n",
    "        return d\n",
    "    \n",
    "    matrix_A = Input(shape=true_volume_shape)\n",
    "    matrix_B = Input(shape=history_volume_shape)\n",
    "\n",
    "    # Concatenate image and conditioning image生成输入对象\n",
    "    combined_matrix = Concatenate(axis=-1)([matrix_A, matrix_B])\n",
    "\n",
    "    d1 = d_layer(combined_matrix, d_filters_base, bn=False)\n",
    "    d2 = d_layer(d1, d_filters_base*2, stride=2)\n",
    "#     d2 = AveragePooling2D((2, 2))(d2)\n",
    "    d3 = d_layer(d2, d_filters_base*4, stride=2)\n",
    "#     d3 = AveragePooling2D((2, 2))(d3)\n",
    "    d4 = d_layer(d3, d_filters_base*8, stride=2)\n",
    "#     d4 = AveragePooling2D((2, 2))(d4)\n",
    "    d4 = d_layer(d4, d_filters_base*4)\n",
    "    d5 = d_layer(d4, d_filters_base*2)\n",
    "    d6 = d_layer(d5, d_filters_base*1)\n",
    "    \n",
    "    validity = Conv2D(1, kernel_size=3, strides=1, padding='same')(d6)\n",
    "    model = Model([matrix_A, matrix_B], validity)\n",
    "    model.compile(optimizer=Adam(lr=learn_rate_d), loss=wasserstein_loss, metrics=['mse'])   #binary_crossentropy\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomWeightedAverage(_Merge):\n",
    "    \"\"\"Provides a (random) weighted average between real and generated image samples\"\"\"\n",
    "    def _merge_function(self, inputs):\n",
    "        alpha = K.random_uniform((64, 1, 1, 1))\n",
    "        return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])\n",
    "    \n",
    "    \n",
    "class GradNorm(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(GradNorm, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(GradNorm, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        vaild_interpolated, interpolation_volume = inputs\n",
    "        grads = K.gradients(vaild_interpolated, interpolation_volume)\n",
    "        assert len(grads) == 1\n",
    "        grad = grads[0]\n",
    "#         a = K.sqrt(K.sum(K.batch_flatten(K.square(grad)), axis=1, keepdims=True))\n",
    "        return grad\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (MAX_BATCH_SIZE,) + true_volume_shape\n",
    "    \n",
    "    def compute_output_shape(self, input_shapes):\n",
    "        return (MAX_BATCH_SIZE,) + true_volume_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "discriminator = build_discriminator()\n",
    "generator = build_generator()\n",
    "\n",
    "\n",
    "true_volume = Input(shape=true_volume_shape)\n",
    "history_volume = Input(shape=history_volume_shape)\n",
    "interpolation_volume = Input(shape=true_volume_shape)\n",
    "\n",
    "forecast_volume = generator(history_volume)\n",
    "\n",
    "discriminator.trainable = False\n",
    "true_vaild = discriminator([true_volume, history_volume])\n",
    "fake_vaild = discriminator([forecast_volume, history_volume])\n",
    "\n",
    "# gp = gradient_penalty_loss(true_volume, forecast_volume, interpolation_volume)\n",
    "norm = GradNorm()([discriminator([interpolation_volume, history_volume]), interpolation_volume])\n",
    "\n",
    "combined = Model(inputs=[true_volume, history_volume, interpolation_volume],\n",
    "                    outputs=[true_vaild, fake_vaild, norm, forecast_volume])\n",
    "combined.compile(loss=[wasserstein_loss,\n",
    "                        neg_wasserstein_loss,\n",
    "                       'mse',\n",
    "                        'mse'],\n",
    "                        optimizer=RMSprop(lr=learn_rate_c),\n",
    "                        loss_weights=[1, 1, 10, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_step = []\n",
    "l2_validation = []\n",
    "\n",
    "def train(train_matrix, epochs, batch_size=MAX_BATCH_SIZE, learn_rate=0.01):\n",
    "\n",
    "    min_mse = 999\n",
    "    start_time = datetime.datetime.now()\n",
    "    print(\"train start \"+str(start_time))\n",
    "\n",
    "    # Adversarial loss ground truths\n",
    "#     valid = np.ones((MAX_BATCH_SIZE,) + disc_patch)+np.random.rand(MAX_BATCH_SIZE, patch, patch, 1)/5\n",
    "#     fake = np.zeros((MAX_BATCH_SIZE,) + disc_patch)+np.random.rand(MAX_BATCH_SIZE, patch, patch, 1)/5\n",
    "    valid = np.ones((MAX_BATCH_SIZE,) + disc_patch)\n",
    "    fake = -np.ones((MAX_BATCH_SIZE,) + disc_patch)\n",
    "    dummy = np.ones((MAX_BATCH_SIZE,) + true_volume_shape)\n",
    "\n",
    "    #　周期修改学习率　https://zhuanlan.zhihu.com/p/52084949\n",
    "    for epoch in range(epochs):\n",
    "        if epoch>=100 and epoch % 5 == 0 and epoch != 0:\n",
    "            generator_lr = K.get_value(generator.optimizer.lr)\n",
    "            discriminator_lr = K.get_value(discriminator.optimizer.lr)\n",
    "            combined_lr = K.get_value(combined.optimizer.lr)\n",
    "            if generator_lr>0.0001:\n",
    "                K.set_value(generator.optimizer.lr, generator_lr*0.9)\n",
    "            if discriminator_lr>0.0005:\n",
    "                K.set_value(discriminator.optimizer.lr, discriminator_lr*0.9)\n",
    "            if combined_lr>0.0001:\n",
    "                K.set_value(combined.optimizer.lr, combined_lr*0.9)\n",
    "\n",
    "        for batch_i, (true_volume, history_volume) in enumerate(load_data(train_matrix,batch_size)):\n",
    "            # true_volume 真实待预测路网交通量  history_volume 路网交通量历史数据\n",
    "            #  训练 Discriminator\n",
    "\n",
    "            # 根据历史数据生成预测数据\n",
    "            forecast_volume = generator.predict(history_volume)\n",
    "\n",
    "            # 训练 the discriminators (original images = real / generated = Fake)\n",
    "            discriminator.trainable = True\n",
    "            d_loss_real = discriminator.train_on_batch([true_volume, history_volume], valid)\n",
    "            d_loss_fake = discriminator.train_on_batch([forecast_volume, history_volume], fake)\n",
    "            discriminator.trainable = False\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            \n",
    "\n",
    "            epsilon = np.random.uniform(0, 1, size=(MAX_BATCH_SIZE,1,1,1))\n",
    "            interpolation_volume = epsilon*true_volume + (1-epsilon)*forecast_volume\n",
    "            #  训练 Generator\n",
    "            g_loss = combined.train_on_batch([true_volume, history_volume, interpolation_volume], [valid, fake, dummy, true_volume])\n",
    "\n",
    "            elapsed_time = datetime.datetime.now() - start_time\n",
    "\n",
    "        # Plot the progress\n",
    "        y_pred = generator.predict(X_test[:, :, :, 1:])\n",
    "        y_true = X_test[:, :, :, :1]\n",
    "\n",
    "        l2_epoch_validation = l2(y_true, y_pred)\n",
    "        l1_epoch_validation = l1(y_true, y_pred)\n",
    "        \n",
    "        y_pred[y_true==0] += 1\n",
    "        y_true[y_true==0] += 1\n",
    "        mape_epoch_validation = mape(y_true, y_pred)\n",
    "        \n",
    "#         lr_step.append(K.get_value(discriminator.optimizer.lr))\n",
    "        if(l2_epoch_validation<12 and l2_epoch_validation < min_mse):\n",
    "            generator.save_weights('./model/wganpg/tmp/min_generator_wganpg.h5')\n",
    "            discriminator.save_weights('./model/wganpg/tmp/min_discriminator_wganpg.h5')\n",
    "            combined.save_weights('./model/wganpg/tmp/min_combined_wganpg.h5')\n",
    "            min_mse = l2_epoch_validation\n",
    "            \n",
    "        l2_validation.append(l2_epoch_validation)\n",
    "        if epoch%1==0:\n",
    "#             print(\"unet lr:\"+ str(K.get_value(unet.optimizer.lr)))\n",
    "            print (\"[Epoch %d/%d]  [D loss: %f, mse: %f] [mae: %f] [mape: %f] [G loss: %f] time: %s\" % (epoch+1, epochs,\n",
    "                                                                    d_loss[0], l2_epoch_validation,\n",
    "                                                                    l1_epoch_validation,\n",
    "                                                                    mape_epoch_validation,\n",
    "                                                                    g_loss[0],\n",
    "                                                                    elapsed_time))\n",
    "        # If at show interval => show generated image samples\n",
    "#             if epoch % show_interval == 0:\n",
    "#                     show_images(dataset_name,epoch, batch_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train start 2019-11-22 13:28:45.020530\n",
      "[Epoch 1/200]  [D loss: 0.099829, mse: 75.412427] [mae: 53.754347] [mape: 22.552220] [G loss: 36755.367188] time: 0:01:07.694505\n",
      "[Epoch 2/200]  [D loss: 0.019736, mse: 68.711420] [mae: 50.301402] [mape: 20.923689] [G loss: 27236.039062] time: 0:01:53.921980\n",
      "[Epoch 3/200]  [D loss: 0.172512, mse: 53.694903] [mae: 38.772922] [mape: 16.664168] [G loss: 15834.010742] time: 0:02:39.838799\n",
      "[Epoch 4/200]  [D loss: 0.046796, mse: 48.093225] [mae: 34.632226] [mape: 14.946397] [G loss: 12845.815430] time: 0:03:27.274302\n",
      "[Epoch 5/200]  [D loss: 0.050257, mse: 45.790565] [mae: 32.901498] [mape: 14.033541] [G loss: 11406.830078] time: 0:04:13.232557\n",
      "[Epoch 6/200]  [D loss: 0.923958, mse: 42.318800] [mae: 30.252766] [mape: 12.883670] [G loss: 9857.814453] time: 0:04:59.278399\n",
      "[Epoch 7/200]  [D loss: 0.062655, mse: 41.764880] [mae: 29.924149] [mape: 12.519177] [G loss: 10031.925781] time: 0:05:45.260409\n",
      "[Epoch 8/200]  [D loss: 0.346549, mse: 38.147499] [mae: 27.032004] [mape: 11.313093] [G loss: 8671.840820] time: 0:06:31.642287\n",
      "[Epoch 9/200]  [D loss: 0.360397, mse: 33.955474] [mae: 23.768262] [mape: 10.143193] [G loss: 7856.921875] time: 0:07:17.663557\n",
      "[Epoch 10/200]  [D loss: 0.010378, mse: 31.387172] [mae: 21.616734] [mape: 9.319509] [G loss: 8292.980469] time: 0:08:03.707404\n",
      "[Epoch 11/200]  [D loss: 0.307305, mse: 22.557703] [mae: 14.464575] [mape: 7.114540] [G loss: 4868.905762] time: 0:08:49.556772\n",
      "[Epoch 12/200]  [D loss: 0.060564, mse: 30.811258] [mae: 21.052580] [mape: 8.890129] [G loss: 7032.927246] time: 0:09:35.474955\n",
      "[Epoch 13/200]  [D loss: 0.152354, mse: 30.677555] [mae: 21.009678] [mape: 8.713965] [G loss: 8159.971680] time: 0:10:21.783676\n",
      "[Epoch 14/200]  [D loss: 0.281668, mse: 18.076382] [mae: 10.976318] [mape: 6.039907] [G loss: 3959.535889] time: 0:11:07.692352\n",
      "[Epoch 15/200]  [D loss: 0.263856, mse: 17.233163] [mae: 10.456714] [mape: 6.116652] [G loss: 3975.776123] time: 0:11:53.557218\n",
      "[Epoch 16/200]  [D loss: 0.040065, mse: 17.568679] [mae: 10.679988] [mape: 5.833280] [G loss: 3656.205078] time: 0:12:39.673869\n",
      "[Epoch 17/200]  [D loss: 0.055897, mse: 17.138116] [mae: 10.370112] [mape: 5.610483] [G loss: 3510.115479] time: 0:13:26.100693\n",
      "[Epoch 18/200]  [D loss: 0.174847, mse: 16.947933] [mae: 10.320329] [mape: 5.772724] [G loss: 3440.992188] time: 0:14:12.295136\n",
      "[Epoch 19/200]  [D loss: 0.144558, mse: 28.473815] [mae: 19.411723] [mape: 7.881122] [G loss: 6106.554199] time: 0:14:58.327015\n",
      "[Epoch 20/200]  [D loss: 0.073397, mse: 37.349314] [mae: 26.737875] [mape: 10.276462] [G loss: 5886.338379] time: 0:15:44.497524\n",
      "[Epoch 21/200]  [D loss: 0.010198, mse: 20.785777] [mae: 13.571759] [mape: 6.336940] [G loss: 3379.275146] time: 0:16:30.424714\n",
      "[Epoch 22/200]  [D loss: 0.000611, mse: 36.043268] [mae: 25.739947] [mape: 9.983423] [G loss: 6669.629883] time: 0:17:16.558291\n",
      "[Epoch 23/200]  [D loss: 0.000102, mse: 19.734480] [mae: 12.831994] [mape: 6.108555] [G loss: 3378.239258] time: 0:18:02.500409\n",
      "[Epoch 24/200]  [D loss: 0.000070, mse: 34.959443] [mae: 24.897654] [mape: 9.671209] [G loss: 6758.493652] time: 0:18:48.446518\n",
      "[Epoch 25/200]  [D loss: 0.000076, mse: 15.950585] [mae: 9.833017] [mape: 5.308716] [G loss: 3104.207275] time: 0:19:34.470420\n",
      "[Epoch 26/200]  [D loss: 0.000082, mse: 16.565829] [mae: 10.357218] [mape: 5.389017] [G loss: 3062.534912] time: 0:20:20.443454\n",
      "[Epoch 27/200]  [D loss: 0.000087, mse: 15.063286] [mae: 9.156120] [mape: 5.107041] [G loss: 2906.010254] time: 0:21:06.394550\n",
      "[Epoch 28/200]  [D loss: 0.000089, mse: 18.137518] [mae: 11.638012] [mape: 5.745060] [G loss: 3146.809082] time: 0:21:52.393517\n",
      "[Epoch 29/200]  [D loss: 0.000092, mse: 19.808106] [mae: 12.981636] [mape: 6.082251] [G loss: 3420.202881] time: 0:22:39.909427\n",
      "[Epoch 30/200]  [D loss: 0.000098, mse: 16.798971] [mae: 10.764833] [mape: 5.727677] [G loss: 2987.607178] time: 0:23:26.372126\n",
      "[Epoch 31/200]  [D loss: 0.000113, mse: 25.126503] [mae: 18.047102] [mape: 9.254893] [G loss: 3642.294678] time: 0:24:13.672612\n",
      "[Epoch 32/200]  [D loss: 0.000139, mse: 17.225436] [mae: 11.019400] [mape: 5.483787] [G loss: 2940.578369] time: 0:25:01.300973\n",
      "[Epoch 33/200]  [D loss: 0.368946, mse: 26.907559] [mae: 18.855883] [mape: 7.759633] [G loss: 4359.750488] time: 0:25:47.553261\n",
      "[Epoch 34/200]  [D loss: 0.072217, mse: 15.517371] [mae: 9.719717] [mape: 5.158541] [G loss: 2789.280762] time: 0:26:33.480420\n",
      "[Epoch 35/200]  [D loss: 0.000050, mse: 26.063585] [mae: 18.468871] [mape: 7.796793] [G loss: 3444.862793] time: 0:27:19.352726\n",
      "[Epoch 36/200]  [D loss: 0.000053, mse: 20.708915] [mae: 13.865185] [mape: 6.186450] [G loss: 3261.927734] time: 0:28:05.275927\n",
      "[Epoch 37/200]  [D loss: 0.000057, mse: 15.266251] [mae: 9.656229] [mape: 5.159339] [G loss: 2718.733887] time: 0:28:51.513226\n",
      "[Epoch 38/200]  [D loss: 0.000060, mse: 17.888183] [mae: 11.656580] [mape: 5.579579] [G loss: 2922.377930] time: 0:29:39.283455\n",
      "[Epoch 39/200]  [D loss: 0.000063, mse: 20.603015] [mae: 13.835200] [mape: 6.118307] [G loss: 3216.939941] time: 0:30:26.694677\n",
      "[Epoch 40/200]  [D loss: 0.000066, mse: 16.209601] [mae: 10.335277] [mape: 5.248791] [G loss: 2763.218506] time: 0:31:13.553313\n",
      "[Epoch 41/200]  [D loss: 0.000069, mse: 17.307742] [mae: 11.481080] [mape: 5.948992] [G loss: 3203.951416] time: 0:32:02.140360\n",
      "[Epoch 42/200]  [D loss: 0.000077, mse: 22.092814] [mae: 14.953174] [mape: 6.313413] [G loss: 3538.107422] time: 0:32:50.361383\n",
      "[Epoch 43/200]  [D loss: 0.000095, mse: 20.121901] [mae: 13.533091] [mape: 5.950699] [G loss: 3167.126465] time: 0:33:39.467113\n",
      "[Epoch 44/200]  [D loss: 0.000124, mse: 14.112801] [mae: 8.768918] [mape: 4.825891] [G loss: 2631.100098] time: 0:34:25.875759\n",
      "[Epoch 45/200]  [D loss: 0.000168, mse: 13.926988] [mae: 8.657145] [mape: 4.805314] [G loss: 2605.106934] time: 0:35:13.112888\n",
      "[Epoch 46/200]  [D loss: 0.000152, mse: 17.249038] [mae: 11.190757] [mape: 5.306111] [G loss: 2902.790039] time: 0:36:00.545860\n",
      "[Epoch 47/200]  [D loss: 0.000251, mse: 14.936766] [mae: 9.502570] [mape: 4.956270] [G loss: 2690.131104] time: 0:36:47.771860\n",
      "[Epoch 48/200]  [D loss: 0.001622, mse: 14.584457] [mae: 9.211846] [mape: 4.877075] [G loss: 2674.396729] time: 0:37:34.909668\n",
      "[Epoch 49/200]  [D loss: 0.000297, mse: 14.835836] [mae: 9.500238] [mape: 5.213625] [G loss: 2755.620850] time: 0:38:22.175472\n",
      "[Epoch 50/200]  [D loss: 0.000220, mse: 13.630286] [mae: 8.493098] [mape: 4.965711] [G loss: 2612.352783] time: 0:39:10.970547\n",
      "[Epoch 51/200]  [D loss: 0.000262, mse: 15.743937] [mae: 10.027046] [mape: 4.966238] [G loss: 2778.440674] time: 0:39:58.596445\n",
      "[Epoch 52/200]  [D loss: 0.000306, mse: 23.118781] [mae: 16.246504] [mape: 7.485505] [G loss: 3422.026367] time: 0:40:46.259492\n",
      "[Epoch 53/200]  [D loss: 0.000254, mse: 16.625294] [mae: 10.752871] [mape: 5.145139] [G loss: 2820.949219] time: 0:41:34.226468\n",
      "[Epoch 54/200]  [D loss: 0.000406, mse: 15.025285] [mae: 9.472272] [mape: 4.835683] [G loss: 2705.934814] time: 0:42:22.134106\n",
      "[Epoch 55/200]  [D loss: 0.000390, mse: 14.940692] [mae: 9.426909] [mape: 4.786655] [G loss: 2772.364502] time: 0:43:10.103010\n",
      "[Epoch 56/200]  [D loss: 0.000385, mse: 13.773303] [mae: 8.635804] [mape: 5.025395] [G loss: 2524.622803] time: 0:43:57.627317\n",
      "[Epoch 57/200]  [D loss: 0.000434, mse: 14.716322] [mae: 9.405600] [mape: 5.272645] [G loss: 2719.589355] time: 0:44:45.182623\n",
      "[Epoch 58/200]  [D loss: 0.000381, mse: 18.016584] [mae: 11.877334] [mape: 5.382041] [G loss: 2966.837646] time: 0:45:32.160060\n",
      "[Epoch 59/200]  [D loss: 0.000451, mse: 16.011169] [mae: 10.302468] [mape: 4.936972] [G loss: 2796.422607] time: 0:46:19.309956\n",
      "[Epoch 60/200]  [D loss: 0.000435, mse: 17.236509] [mae: 11.382301] [mape: 5.274235] [G loss: 3091.752930] time: 0:47:06.193393\n",
      "[Epoch 61/200]  [D loss: 0.000426, mse: 16.461234] [mae: 10.956397] [mape: 5.864244] [G loss: 2675.480469] time: 0:47:52.879871\n",
      "[Epoch 62/200]  [D loss: 0.000390, mse: 18.370821] [mae: 12.245646] [mape: 5.462986] [G loss: 3248.301025] time: 0:48:39.111216\n",
      "[Epoch 63/200]  [D loss: 0.000417, mse: 16.069748] [mae: 10.661518] [mape: 5.881341] [G loss: 2653.263672] time: 0:49:25.359516\n",
      "[Epoch 64/200]  [D loss: 0.000395, mse: 17.989504] [mae: 12.134234] [mape: 5.541363] [G loss: 3680.096436] time: 0:50:11.905021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 65/200]  [D loss: 0.000326, mse: 13.003484] [mae: 8.062651] [mape: 4.662920] [G loss: 2383.861572] time: 0:50:58.255051\n",
      "[Epoch 66/200]  [D loss: 0.000401, mse: 13.398154] [mae: 8.209051] [mape: 4.402058] [G loss: 2440.237305] time: 0:51:44.710795\n",
      "[Epoch 67/200]  [D loss: 0.000420, mse: 16.961104] [mae: 11.239053] [mape: 5.162891] [G loss: 3132.855713] time: 0:52:31.103041\n",
      "[Epoch 68/200]  [D loss: 0.000450, mse: 14.116657] [mae: 8.759947] [mape: 4.660333] [G loss: 2400.249268] time: 0:53:17.404186\n",
      "[Epoch 69/200]  [D loss: 0.000485, mse: 17.397228] [mae: 11.689188] [mape: 5.745138] [G loss: 2751.148438] time: 0:54:03.635409\n",
      "[Epoch 70/200]  [D loss: 0.000423, mse: 19.083631] [mae: 13.187213] [mape: 6.450329] [G loss: 2752.986572] time: 0:54:50.030318\n",
      "[Epoch 71/200]  [D loss: 0.000418, mse: 12.863055] [mae: 7.801834] [mape: 4.454241] [G loss: 2287.950928] time: 0:55:36.384368\n",
      "[Epoch 72/200]  [D loss: 0.000408, mse: 12.802588] [mae: 7.958499] [mape: 4.622249] [G loss: 2273.432861] time: 0:56:22.709460\n",
      "[Epoch 73/200]  [D loss: 0.000414, mse: 13.169946] [mae: 8.108563] [mape: 4.357572] [G loss: 2378.828613] time: 0:57:09.228008\n",
      "[Epoch 74/200]  [D loss: 0.000415, mse: 17.098078] [mae: 11.244818] [mape: 5.028252] [G loss: 2732.295654] time: 0:57:55.432424\n",
      "[Epoch 75/200]  [D loss: 0.000437, mse: 14.595484] [mae: 9.439892] [mape: 5.162694] [G loss: 2397.563477] time: 0:58:42.147430\n",
      "[Epoch 76/200]  [D loss: 0.000435, mse: 18.840262] [mae: 12.813872] [mape: 5.781926] [G loss: 3053.396973] time: 0:59:28.304963\n",
      "[Epoch 77/200]  [D loss: 0.000388, mse: 13.605730] [mae: 8.436655] [mape: 4.336208] [G loss: 2355.737305] time: 1:00:14.371750\n",
      "[Epoch 78/200]  [D loss: 0.000400, mse: 12.691463] [mae: 7.776416] [mape: 4.356662] [G loss: 2260.303467] time: 1:01:00.737431\n",
      "[Epoch 79/200]  [D loss: 0.000394, mse: 18.275835] [mae: 12.087760] [mape: 5.213918] [G loss: 2627.645508] time: 1:01:48.129671\n",
      "[Epoch 80/200]  [D loss: 0.000383, mse: 13.979860] [mae: 8.796932] [mape: 4.388262] [G loss: 2271.937012] time: 1:02:34.426549\n",
      "[Epoch 81/200]  [D loss: 0.000409, mse: 13.032525] [mae: 7.883600] [mape: 4.070522] [G loss: 2159.920898] time: 1:03:21.711168\n",
      "[Epoch 82/200]  [D loss: 0.000391, mse: 12.621067] [mae: 7.764648] [mape: 4.215076] [G loss: 2147.841797] time: 1:04:09.077068\n",
      "[Epoch 83/200]  [D loss: 0.000394, mse: 12.567192] [mae: 7.512392] [mape: 4.005801] [G loss: 2093.226318] time: 1:04:55.674434\n",
      "[Epoch 84/200]  [D loss: 0.000409, mse: 19.109347] [mae: 13.026849] [mape: 5.503047] [G loss: 3315.122314] time: 1:05:42.713876\n",
      "[Epoch 85/200]  [D loss: 0.000417, mse: 15.250771] [mae: 9.842206] [mape: 4.671601] [G loss: 2237.400146] time: 1:06:31.436557\n",
      "[Epoch 86/200]  [D loss: 0.000400, mse: 12.053737] [mae: 7.262003] [mape: 4.084101] [G loss: 2052.569824] time: 1:07:19.949799\n",
      "[Epoch 87/200]  [D loss: 0.000409, mse: 16.119500] [mae: 10.729468] [mape: 5.286133] [G loss: 2898.405518] time: 1:08:07.652211\n",
      "[Epoch 88/200]  [D loss: 0.000394, mse: 13.491729] [mae: 8.366551] [mape: 4.171097] [G loss: 2123.861816] time: 1:08:57.782128\n",
      "[Epoch 89/200]  [D loss: 0.000453, mse: 14.430675] [mae: 9.202511] [mape: 4.435087] [G loss: 2140.656982] time: 1:09:45.179356\n",
      "[Epoch 90/200]  [D loss: 0.000399, mse: 12.195047] [mae: 7.611041] [mape: 4.187882] [G loss: 2028.169312] time: 1:10:33.000449\n",
      "[Epoch 91/200]  [D loss: 0.000389, mse: 11.933410] [mae: 7.221541] [mape: 3.956445] [G loss: 1987.261841] time: 1:11:21.036966\n",
      "[Epoch 92/200]  [D loss: 0.000452, mse: 14.927337] [mae: 9.652315] [mape: 4.563662] [G loss: 2170.254883] time: 1:12:43.352815\n",
      "[Epoch 93/200]  [D loss: 0.000439, mse: 12.570111] [mae: 7.806312] [mape: 4.176368] [G loss: 2050.435303] time: 1:13:31.255680\n",
      "[Epoch 94/200]  [D loss: 0.000425, mse: 12.155467] [mae: 7.341410] [mape: 3.956854] [G loss: 1929.861572] time: 1:14:18.287886\n",
      "[Epoch 95/200]  [D loss: 0.000425, mse: 12.787255] [mae: 8.072838] [mape: 4.279263] [G loss: 2106.772217] time: 1:15:05.377939\n",
      "[Epoch 96/200]  [D loss: 0.000405, mse: 19.796916] [mae: 13.439550] [mape: 5.468164] [G loss: 3336.279541] time: 1:15:53.371571\n",
      "[Epoch 97/200]  [D loss: 0.000417, mse: 17.344060] [mae: 11.494392] [mape: 5.037781] [G loss: 2093.877197] time: 1:16:41.079961\n",
      "[Epoch 98/200]  [D loss: 0.000381, mse: 15.195727] [mae: 10.198745] [mape: 5.018924] [G loss: 2452.854248] time: 1:17:27.634466\n",
      "[Epoch 99/200]  [D loss: 0.000387, mse: 11.856133] [mae: 7.108070] [mape: 3.796907] [G loss: 1850.172852] time: 1:18:15.348821\n",
      "[Epoch 100/200]  [D loss: 0.000366, mse: 11.588594] [mae: 6.942169] [mape: 3.801721] [G loss: 1807.104248] time: 1:19:06.149169\n",
      "[Epoch 101/200]  [D loss: 0.000366, mse: 11.473695] [mae: 6.816203] [mape: 3.684289] [G loss: 1772.706543] time: 1:20:07.362461\n",
      "[Epoch 102/200]  [D loss: 0.000402, mse: 17.097610] [mae: 11.645813] [mape: 5.322824] [G loss: 2068.862061] time: 1:20:57.814056\n",
      "[Epoch 103/200]  [D loss: 0.000298, mse: 12.369428] [mae: 7.607167] [mape: 3.884753] [G loss: 1960.065552] time: 1:21:45.955294\n",
      "[Epoch 104/200]  [D loss: 0.000331, mse: 12.154105] [mae: 7.321275] [mape: 3.751276] [G loss: 1742.031982] time: 1:22:35.055963\n",
      "[Epoch 105/200]  [D loss: 0.000362, mse: 13.966131] [mae: 8.903163] [mape: 4.217225] [G loss: 1813.934814] time: 1:23:22.732570\n",
      "[Epoch 106/200]  [D loss: 0.000276, mse: 13.108615] [mae: 8.143377] [mape: 3.946643] [G loss: 1769.282471] time: 1:24:09.281067\n",
      "[Epoch 107/200]  [D loss: 0.000212, mse: 11.235166] [mae: 6.711754] [mape: 3.581551] [G loss: 1699.624146] time: 1:24:55.420658\n",
      "[Epoch 108/200]  [D loss: 0.000252, mse: 11.792416] [mae: 7.228333] [mape: 3.733268] [G loss: 1717.541626] time: 1:25:43.080214\n",
      "[Epoch 109/200]  [D loss: 0.000216, mse: 11.353653] [mae: 6.805606] [mape: 3.580340] [G loss: 1696.169800] time: 1:26:29.122036\n",
      "[Epoch 110/200]  [D loss: 0.000262, mse: 16.283088] [mae: 10.773640] [mape: 4.733257] [G loss: 2523.624023] time: 1:27:15.152919\n",
      "[Epoch 111/200]  [D loss: 0.000252, mse: 12.550212] [mae: 7.935853] [mape: 3.888682] [G loss: 1739.663330] time: 1:28:01.806663\n",
      "[Epoch 112/200]  [D loss: 0.000144, mse: 11.837128] [mae: 7.295450] [mape: 3.700677] [G loss: 1669.767212] time: 1:28:48.097848\n",
      "[Epoch 113/200]  [D loss: 0.000228, mse: 13.309133] [mae: 8.584823] [mape: 4.176515] [G loss: 1747.954102] time: 1:29:34.303264\n",
      "[Epoch 114/200]  [D loss: 0.000228, mse: 11.359213] [mae: 6.892696] [mape: 3.625568] [G loss: 1605.744385] time: 1:30:22.051551\n",
      "[Epoch 115/200]  [D loss: 0.000266, mse: 11.686874] [mae: 7.174281] [mape: 3.699572] [G loss: 1662.321289] time: 1:31:09.473712\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-f2845cdbc646>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMAX_BATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearn_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearn_rate_c\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-39-ded675f42176>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(train_matrix, epochs, batch_size, learn_rate)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[1;31m# 根据历史数据生成预测数据\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m             \u001b[0mforecast_volume\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory_volume\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[1;31m# 训练 the discriminators (original images = real / generated = Fake)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1165\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1166\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1167\u001b[1;33m                                             steps=steps)\n\u001b[0m\u001b[0;32m   1168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1169\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2664\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2666\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2667\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2668\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2617\u001b[0m                 array_vals.append(\n\u001b[0;32m   2618\u001b[0m                     np.asarray(value,\n\u001b[1;32m-> 2619\u001b[1;33m                                dtype=tf.as_dtype(tensor.dtype).as_numpy_dtype))\n\u001b[0m\u001b[0;32m   2620\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2621\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m     \"\"\"\n\u001b[1;32m--> 492\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(X_train, epochs=200, batch_size=MAX_BATCH_SIZE, learn_rate=learn_rate_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator.save_weights('./model/wganpg/generator_167epoch_11rmse.h5')\n",
    "# discriminator.save_weights('./model/wganpg/discriminator_167epoch_11rmse.h5')\n",
    "# combined.save_weights('./model/wganpg/combined_167epoch_11rmse.h5')\n",
    "\n",
    "# generator.load_weights('./model/wganpg/DS_rmse11/generator_167epoch_11rmse.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = generator.predict(X_test[:, :, :, 1:])\n",
    "y_true = X_test[:, :, :, :1]\n",
    "\n",
    "l2(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.sqrt(np.sum(np.mean(np.square(y_true - y_pred), axis=0))/1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2(y_true, y_pred+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y = y_true.reshape(-1,)[1600:1700]\n",
    "x = np.linspace(0, len(y), len(y))\n",
    "\n",
    "yi = y_pred.reshape(-1,)[1600:1700]\n",
    "xi = np.linspace(0, len(yi), len(yi))\n",
    "fig, ax = plt.subplots(figsize=(25, 6))\n",
    "# ax.plot(x, y, '.', linewidth=1, markersize=10)\n",
    "lines = plt.plot(xi, yi, 'k^--', x, y, 'ro-',linewidth=1, markersize=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yi = l2_validation\n",
    "xi = np.linspace(0, len(yi), len(yi))\n",
    "\n",
    "y = [i*10000 for i in lr_step]\n",
    "x = np.linspace(0, len(y), len(y))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "lines = plt.plot(x, y, 'ko-', xi, yi, 'k^--', linewidth=1, markersize=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = lr_step\n",
    "x = np.linspace(0, len(y), len(y))\n",
    "# fig, ax = plt.subplots(figsize=(6, 6))\n",
    "# lines = plt.plot(x, y, 'ko-', linewidth=1, markersize=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_true.reshape(-1,)[3600:3700]\n",
    "x = np.linspace(0, len(y), len(y))\n",
    "\n",
    "yi = y_pred.reshape(-1,)[3600:3700]\n",
    "xi = np.linspace(0, len(yi), len(yi))\n",
    "fig, ax = plt.subplots(figsize=(25, 6))\n",
    "ax.plot(x, y, '.', linewidth=1, markersize=10)\n",
    "lines = plt.plot(xi, yi, 'k^--', x, y, 'ro-',linewidth=1, markersize=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = 0\n",
    "y = y_true.reshape(-1,)[start_time: start_time+100]\n",
    "x = np.linspace(0, len(y), len(y))\n",
    "\n",
    "yi = y_pred.reshape(-1,)[start_time: start_time+100]\n",
    "xi = np.linspace(0, len(yi), len(yi))\n",
    "fig, ax = plt.subplots(figsize=(25, 6))\n",
    "# ax.plot(x, y, '.', linewidth=1, markersize=10)\n",
    "lines = plt.plot(xi, yi, 'k^--', x, y, 'ro-',linewidth=1, markersize=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
